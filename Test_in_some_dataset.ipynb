{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZHaxeokookA",
    "outputId": "2d6e8472-802b-44a7-bd75-3b94b491e60d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-Z19I3EFmRA",
    "outputId": "70c8a430-f379-493f-8efe-ec0aec8e1ea0"
   },
   "outputs": [],
   "source": [
    "!fusermount -u drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZ-SO1Rzp75z"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow-gpu==2.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AC8sXLyp9h6"
   },
   "outputs": [],
   "source": [
    "# from unet_model_with_functions_of_blocks import build_unet\n",
    "from __future__ import division\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import *\n",
    "import numpy as np\n",
    "from tensorflow.keras import callbacks\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from glob import glob\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iw7z1afhOXJM",
    "outputId": "d668eb99-1699-4394-d357-3a8140c208ac"
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_wfBmH4dA7UX",
    "outputId": "42572c09-c482-4b75-a6b9-98d919ff76c0"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xxISS7V8BUcm",
    "outputId": "8208273b-0e7c-43f2-b3b1-adb559577bfe"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "erj2ZqbACK_9",
    "outputId": "e0c374e7-2d36-4a96-d407-8b1dbea3bd46"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_D-JoeAJqQ5l"
   },
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiFyNmZCUrgo",
    "outputId": "a82507c6-ccb4-455b-a581-ac0400035e6c"
   },
   "outputs": [],
   "source": [
    "!zip Standard.zip '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQoYDmnCXZko"
   },
   "outputs": [],
   "source": [
    "!apt-get install rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IxIIMHuXbQv"
   },
   "outputs": [],
   "source": [
    "!rar a '/content/drive/MyDrive/Test DDSM 185 Images/StandardModel.rar' '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWKxtFTQZDM3"
   },
   "outputs": [],
   "source": [
    "!rar a '/content/drive/MyDrive/Test DDSM 185 Images/without2skipconnection.rar' '/content/drive/MyDrive/Test DDSM 185 Images/without 2 skip connection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v62M9ME4ZQ0D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9WSDSxOxZlj"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cImDOYcp6G3"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/New Dataset/New_Training_20k_bkg.rar\"\n",
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/New Dataset/New_Validation_3k_bkg.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyhHi3vup_l6"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "epochs = 100\n",
    "height = 256\n",
    "width= 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTlR5EhfqW2x"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "log_file = os.path.join(files_dir,'log_new-data-bkg_15-5_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noTmViapqZ0n"
   },
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "  if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abDzVPsNqaLT"
   },
   "outputs": [],
   "source": [
    "create_dir(files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mkhlPKwqbmR"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "  train_x = sorted(glob(os.path.join(path, 'New_Training_20k_bkg', 'Patch', '*')))\n",
    "  train_y = sorted(glob(os.path.join(path, 'New_Training_20k_bkg', 'Mask', '*')))\n",
    "\n",
    "  valid_x = sorted(glob(os.path.join(path, 'New_Validation_3k_bkg', 'Patch', '*')))\n",
    "  valid_y = sorted(glob(os.path.join(path, 'New_Validation_3k_bkg', 'Mask', '*')))\n",
    "\n",
    "  return (train_x, train_y), (valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcCs6BWyqdZg"
   },
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "  path = path.decode()\n",
    "  x = cv.imread(path).astype(np.float32)\n",
    "  x = x/255.0\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8BXeL-fqezp"
   },
   "outputs": [],
   "source": [
    "def read_mask(path):\n",
    "  path = path.decode()\n",
    "  x = cv.imread(path, 0).astype(np.bool_)\n",
    "  # x = x/255.0\n",
    "  x = np.expand_dims(x, axis = -1)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlT6S8ztqiRf"
   },
   "outputs": [],
   "source": [
    "def tf_parse(x,y):\n",
    "  def _parse(x,y):\n",
    "    x = read_image(x)\n",
    "    y = read_mask(y)\n",
    "    return x, y\n",
    "\n",
    "  x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.bool])\n",
    "  x.set_shape([height, width, 3])\n",
    "  y.set_shape([height, width, 1])\n",
    "\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzjE-AWJqitP"
   },
   "outputs": [],
   "source": [
    "def tf_dataset(x, y, batch = 8):\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "  dataset = dataset.map(tf_parse, num_parallel_calls= tf.data.AUTOTUNE)\n",
    "  dataset = dataset.batch(batch)\n",
    "  dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4H-x-JykqkJ6",
    "outputId": "bd2483c8-807e-4c22-c475-ed123337d345"
   },
   "outputs": [],
   "source": [
    "(train_x, train_y), (valid_x, valid_y) = load_data(dataset_path)\n",
    "print(f'TRAIN:{len(train_x)}')\n",
    "print(f'VALID:{len(valid_x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5lzMwcWjqluN"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf_dataset(train_x, train_y, batch = batch_size)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bmDwvdc_CT0D",
    "outputId": "ee5a6bac-970e-4270-9433-2b046b10cb79"
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "for x, y in valid_dataset:\n",
    "  if n in [1,5, 7, 8, 9]:\n",
    "  # print(x.shape, y.shape)\n",
    "  # print(y[0].dtype)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(x[0], cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(np.squeeze(y[0]), cmap='gray')\n",
    "    plt.show()\n",
    "  n = n + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faSnoYZMxdbj"
   },
   "source": [
    "### Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9H_Y4fPFqpCx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Concatenate, MaxPooling2D, BatchNormalization, Activation, DepthwiseConv2D, SeparableConv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def decoder_block(inputs, skip, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = conv_block(x, num_filters)\n",
    "\n",
    "    return x\n",
    "\n",
    "def efficientnetb0_unet(input_shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    \"\"\" Pre-trained Encoder \"\"\"\n",
    "    encoder = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "\n",
    "    s1 = encoder.get_layer(\"input_1\").output                      ## 256\n",
    "    s2 = encoder.get_layer(\"block2a_expand_activation\").output    ## 128\n",
    "    s3 = encoder.get_layer(\"block3a_expand_activation\").output    ## 64\n",
    "    s4 = encoder.get_layer(\"block4a_expand_activation\").output    ## 32\n",
    "\n",
    "    \"\"\" Bottleneck \"\"\"\n",
    "    b1 = encoder.get_layer(\"block6a_expand_activation\").output    ## 16\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 512)                               ## 32\n",
    "    d2 = decoder_block(d1, s3, 256)                               ## 64\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)                                ## 128\n",
    "\n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"EfficientNetB0_UNET\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_s9XzGeqq6T",
    "outputId": "3d3062de-5f58-4484-f2ae-5027e13e50bc"
   },
   "outputs": [],
   "source": [
    "input_shape = (height, width, 3)\n",
    "model = efficientnetb0_unet(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eL024JfQI6Vh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4edJRg_Qv0Ho"
   },
   "outputs": [],
   "source": [
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + 0.5 * dice_loss(tf.cast(y_true, tf.float32), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMVcY9gd0SZl"
   },
   "outputs": [],
   "source": [
    "def segment_sensitivity(y,y_pred):\n",
    "  bitwise_and_roi_patch = np.logical_and(np.squeeze(y), np.squeeze(y_pred))\n",
    "  segment_sensitivity = round(np.sum(bitwise_and_roi_patch) / np.sum(np.squeeze(y)), 2)\n",
    "  return segment_sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lD7z4jDqrSd"
   },
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8K0_KArN0iL2"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = model_file, verbose = 1, save_best_only= True),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, verbose=1),\n",
    "    CSVLogger(log_file),\n",
    "    EarlyStopping(monitor = 'val_loss', patience = 20,verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7a4BnLt1mJh"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1.0000e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pp4H419thpl6",
    "outputId": "682eb502-d6e6-4860-ecc4-8d6c0b270546"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.testing import assert_allclose\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# load the model\n",
    "new_model = load_model(model_file\n",
    "                       )\n",
    "\n",
    "# fit the model\n",
    "new_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data= valid_dataset,\n",
    "    epochs= epochs,\n",
    "    callbacks= callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nD5oVHmWS3t",
    "outputId": "cddddbf3-d05f-4bc5-8517-4475b92e76f4"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.metrics import Precision, Recall, MeanIoU\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data= valid_dataset,\n",
    "    epochs= epochs,\n",
    "    callbacks= callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVXreHqryGCJ"
   },
   "source": [
    "#### plot loss and accuracy diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "27uF0ed4Gi3r",
    "outputId": "7de4f250-8d6e-462f-8a0e-bdd0e3ecdb19"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(log_file)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(data[\"epoch\"],data[\"accuracy\"])\n",
    "plt.plot(data[\"epoch\"],data[\"val_accuracy\"])\n",
    "plt.legend(['train_acc', 'val_acc'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "NC0xY6B8GzoS",
    "outputId": "7206ce3e-97af-4a9f-8abd-f330a52fa66f"
   },
   "outputs": [],
   "source": [
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(data[\"epoch\"],data[\"loss\"])\n",
    "plt.plot(data[\"epoch\"],data[\"val_loss\"])\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "nn5QMP8eHVt-",
    "outputId": "6fb2ca87-96d1-4509-9145-e802b4d833bd"
   },
   "outputs": [],
   "source": [
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(data[\"epoch\"][7:],data[\"loss\"][7:])\n",
    "plt.plot(data[\"epoch\"][7:],data[\"val_loss\"][7:])\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GG8FGc7MsS_V"
   },
   "outputs": [],
   "source": [
    "files_dir_2nd = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg_unet_without_skip')\n",
    "model_file_2nd = os.path.join(files_dir_2nd,'unet_effb0-new-data-20_bkg-without-skip.h5')\n",
    "log_file_2nd = os.path.join(files_dir_2nd,'log_new-data-bkg_15-5-without-skip_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcTaPmo7u97Z"
   },
   "outputs": [],
   "source": [
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "log_file = os.path.join(files_dir,'log_new-data-bkg_15-5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "9-8c5Bc7tQcF",
    "outputId": "a0001124-7a0b-4fab-b54c-0f9e2c6a9374"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(log_file)\n",
    "data_2nd = pd.read_csv(log_file_2nd)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(data[\"epoch\"][10:],data[\"loss\"][10:], color = 'blue')\n",
    "plt.plot(data[\"epoch\"][10:],data[\"val_loss\"][10:], color = 'green')\n",
    "\n",
    "plt.plot(data_2nd[\"epoch\"][10:],data_2nd[\"loss\"][10:], color = 'red')\n",
    "plt.plot(data_2nd[\"epoch\"][10:],data_2nd[\"val_loss\"][10:], color = 'orange')\n",
    "plt.legend(['train_loss_1', 'val_loss_1', 'train_loss_2', 'val_loss_2'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "Gz-giEoSv7ta",
    "outputId": "5b7bab26-c16f-4a05-ce64-d4c7ff1d7b44"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(log_file)\n",
    "data_2nd = pd.read_csv(log_file_2nd)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(data[\"epoch\"][10:],data[\"accuracy\"][10:], color = 'blue')\n",
    "plt.plot(data[\"epoch\"][10:],data[\"val_accuracy\"][10:], color = 'green')\n",
    "\n",
    "plt.plot(data_2nd[\"epoch\"][10:],data_2nd[\"accuracy\"][10:], color = 'red')\n",
    "plt.plot(data_2nd[\"epoch\"][10:],data_2nd[\"val_accuracy\"][10:], color = 'orange')\n",
    "plt.legend(['train_acc_1', 'val_acc_1', 'train_acc_2', 'val_acc_2'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "XLlXITCHEFe8",
    "outputId": "839e289b-1e92-44b0-bb1c-2335abeda7cd"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(log_file)\n",
    "plt.xlabel(\"epoch\")\n",
    "# plt.ylabel(\"accuracy\")\n",
    "plt.plot(data[\"epoch\"][10:],data[\"accuracy\"][10:])\n",
    "plt.plot(data[\"epoch\"][10:],data[\"loss\"][10:])\n",
    "plt.legend(['train_acc', 'train_loss'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGb_NECkIQg6"
   },
   "outputs": [],
   "source": [
    "def cal_overlap(x,y,y_pred):\n",
    "  bitwise_and_roi_patch = np.logical_and(np.squeeze(y), np.squeeze(y_pred))\n",
    "  overlap = round(np.sum(bitwise_and_roi_patch) / np.sum(np.squeeze(y)), 2)\n",
    "  return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ho5AfGCSISoi"
   },
   "outputs": [],
   "source": [
    "def show_image_roi_predict1_img(index, x, y, predict):\n",
    "    overlap = cal_overlap(x[index], y[index], predict)\n",
    "    print (overlap)\n",
    "\n",
    "    img = x[index]\n",
    "\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Image' + str(index))\n",
    "    plt.axis('off')\n",
    "\n",
    "    roi = np.squeeze(y[index])\n",
    "    plt.subplot(132)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(roi, 'gray')\n",
    "    plt.title('ROI ' + str(index))\n",
    "\n",
    "    roi_pred = np.squeeze(predict)\n",
    "    plt.subplot(133)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(roi_pred)\n",
    "    plt.title('ROI pred ' + str(index))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umPCIZnoyM7H"
   },
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9pyRuybIcHj",
    "outputId": "1d834b0a-b258-4946-db55-d1314c7db044"
   },
   "outputs": [],
   "source": [
    "preds_test = model.predict(valid_dataset, verbose=1)\n",
    "test_set_y_pred = (preds_test > 0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mXdCCQ6WIVjB",
    "outputId": "f4748e80-67d8-41ff-da6a-89132e01881c"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for x, y in valid_dataset:\n",
    "    show_image_roi_predict1_img(5, x, y, test_set_y_pred[(i)*batch_size + 5])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-UFeZpsUkk2"
   },
   "source": [
    "### Multi Tumors Testing (CBIS-DDSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5eY7LMQUqTW"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/New Dataset/CBIS Test set_preprocessing.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2GL5QhLWNXv"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/New Dataset/CBIS Test set - CLAHE.rar\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RysdEuQ6zQUv",
    "outputId": "5a911862-9053-4ded-dd0e-06f95b4b8e96"
   },
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdQqs9CFzIku"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "# test_x = sorted(glob(os.path.join(dataset_path, 'CBIS Test set_preprocessing', 'Image', '*')))\n",
    "# test_y = sorted(glob(os.path.join(dataset_path, 'CBIS Test set_preprocessing', 'Mask', '*')))\n",
    "\n",
    "test_x_clahe = sorted(glob(os.path.join(dataset_path, 'CBIS Test set - CLAHE', 'Image', '*')))\n",
    "test_y_clahe = sorted(glob(os.path.join(dataset_path, 'CBIS Test set - CLAHE', 'Mask', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLw2nu0ZzK52"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x_clahe, 'roi': test_y_clahe})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/New Dataset/cbis_test_clahe_multi_rois.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kGV2FxozzqH"
   },
   "outputs": [],
   "source": [
    "def show_y_predict(randomlist, y, y_pred):\n",
    "  fg, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[0, i].imshow(np.squeeze(y[index]), 'gray')\n",
    "    ax[0, i].set_xlabel('y ' + str(index))\n",
    "    # print(y[index].shape)\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[1, i].imshow(np.squeeze(y_pred[index]), 'gray')\n",
    "    ax[1, i].set_xlabel('y_pred ' + str(index))\n",
    "\n",
    "def prediction(model, large_image, patch_size, step):\n",
    "  patches = patchify(large_image, (patch_size, patch_size), step=step)  #Step=256 for 256 patches means no overlap\n",
    "\n",
    "  print(patches.shape)\n",
    "\n",
    "  redicted_patches = []\n",
    "  patches_input = []\n",
    "  for i in range(patches.shape[0]):\n",
    "    for j in range(patches.shape[1]):\n",
    "        # print(i,j)\n",
    "        single_patch = patches[i,j,:,:]\n",
    "        single_patch_input=np.expand_dims(single_patch, -1)\n",
    "        # single_patch = np.array(single_patch)\n",
    "        # print(single_patch.shape)\n",
    "        #Predict and threshold for values above 0.5 probability\n",
    "\n",
    "        single_patch_input = np.zeros((patch_size,patch_size,3), dtype=\"float32\")\n",
    "        single_patch_input[:,:,0] = single_patch\n",
    "        single_patch_input[:,:,1] = single_patch\n",
    "        single_patch_input[:,:,2] = single_patch\n",
    "\n",
    "        single_patch_input = cv.resize(single_patch_input, (256,256), cv.INTER_AREA)\n",
    "        single_patch_input = np.array(single_patch_input)\n",
    "        patches_input.append(single_patch_input)\n",
    "\n",
    "  patches_input = np.array(patches_input)\n",
    "\n",
    "  patches_prediction = (model.predict(patches_input) >= 0.5).astype(np.uint8)\n",
    "\n",
    "  # randomlist = random.sample(range(0, len(patches_prediction)),5)\n",
    "  # show_y_predict(randomlist, patches_input, patches_prediction)\n",
    "  # plt.show()\n",
    "\n",
    "  patches_prediction_resize = []\n",
    "  for i in patches_prediction:\n",
    "    i = cv.resize(i, (patch_size,patch_size), cv.INTER_AREA)\n",
    "    patches_prediction_resize.append(i)\n",
    "\n",
    "  predicted_patches_reshaped = np.reshape(patches_prediction_resize, (patches.shape[0], patches.shape[1], patch_size,patch_size) )\n",
    "  print(predicted_patches_reshaped.shape)\n",
    "\n",
    "  reconstructed_image = unpatchify(predicted_patches_reshaped, large_image.shape)\n",
    "  plt.imshow(np.squeeze(reconstructed_image), cmap='gray')\n",
    "  return reconstructed_image\n",
    "\n",
    "def filter_FP(y_pred, thresh):\n",
    "  y_pred_filter = y_pred.copy()\n",
    "  kernel = np.ones((3,3),np.uint8)\n",
    "  y_pred_filter = cv.erode(y_pred_filter, kernel)\n",
    "\n",
    "  contours, _ = cv.findContours(y_pred_filter.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "  n = 0\n",
    "  for ct in contours:\n",
    "      contour_area = cv.contourArea(ct)\n",
    "      if (contour_area>= thresh):\n",
    "          n += 1\n",
    "      else:\n",
    "        y_pred_filter = cv.fillPoly(y_pred_filter, pts=[ct], color=(0, 0))\n",
    "  y_pred_filter =  cv.dilate(y_pred_filter, kernel)\n",
    "  return y_pred_filter, n\n",
    "\n",
    "\n",
    "def draw_contour_pred_and_truth(large_image, pred, roi):\n",
    "  img_copy = large_image.copy()\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  cv.drawContours(img_copy, contours_roi , -1, (255,0,0), 3)\n",
    "  cv.drawContours(img_copy, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "  return img_copy\n",
    "\n",
    "def check_Left_Orient(img, roi):\n",
    "    left_nonzero = cv.countNonZero(img[:, 0:int(img.shape[1] / 2)])\n",
    "    right_nonzero = cv.countNonZero(img[:, int(img.shape[1] / 2):])\n",
    "\n",
    "    if (left_nonzero <= right_nonzero):\n",
    "            img = cv.flip(img, 1)\n",
    "            roi = cv.flip(roi, 1)\n",
    "\n",
    "    return img, roi\n",
    "\n",
    "def cal_overlap_per_large_img(roi, overlap_img):\n",
    "  bitwise_and_roi_pred = cv.bitwise_and(overlap_img, roi)\n",
    "  area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "  overlap = round(area_truth / np.count_nonzero(roi), 4)*100\n",
    "  return bitwise_and_roi_pred, area_truth, overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1d_1BhIj0iUC"
   },
   "outputs": [],
   "source": [
    "def cal_overlap_per_large_img(roi, overlap_img):\n",
    "  bitwise_and_roi_pred = cv.bitwise_and(overlap_img, roi)\n",
    "  area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "  overlap = round(area_truth / np.count_nonzero(roi), 4)*100\n",
    "  return bitwise_and_roi_pred, area_truth, overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBGDlaPt0WC3"
   },
   "outputs": [],
   "source": [
    "new_model_file = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQNUQTftyAXx"
   },
   "source": [
    "#### not clahe, patch 512, step 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LN7K7kb_0Y9e",
    "outputId": "689cf7e0-8d2b-48fd-9c61-1323bc92ddfd"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/New Dataset/cbis_test_multi_rois.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test CBIS Predict/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test CBIS Predict/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test CBIS Predict/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0).astype(np.float32)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # bit_depth = img.depth\n",
    "        # print(large_image.depth, roi.depth)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "        h,w = img.shape\n",
    "        patch_size = 1024\n",
    "        step = 128\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img = img[0:new_img_h, 0: new_img_w]\n",
    "        roi = roi[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(roi)\n",
    "        # plt.show()\n",
    "\n",
    "        segmented_image = prediction(new_model_file, img, patch_size, step)\n",
    "\n",
    "        pred_img = np.zeros(roi.shape, dtype=\"uint8\")\n",
    "\n",
    "        h, w = segmented_image.shape\n",
    "        print(segmented_image.dtype)\n",
    "\n",
    "        plt.imshow(segmented_image)\n",
    "        plt.show()\n",
    "\n",
    "        pred_img[0:h, 0:w] = segmented_image\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(pred_img, 2000 )\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_FP = num_FP + n\n",
    "        num_P_list.append(n)\n",
    "        print(\"number FP  = \", n )\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, area_truth, overlap = cal_overlap_per_large_img(roi, y_pred_filter)\n",
    "        print(overlap)\n",
    "        area_truth_list.append(area_truth)\n",
    "        overlap_list.append(overlap)\n",
    "        overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.title(name_file_saver + \"- overlap = \"+ str(overlap) + \", Roi = \" + str(n))\n",
    "        plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5klxmbOx5Tx"
   },
   "source": [
    "#### not clahe, patch 1024, step 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rhEByUZzx3gz",
    "outputId": "a2c9d2bf-e8d4-4f7d-af76-96d2d6d826f8"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/New Dataset/cbis_test_multi_rois.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test CBIS Predict/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test CBIS Predict/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test CBIS Predict/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0).astype(np.float32)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # bit_depth = img.depth\n",
    "        # print(large_image.depth, roi.depth)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "        h,w = img.shape\n",
    "        patch_size = 1024\n",
    "        step = 128\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img = img[0:new_img_h, 0: new_img_w]\n",
    "        roi = roi[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(roi)\n",
    "        # plt.show()\n",
    "\n",
    "        segmented_image = prediction(new_model_file, img, patch_size, step)\n",
    "\n",
    "        pred_img = np.zeros(roi.shape, dtype=\"uint8\")\n",
    "\n",
    "        h, w = segmented_image.shape\n",
    "        print(segmented_image.dtype)\n",
    "\n",
    "        plt.imshow(segmented_image)\n",
    "        plt.show()\n",
    "\n",
    "        pred_img[0:h, 0:w] = segmented_image\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(pred_img, 2000 )\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_FP = num_FP + n\n",
    "        num_P_list.append(n)\n",
    "        print(\"number FP  = \", n )\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, area_truth, overlap = cal_overlap_per_large_img(roi, y_pred_filter)\n",
    "        print(overlap)\n",
    "        area_truth_list.append(area_truth)\n",
    "        overlap_list.append(overlap)\n",
    "        overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.title(name_file_saver + \"- overlap = \"+ str(overlap) + \", Roi = \" + str(n))\n",
    "        plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nt0opVed3sBC"
   },
   "source": [
    "#### not clahe, patch 384, step 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdVawInz3xfY"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/New Dataset/cbis_test_multi_rois.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test CBIS Predict/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test CBIS Predict/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test CBIS Predict/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0).astype(np.float32)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # bit_depth = img.depth\n",
    "        # print(large_image.depth, roi.depth)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "        h,w = img.shape\n",
    "        patch_size = 384\n",
    "        step = 64\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img = img[0:new_img_h, 0: new_img_w]\n",
    "        roi = roi[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(roi)\n",
    "        # plt.show()\n",
    "\n",
    "        segmented_image = prediction(new_model_file, img, patch_size, step)\n",
    "\n",
    "        pred_img = np.zeros(roi.shape, dtype=\"uint8\")\n",
    "\n",
    "        h, w = segmented_image.shape\n",
    "        print(segmented_image.dtype)\n",
    "\n",
    "        plt.imshow(segmented_image)\n",
    "        plt.show()\n",
    "\n",
    "        pred_img[0:h, 0:w] = segmented_image\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(pred_img, 2000 )\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_FP = num_FP + n\n",
    "        num_P_list.append(n)\n",
    "        print(\"number FP  = \", n )\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, area_truth, overlap = cal_overlap_per_large_img(roi, y_pred_filter)\n",
    "        print(overlap)\n",
    "        area_truth_list.append(area_truth)\n",
    "        overlap_list.append(overlap)\n",
    "        overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.title(name_file_saver + \"- overlap = \"+ str(overlap) + \", Roi = \" + str(n))\n",
    "        plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i5qS4Fu9oBf"
   },
   "source": [
    "### Multi Tumors CBIS, clahe, patch 1024, step 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hVtyKOrR9s3X",
    "outputId": "a6a4fba5-1d86-4f99-e89c-dcf04da3ee2f"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/New Dataset/cbis_test_clahe_multi_rois.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test CBIS CLAHE Predict - 1024 step 128/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test CBIS CLAHE Predict - 1024 step 128/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test CBIS CLAHE Predict - 1024 step 128/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0).astype(np.float32)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # bit_depth = img.depth\n",
    "        # print(large_image.depth, roi.depth)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "        h,w = img.shape\n",
    "        patch_size = 1024\n",
    "        step = 128\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img = img[0:new_img_h, 0: new_img_w]\n",
    "        roi = roi[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(roi)\n",
    "        # plt.show()\n",
    "\n",
    "        segmented_image = prediction(new_model_file, img, patch_size, step)\n",
    "\n",
    "        pred_img = np.zeros(roi.shape, dtype=\"uint8\")\n",
    "\n",
    "        h, w = segmented_image.shape\n",
    "        print(segmented_image.dtype)\n",
    "\n",
    "        plt.imshow(segmented_image)\n",
    "        plt.show()\n",
    "\n",
    "        pred_img[0:h, 0:w] = segmented_image\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(pred_img, 2000 )\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_FP = num_FP + n\n",
    "        num_P_list.append(n)\n",
    "        print(\"number FP  = \", n )\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, area_truth, overlap = cal_overlap_per_large_img(roi, y_pred_filter)\n",
    "        print(overlap)\n",
    "        area_truth_list.append(area_truth)\n",
    "        overlap_list.append(overlap)\n",
    "        overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.title(name_file_saver + \"- overlap = \"+ str(overlap) + \", Roi = \" + str(n))\n",
    "        plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOWQiO1oX2AY"
   },
   "source": [
    "#### clahe patch 512, step 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7bQRvUQX5Qt"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/New Dataset/cbis_test_clahe_multi_rois.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test CBIS CLAHE Predict - 1024 step 128/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test CBIS CLAHE Predict - 1024 step 128/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test CBIS CLAHE Predict - 1024 step 128/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0).astype(np.float32)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # bit_depth = img.depth\n",
    "        # print(large_image.depth, roi.depth)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "        h,w = img.shape\n",
    "        patch_size = 1024\n",
    "        step = 128\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img = img[0:new_img_h, 0: new_img_w]\n",
    "        roi = roi[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(roi)\n",
    "        # plt.show()\n",
    "\n",
    "        segmented_image = prediction(new_model_file, img, patch_size, step)\n",
    "\n",
    "        pred_img = np.zeros(roi.shape, dtype=\"uint8\")\n",
    "\n",
    "        h, w = segmented_image.shape\n",
    "        print(segmented_image.dtype)\n",
    "\n",
    "        plt.imshow(segmented_image)\n",
    "        plt.show()\n",
    "\n",
    "        pred_img[0:h, 0:w] = segmented_image\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(pred_img, 2000 )\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_FP = num_FP + n\n",
    "        num_P_list.append(n)\n",
    "        print(\"number FP  = \", n )\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, area_truth, overlap = cal_overlap_per_large_img(roi, y_pred_filter)\n",
    "        print(overlap)\n",
    "        area_truth_list.append(area_truth)\n",
    "        overlap_list.append(overlap)\n",
    "        overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.title(name_file_saver + \"- overlap = \"+ str(overlap) + \", Roi = \" + str(n))\n",
    "        plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSAMifOQY2QM"
   },
   "source": [
    "#### clahe, patch 512, step 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ci9Ghw0yY6jT",
    "outputId": "7bf7a4cf-9c9b-467d-d1e5-91a12618f229"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/New Dataset/cbis_test_clahe_multi_rois.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test CBIS CLAHE Predict - 512 step 128/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test CBIS CLAHE Predict - 512 step 128/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test CBIS CLAHE Predict - 512 step 128/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0).astype(np.float32)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # bit_depth = img.depth\n",
    "        # print(large_image.depth, roi.depth)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "        h,w = img.shape\n",
    "        patch_size = 512\n",
    "        step = 128\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img = img[0:new_img_h, 0: new_img_w]\n",
    "        roi = roi[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(roi)\n",
    "        # plt.show()\n",
    "\n",
    "        segmented_image = prediction(new_model_file, img, patch_size, step)\n",
    "\n",
    "        pred_img = np.zeros(roi.shape, dtype=\"uint8\")\n",
    "\n",
    "        h, w = segmented_image.shape\n",
    "        print(segmented_image.dtype)\n",
    "\n",
    "        plt.imshow(segmented_image)\n",
    "        plt.show()\n",
    "\n",
    "        pred_img[0:h, 0:w] = segmented_image\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(pred_img, 2000 )\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_FP = num_FP + n\n",
    "        num_P_list.append(n)\n",
    "        print(\"number FP  = \", n )\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, area_truth, overlap = cal_overlap_per_large_img(roi, y_pred_filter)\n",
    "        print(overlap)\n",
    "        area_truth_list.append(area_truth)\n",
    "        overlap_list.append(overlap)\n",
    "        overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.title(name_file_saver + \"- overlap = \"+ str(overlap) + \", Roi = \" + str(n))\n",
    "        plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtuFI3auxHuE"
   },
   "source": [
    "### Load model and predict INBREAST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvXuZf9G3H-o"
   },
   "source": [
    "#### INBreast patch 1024, step 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nX9ir3RXx5T8"
   },
   "outputs": [],
   "source": [
    "def cal_overlap(x,y,y_pred):\n",
    "  bitwise_and_roi_patch = np.logical_and(np.squeeze(y), np.squeeze(y_pred))\n",
    "  overlap = round(np.sum(bitwise_and_roi_patch) / np.sum(np.squeeze(y)), 2)\n",
    "  return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29P1ac_Px59k"
   },
   "outputs": [],
   "source": [
    "def show_image_roi_predict1_img(index, x, y, predict):\n",
    "    overlap = cal_overlap(x[index], y[index], predict)\n",
    "    print (overlap)\n",
    "\n",
    "    img = x[index]\n",
    "\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Image' + str(index))\n",
    "    plt.axis('off')\n",
    "\n",
    "    roi = np.squeeze(y[index])\n",
    "    plt.subplot(132)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(roi, 'gray')\n",
    "    plt.title('ROI ' + str(index))\n",
    "\n",
    "    roi_pred = np.squeeze(predict)\n",
    "    plt.subplot(133)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(roi_pred)\n",
    "    plt.title('ROI pred ' + str(index))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pFohbWshjza7",
    "outputId": "1046c5ac-f950-4400-f764-85231b9aa7d4"
   },
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCk5j8Ssj2kz"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/INBreast one roi 512.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pmpHle7kWdH"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/INBreast one roi 512.rar\"\n",
    "\n",
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'INBreast one roi 512', 'image_thresh_2800_one_roi_512', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'INBreast one roi 512', 'roi_thresh_2800_one_roi_512', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-DdNm8Xb3adQ",
    "outputId": "d943c774-fd9f-41b9-f125-52d6222ceecd"
   },
   "outputs": [],
   "source": [
    "print(len(test_x), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9279OjEul4YN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/img_mask_path_one_roi.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nK-dkiq-4VO4"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/img_mask_path_one_roi.csv'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file = os.path.basename(img_file)\n",
    "        print(name_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0).astype(np.float32)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        # bit_depth = img.depth\n",
    "        # print(large_image.depth, roi.depth)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "        h,w = img.shape\n",
    "        patch_size = 1024\n",
    "        step = 128\n",
    "        print(img.shape, roi.shape)\n",
    "\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img = img[0:new_img_h, 0: new_img_w]\n",
    "        roi = roi[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        print(img.shape, roi.shape)\n",
    "\n",
    "        plt.imsave(img_file, img, cmap='gray')\n",
    "        plt.imsave(roi_file, roi, cmap='gray')\n",
    "\n",
    "\n",
    "        # plt.imshow(img, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(roi, 'gray')\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeFSpYgG7Kpp"
   },
   "outputs": [],
   "source": [
    "def show_y_predict(randomlist, y, y_pred):\n",
    "  fg, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[0, i].imshow(np.squeeze(y[index]), 'gray')\n",
    "    ax[0, i].set_xlabel('y ' + str(index))\n",
    "    # print(y[index].shape)\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[1, i].imshow(np.squeeze(y_pred[index]), 'gray')\n",
    "    ax[1, i].set_xlabel('y_pred ' + str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ptjSFN4nd9-"
   },
   "outputs": [],
   "source": [
    "def prediction(model, large_image, patch_size, step):\n",
    "  patches = patchify(large_image, (patch_size, patch_size), step=step)  #Step=256 for 256 patches means no overlap\n",
    "\n",
    "  print(patches.shape)\n",
    "\n",
    "  redicted_patches = []\n",
    "  patches_input = []\n",
    "  for i in range(patches.shape[0]):\n",
    "    for j in range(patches.shape[1]):\n",
    "        # print(i,j)\n",
    "        single_patch = patches[i,j,:,:]\n",
    "        single_patch_input=np.expand_dims(single_patch, -1)\n",
    "        # single_patch = np.array(single_patch)\n",
    "        # print(single_patch.shape)\n",
    "        #Predict and threshold for values above 0.5 probability\n",
    "\n",
    "        single_patch_input = np.zeros((patch_size,patch_size,3), dtype=\"float32\")\n",
    "        single_patch_input[:,:,0] = single_patch\n",
    "        single_patch_input[:,:,1] = single_patch\n",
    "        single_patch_input[:,:,2] = single_patch\n",
    "\n",
    "        single_patch_input = cv.resize(single_patch_input, (256,256), cv.INTER_AREA)\n",
    "        single_patch_input = np.array(single_patch_input)\n",
    "        patches_input.append(single_patch_input)\n",
    "\n",
    "  patches_input = np.array(patches_input)\n",
    "\n",
    "  patches_prediction = (model.predict(patches_input) >= 0.5).astype(np.uint8)\n",
    "\n",
    "  # randomlist = random.sample(range(0, len(patches_prediction)),5)\n",
    "  # show_y_predict(randomlist, patches_input, patches_prediction)\n",
    "  # plt.show()\n",
    "\n",
    "  patches_prediction_resize = []\n",
    "  for i in patches_prediction:\n",
    "    i = cv.resize(i, (patch_size,patch_size), cv.INTER_AREA)\n",
    "    patches_prediction_resize.append(i)\n",
    "\n",
    "  predicted_patches_reshaped = np.reshape(patches_prediction_resize, (patches.shape[0], patches.shape[1], patch_size,patch_size) )\n",
    "  print(predicted_patches_reshaped.shape)\n",
    "\n",
    "  reconstructed_image = unpatchify(predicted_patches_reshaped, large_image.shape)\n",
    "  plt.imshow(np.squeeze(reconstructed_image), cmap='gray')\n",
    "  return reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-buAmUHnhIc"
   },
   "outputs": [],
   "source": [
    "def filter_FP(y_pred, thresh):\n",
    "  y_pred_filter = y_pred.copy()\n",
    "  kernel = np.ones((3,3),np.uint8)\n",
    "  y_pred_filter = cv.erode(y_pred_filter, kernel)\n",
    "\n",
    "  contours, _ = cv.findContours(y_pred_filter.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "  n = 0\n",
    "  for ct in contours:\n",
    "      contour_area = cv.contourArea(ct)\n",
    "      if (contour_area>= thresh):\n",
    "          n += 1\n",
    "      else:\n",
    "        y_pred_filter = cv.fillPoly(y_pred_filter, pts=[ct], color=(0, 0))\n",
    "  y_pred_filter =  cv.dilate(y_pred_filter, kernel)\n",
    "  return y_pred_filter, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VRFMr94n3TT"
   },
   "outputs": [],
   "source": [
    "def cal_overlap_per_large_img(roi, overlap_img):\n",
    "  bitwise_and_roi_pred = np.logical_and(overlap_img, roi)\n",
    "  area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "  overlap = round(area_truth / np.count_nonzero(roi), 4)*100\n",
    "  return bitwise_and_roi_pred, area_truth, overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k16eQJJkoJ48"
   },
   "outputs": [],
   "source": [
    "def draw_contour_pred_and_truth(large_image, pred, roi):\n",
    "  img_copy = large_image.copy()\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  cv.drawContours(img_copy, contours_roi , -1, (255,0,0), 3)\n",
    "  cv.drawContours(img_copy, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "  return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CEpX0jE2NSA"
   },
   "outputs": [],
   "source": [
    "def check_Left_Orient(img, roi):\n",
    "    left_nonzero = cv.countNonZero(img[:, 0:int(img.shape[1] / 2)])\n",
    "    right_nonzero = cv.countNonZero(img[:, int(img.shape[1] / 2):])\n",
    "\n",
    "    if (left_nonzero <= right_nonzero):\n",
    "            img = cv.flip(img, 1)\n",
    "            roi = cv.flip(roi, 1)\n",
    "\n",
    "    return img, roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MctLlOzyBbgz"
   },
   "outputs": [],
   "source": [
    "new_model_file = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Hx6LAvLvmgV0",
    "outputId": "9b0e8a92-2b19-4d16-e33c-942204b0767b"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/img_mask_path_one_roi.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test_INBreast_Predict - 1024 step 128/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test_INBreast_Predict - 1024 step 128/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test_INBreast_Predict - 1024 step 128/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0).astype(np.float32)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        # bit_depth = img.depth\n",
    "        # print(large_image.depth, roi.depth)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "        h,w = img.shape\n",
    "        patch_size = 1024\n",
    "        step = 128\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img = img[0:new_img_h, 0: new_img_w]\n",
    "        roi = roi[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        plt.imsave(img_file, img, cmap='gray')\n",
    "        plt.imsave(roi_file, roi, cmap='gray')\n",
    "\n",
    "        # print (img.dtype, roi.dtype)\n",
    "\n",
    "        # plt.imshow(img, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(roi, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        segmented_image = prediction(new_model_file, img, patch_size, step)\n",
    "\n",
    "        pred_img = np.zeros(roi.shape, dtype=\"uint8\")\n",
    "\n",
    "        h, w = segmented_image.shape\n",
    "        print(segmented_image.dtype)\n",
    "\n",
    "        plt.imshow(segmented_image)\n",
    "        plt.show()\n",
    "\n",
    "        pred_img[0:h, 0:w] = segmented_image\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(pred_img, 2000 )\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_FP = num_FP + n\n",
    "        num_P_list.append(n)\n",
    "        print(\"number FP  = \", n )\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, area_truth, overlap = cal_overlap_per_large_img(roi, y_pred_filter)\n",
    "        print(overlap)\n",
    "        area_truth_list.append(area_truth)\n",
    "        overlap_list.append(overlap)\n",
    "        overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.title(name_file_saver + \"- overlap = \"+ str(overlap) + \", Roi = \" + str(n))\n",
    "        plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBKl0tDaR3Xb"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "img = data[\"img\"]\n",
    "roi = data[\"roi\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test_INBreast_Predict - 1024 step 128/overlap_patch_1024_step_128.csv'\n",
    "df = pd.DataFrame({'img': img, 'roi': roi, 'overlap': overlap_list, 'area_truth_list': area_truth_list, 'num_FP': num_P_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-toASA_YIlf"
   },
   "source": [
    "#### INbreast patch 512, step 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-_qnFgXtYMw7",
    "outputId": "711c4651-b7bd-492e-fd5f-520cd33af366"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/img_mask_path_one_roi.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test_INBreast_Predict - 512 step 64/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test_INBreast_Predict - 512 step 64/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test_INBreast_Predict - 512 step 64/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0).astype(np.float32)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        # bit_depth = img.depth\n",
    "        # print(large_image.depth, roi.depth)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "        h,w = img.shape\n",
    "        patch_size = 512\n",
    "        step = 64\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img = img[0:new_img_h, 0: new_img_w]\n",
    "        roi = roi[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        plt.imsave(img_file, img, cmap='gray')\n",
    "        plt.imsave(roi_file, roi, cmap='gray')\n",
    "\n",
    "        # print (img.dtype, roi.dtype)\n",
    "\n",
    "        # plt.imshow(img, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(roi, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        segmented_image = prediction(new_model_file, img, patch_size, step)\n",
    "\n",
    "        pred_img = np.zeros(roi.shape, dtype=\"uint8\")\n",
    "\n",
    "        h, w = segmented_image.shape\n",
    "        print(segmented_image.dtype)\n",
    "\n",
    "        plt.imshow(segmented_image)\n",
    "        plt.show()\n",
    "\n",
    "        pred_img[0:h, 0:w] = segmented_image\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(pred_img, 2000 )\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_FP = num_FP + n\n",
    "        num_P_list.append(n)\n",
    "        print(\"number FP  = \", n )\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, area_truth, overlap = cal_overlap_per_large_img(roi, y_pred_filter)\n",
    "        print(overlap)\n",
    "        area_truth_list.append(area_truth)\n",
    "        overlap_list.append(overlap)\n",
    "        overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.title(name_file_saver + \"- overlap = \"+ str(overlap) + \", Roi = \" + str(n))\n",
    "        plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4roxXuztEWY"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "img = data[\"img\"]\n",
    "roi = data[\"roi\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test_INBreast_Predict - 512 step 64/overlap_patch_512_step_64.csv'\n",
    "df = pd.DataFrame({'img': img, 'roi': roi, 'overlap': overlap_list, 'area_truth_list': area_truth_list, 'num_FP': num_P_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APeYeBdv2dF2"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "#### INBreast patch 384, step 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmXjIQmQS2LX"
   },
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXqatqzkS5j-"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/INBreast one roi 512.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L03EtQYdTAGf"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'INBreast one roi 512', 'image_thresh_2800_one_roi_512', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'INBreast one roi 512', 'roi_thresh_2800_one_roi_512', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_9jxIZzTwc_"
   },
   "outputs": [],
   "source": [
    "def show_y_predict(randomlist, y, y_pred):\n",
    "  fg, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[0, i].imshow(np.squeeze(y[index]), 'gray')\n",
    "    ax[0, i].set_xlabel('y ' + str(index))\n",
    "    # print(y[index].shape)\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[1, i].imshow(np.squeeze(y_pred[index]), 'gray')\n",
    "    ax[1, i].set_xlabel('y_pred ' + str(index))\n",
    "\n",
    "def prediction(model, large_image, patch_size, step):\n",
    "  patches = patchify(large_image, (patch_size, patch_size), step=step)  #Step=256 for 256 patches means no overlap\n",
    "\n",
    "  print(patches.shape)\n",
    "\n",
    "  redicted_patches = []\n",
    "  patches_input = []\n",
    "  for i in range(patches.shape[0]):\n",
    "    for j in range(patches.shape[1]):\n",
    "        # print(i,j)\n",
    "        single_patch = patches[i,j,:,:]\n",
    "        single_patch_input=np.expand_dims(single_patch, -1)\n",
    "        # single_patch = np.array(single_patch)\n",
    "        # print(single_patch.shape)\n",
    "        #Predict and threshold for values above 0.5 probability\n",
    "\n",
    "        single_patch_input = np.zeros((patch_size,patch_size,3), dtype=\"float32\")\n",
    "        single_patch_input[:,:,0] = single_patch\n",
    "        single_patch_input[:,:,1] = single_patch\n",
    "        single_patch_input[:,:,2] = single_patch\n",
    "\n",
    "        single_patch_input = cv.resize(single_patch_input, (256,256), cv.INTER_AREA)\n",
    "        single_patch_input = np.array(single_patch_input)\n",
    "        patches_input.append(single_patch_input)\n",
    "\n",
    "  patches_input = np.array(patches_input)\n",
    "\n",
    "  patches_prediction = (model.predict(patches_input) >= 0.5).astype(np.uint8)\n",
    "\n",
    "  # randomlist = random.sample(range(0, len(patches_prediction)),5)\n",
    "  # show_y_predict(randomlist, patches_input, patches_prediction)\n",
    "  # plt.show()\n",
    "\n",
    "  patches_prediction_resize = []\n",
    "  for i in patches_prediction:\n",
    "    i = cv.resize(i, (patch_size,patch_size), cv.INTER_AREA)\n",
    "    patches_prediction_resize.append(i)\n",
    "\n",
    "  predicted_patches_reshaped = np.reshape(patches_prediction_resize, (patches.shape[0], patches.shape[1], patch_size,patch_size) )\n",
    "  print(predicted_patches_reshaped.shape)\n",
    "\n",
    "  reconstructed_image = unpatchify(predicted_patches_reshaped, large_image.shape)\n",
    "  plt.imshow(np.squeeze(reconstructed_image), cmap='gray')\n",
    "  return reconstructed_image\n",
    "\n",
    "def filter_FP(y_pred, thresh):\n",
    "  y_pred_filter = y_pred.copy()\n",
    "  kernel = np.ones((3,3),np.uint8)\n",
    "  y_pred_filter = cv.erode(y_pred_filter, kernel)\n",
    "\n",
    "  contours, _ = cv.findContours(y_pred_filter.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "  n = 0\n",
    "  for ct in contours:\n",
    "      contour_area = cv.contourArea(ct)\n",
    "      if (contour_area>= thresh):\n",
    "          n += 1\n",
    "      else:\n",
    "        y_pred_filter = cv.fillPoly(y_pred_filter, pts=[ct], color=(0, 0))\n",
    "  y_pred_filter =  cv.dilate(y_pred_filter, kernel)\n",
    "  return y_pred_filter, n\n",
    "\n",
    "def cal_overlap_per_large_img(roi, overlap_img):\n",
    "  bitwise_and_roi_pred = np.logical_and(overlap_img, roi)\n",
    "  area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "  overlap = round(area_truth / np.count_nonzero(roi), 4)*100\n",
    "  return bitwise_and_roi_pred, area_truth, overlap\n",
    "\n",
    "def draw_contour_pred_and_truth(large_image, pred, roi):\n",
    "  img_copy = large_image.copy()\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  cv.drawContours(img_copy, contours_roi , -1, (255,0,0), 3)\n",
    "  cv.drawContours(img_copy, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "  return img_copy\n",
    "\n",
    "def check_Left_Orient(img, roi):\n",
    "    left_nonzero = cv.countNonZero(img[:, 0:int(img.shape[1] / 2)])\n",
    "    right_nonzero = cv.countNonZero(img[:, int(img.shape[1] / 2):])\n",
    "\n",
    "    if (left_nonzero <= right_nonzero):\n",
    "            img = cv.flip(img, 1)\n",
    "            roi = cv.flip(roi, 1)\n",
    "\n",
    "    return img, roi\n",
    "\n",
    "def cal_overlap_per_large_img(roi, overlap_img):\n",
    "  bitwise_and_roi_pred = cv.bitwise_and(overlap_img, roi)\n",
    "  area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "  overlap = round(area_truth / np.count_nonzero(roi), 4)*100\n",
    "  return bitwise_and_roi_pred, area_truth, overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9umYPtsS3aLo"
   },
   "outputs": [],
   "source": [
    "new_model_file = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7Vrgd3VC2gsY",
    "outputId": "1f94ea0a-171b-400c-de20-cf2d7813adad"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/img_mask_path_one_roi.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test_INBreast_Predict - 384 step 64/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test_INBreast_Predict - 384 step 64/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test_INBreast_Predict - 384 step 64/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0).astype(np.float32)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        # bit_depth = img.depth\n",
    "        # print(large_image.depth, roi.depth)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "        h,w = img.shape\n",
    "        patch_size = 384\n",
    "        step = 64\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img = img[0:new_img_h, 0: new_img_w]\n",
    "        roi = roi[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        plt.imsave(img_file, img, cmap='gray')\n",
    "        plt.imsave(roi_file, roi, cmap='gray')\n",
    "\n",
    "        # print (img.dtype, roi.dtype)\n",
    "\n",
    "        # plt.imshow(img, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(roi, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        segmented_image = prediction(new_model_file, img, patch_size, step)\n",
    "\n",
    "        pred_img = np.zeros(roi.shape, dtype=\"uint8\")\n",
    "\n",
    "        h, w = segmented_image.shape\n",
    "        print(segmented_image.dtype)\n",
    "\n",
    "        plt.imshow(segmented_image)\n",
    "        plt.show()\n",
    "\n",
    "        pred_img[0:h, 0:w] = segmented_image\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(pred_img, 2000)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_FP = num_FP + n\n",
    "        num_P_list.append(n)\n",
    "        print(\"number FP  = \", n )\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, area_truth, overlap = cal_overlap_per_large_img(roi, y_pred_filter)\n",
    "        print(overlap)\n",
    "        area_truth_list.append(area_truth)\n",
    "        overlap_list.append(overlap)\n",
    "        overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.title(name_file_saver + \"- overlap = \"+ str(overlap) + \", Roi = \" + str(n))\n",
    "        plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ct_juUr1mgi_"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "img = data[\"img\"]\n",
    "roi = data[\"roi\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test_INBreast_Predict - 384 step 64/overlap.csv'\n",
    "df = pd.DataFrame({'img': img, 'roi': roi, 'overlap': overlap_list, 'area_truth_list': area_truth_list, 'num_FP': num_P_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqKj_Pnwh8vi"
   },
   "source": [
    "### combine patch 512 and 1024 - Test INBreast Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzRSP2LD1eup"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/INBreast one roi 512.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vDRjrW0Jh710"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "predict_patch_1024= sorted(glob(os.path.join(drive_path, 'Test_INBreast_Predict - 1024 step 128', 'original_predict', '*')))\n",
    "predict_patch_512= sorted(glob(os.path.join(drive_path, 'Test_INBreast_Predict - 512 step 64', 'original_predict', '*')))\n",
    "mask = sorted(glob(os.path.join(dataset_path, 'INBreast one roi 512', 'roi_thresh_2800_one_roi_512', '*')))\n",
    "img = sorted(glob(os.path.join(dataset_path, 'INBreast one roi 512', 'image_thresh_2800_one_roi_512', '*')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnOty4xSj8-z",
    "outputId": "7b6d6870-cd7f-41a1-9179-941630e11c21"
   },
   "outputs": [],
   "source": [
    "print(len(predict_patch_512), len(predict_patch_1024), len(mask), len(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-Pfw51_opin",
    "outputId": "4aa78cd8-6fc9-4050-b581-98ec1ad0d5cc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': img, 'mask' : mask  ,'predict_patch_512': predict_patch_512, 'predict_patch_1024': predict_patch_1024})\n",
    "df.to_csv ('/content/drive/MyDrive/Test_INBreast_combine_1024_512/combine_512_1024_predict.csv', index = False, header=True)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2ZWLLMiSyA5s",
    "outputId": "9851f305-7f65-4fa8-aa71-1a2aa249b00a"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Test_INBreast_combine_1024_512/combine_512_1024_predict.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test_INBreast_combine_1024_512/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test_INBreast_combine_1024_512/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test_INBreast_combine_1024_512/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['mask']\n",
    "\n",
    "        mask_patch_512_file = row['predict_patch_512']\n",
    "        mask_patch_1024_file = row['predict_patch_1024']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0)\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        mask_512 = cv.imread(mask_patch_512_file, 0)\n",
    "        mask_1024 = cv.imread(mask_patch_1024_file, 0)\n",
    "\n",
    "        combine = np.zeros(mask_1024.shape, dtype=np.uint8)\n",
    "\n",
    "        combine = np.logical_or(mask_512,mask_1024).astype(np.uint8)\n",
    "        # combine = np.array(combine)\n",
    "        plt.imshow(combine)\n",
    "        plt.title(name_file_saver + \" - combine predict \")\n",
    "        plt.show()\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000 )\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, combine, cmap='gray')\n",
    "\n",
    "        overlap_img, area_truth, overlap = cal_overlap_per_large_img(roi, combine)\n",
    "        print(overlap)\n",
    "        area_truth_list.append(overlap)\n",
    "\n",
    "        overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, combine, roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "        plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72DuR3bcmNV_"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "img = data[\"img\"]\n",
    "roi = data[\"mask\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test_INBreast_combine_1024_512/overlap_combine_patch_512_1024.csv'\n",
    "df = pd.DataFrame({'img': img, 'mask': roi, 'overlap': area_truth_list, 'num_FP': num_P_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiKjKdpUbSw7"
   },
   "source": [
    "###combine patch 384, 512 and 1024 - Test INBreast Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2TWisrAl-8z"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive/Test_INBreast_Predict - 384 step 64'\n",
    "draw_contour= sorted(glob(os.path.join(dataset_path, 'draw contour', '*')))\n",
    "original_predict= sorted(glob(os.path.join(dataset_path,'original_predict', '*')))\n",
    "overlap= sorted(glob(os.path.join(dataset_path,'overlap', '*')))\n",
    "\n",
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "draw_contour= sorted(glob(os.path.join(drive_path, 'Test_INBreast_Predict - 384 step 64', 'draw contour', '*')))\n",
    "original_predict= sorted(glob(os.path.join(drive_path, 'Test_INBreast_Predict - 384 step 64', 'original_predict', '*')))\n",
    "overlap= sorted(glob(os.path.join(drive_path, 'Test_INBreast_Predict - 384 step 64', 'overlap', '*')))\n",
    "\n",
    "\n",
    "print(draw_contour)\n",
    "\n",
    "for i, n in enumerate(draw_contour):\n",
    "        draw_contour_path = draw_contour[i]\n",
    "        original_predict_path = original_predict[i]\n",
    "        overlap_path = overlap[i]\n",
    "\n",
    "        draw_contour_img = cv.imread(draw_contour_path, 0).astype(np.uint8)\n",
    "        original_predict_img = cv.imread(original_predict_path, 0).astype(np.uint8)\n",
    "        overlap_img = cv.imread(overlap_path, 0).astype(np.uint8)\n",
    "\n",
    "        img = np.array(draw_contour_img)\n",
    "        h,w = img.shape\n",
    "        patch_size = 1024\n",
    "        step = 128\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        draw_contour_img = draw_contour_img[0:new_img_h, 0: new_img_w]\n",
    "        original_predict_img = original_predict_img[0:new_img_h, 0: new_img_w]\n",
    "        overlap_img = overlap_img[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        print(draw_contour_img.shape,original_predict_img.shape,overlap_img.shape)\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.show()\n",
    "\n",
    "        # plt.imsave(img_file, img, cmap='gray')\n",
    "        # plt.imsave(roi_file, roi, cmap='gray')\n",
    "        # plt.imsave(roi_file, roi, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjzcur36bYfE"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "predict_patch_1024= sorted(glob(os.path.join(drive_path, 'Test_INBreast_Predict - 1024 step 128', 'original_predict', '*')))\n",
    "predict_patch_512= sorted(glob(os.path.join(drive_path, 'Test_INBreast_Predict - 512 step 64', 'original_predict', '*')))\n",
    "predict_patch_384= sorted(glob(os.path.join(drive_path, 'Test_INBreast_Predict - 384 step 64', 'original_predict', '*')))\n",
    "\n",
    "mask = sorted(glob(os.path.join(dataset_path, 'INBreast one roi 512', 'roi_thresh_2800_one_roi_512', '*')))\n",
    "img = sorted(glob(os.path.join(dataset_path, 'INBreast one roi 512', 'image_thresh_2800_one_roi_512', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Njwvr96FblPb",
    "outputId": "61e7189e-0ac4-4c90-bfde-62aa85f1c646"
   },
   "outputs": [],
   "source": [
    "print(len(predict_patch_384),len(predict_patch_512), len(predict_patch_1024), len(mask), len(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTpntF26bnQT",
    "outputId": "7c4de3ab-c2e6-464f-cac0-701427b7ee7a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': img, 'mask' : mask  ,'predict_patch_384': predict_patch_384 ,'predict_patch_512': predict_patch_512, 'predict_patch_1024': predict_patch_1024})\n",
    "df.to_csv ('/content/drive/MyDrive/Test_INBreast_combine_1024_512_384/combine_384_512_1024_predict.csv', index = False, header=True)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NSZB9gd-cGmN",
    "outputId": "10f76243-3596-4b33-e594-d8825a9ee3bc"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Test_INBreast_combine_1024_512_384/combine_384_512_1024_predict.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test_INBreast_combine_1024_512_384/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test_INBreast_combine_1024_512_384/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test_INBreast_combine_1024_512_384/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['mask']\n",
    "\n",
    "        mask_patch_384_file = row['predict_patch_384']\n",
    "        mask_patch_512_file = row['predict_patch_512']\n",
    "        mask_patch_1024_file = row['predict_patch_1024']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0)\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        mask_512 = cv.imread(mask_patch_512_file, 0)\n",
    "        mask_1024 = cv.imread(mask_patch_1024_file, 0)\n",
    "\n",
    "        mask_384 = cv.imread(mask_patch_384_file, 0)\n",
    "        mask_384 = np.array(mask_384)\n",
    "        h,w = mask_512.shape\n",
    "\n",
    "        mask_384 = mask_384[0:h, 0: w]\n",
    "\n",
    "        combine = np.zeros(mask_1024.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(mask_384, mask_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, mask_1024).astype(np.uint8)\n",
    "        # combine = np.array(combine)\n",
    "        plt.imshow(combine)\n",
    "        plt.title(name_file_saver + \" - combine predict \")\n",
    "        plt.show()\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000 )\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, combine, cmap='gray')\n",
    "\n",
    "        overlap_img, area_truth, overlap = cal_overlap_per_large_img(roi, combine)\n",
    "        print(overlap)\n",
    "        area_truth_list.append(overlap)\n",
    "\n",
    "        overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, combine, roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "        plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7FItXdecnUm"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "img = data[\"img\"]\n",
    "roi = data[\"mask\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test_INBreast_combine_1024_512_384/overlap_combine_384_512_1024.csv'\n",
    "df = pd.DataFrame({'img': img, 'mask': roi, 'overlap': area_truth_list, 'num_FP': num_P_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQr5mnmWO9Js"
   },
   "source": [
    "### Final Solution for INBreast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fkk_xeGcRQRt"
   },
   "source": [
    "##### BB < 850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUUDkFwWPQsD",
    "outputId": "2c382bff-c71f-4b88-afe8-1da2a316351b"
   },
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hjMtKq2PVFk"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/INBreast roi 850 remove bkg.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8JS83YwPQOr"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'INBreast roi 850 remove bkg', 'image_thresh_2800_roi_850', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'INBreast roi 850 remove bkg', 'roi_thresh_2800_roi_850', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdErgPpgQm_t"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/img_mask_path_roi_850_remove_bkg.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RydPl2HYPbGj"
   },
   "outputs": [],
   "source": [
    "load_model_file = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QMGsWrl-PCqL"
   },
   "outputs": [],
   "source": [
    "def show_y_predict(randomlist, y, y_pred):\n",
    "  fg, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[0, i].imshow(np.squeeze(y[index]), 'gray')\n",
    "    ax[0, i].set_xlabel('y ' + str(index))\n",
    "    # print(y[index].shape)\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[1, i].imshow(np.squeeze(y_pred[index]), 'gray')\n",
    "    ax[1, i].set_xlabel('y_pred ' + str(index))\n",
    "\n",
    "def prediction(model, large_image, patch_size, step):\n",
    "  patches = patchify(large_image, (patch_size, patch_size), step=step)  #Step=256 for 256 patches means no overlap\n",
    "\n",
    "  print(patches.shape)\n",
    "\n",
    "  redicted_patches = []\n",
    "  patches_input = []\n",
    "  for i in range(patches.shape[0]):\n",
    "    for j in range(patches.shape[1]):\n",
    "        # print(i,j)\n",
    "        single_patch = patches[i,j,:,:]\n",
    "        single_patch_input=np.expand_dims(single_patch, -1)\n",
    "        # single_patch = np.array(single_patch)\n",
    "        # print(single_patch.shape)\n",
    "        #Predict and threshold for values above 0.5 probability\n",
    "\n",
    "        single_patch_input = np.zeros((patch_size,patch_size,3), dtype=\"float32\")\n",
    "        single_patch_input[:,:,0] = single_patch\n",
    "        single_patch_input[:,:,1] = single_patch\n",
    "        single_patch_input[:,:,2] = single_patch\n",
    "\n",
    "        single_patch_input = cv.resize(single_patch_input, (256,256), cv.INTER_AREA)\n",
    "        single_patch_input = np.array(single_patch_input)\n",
    "        patches_input.append(single_patch_input)\n",
    "\n",
    "  patches_input = np.array(patches_input)\n",
    "\n",
    "  patches_prediction = (model.predict(patches_input) >= 0.5).astype(np.uint8)\n",
    "\n",
    "  # randomlist = random.sample(range(0, len(patches_prediction)),5)\n",
    "  # show_y_predict(randomlist, patches_input, patches_prediction)\n",
    "  # plt.show()\n",
    "\n",
    "  patches_prediction_resize = []\n",
    "  for i in patches_prediction:\n",
    "    i = cv.resize(i, (patch_size,patch_size), cv.INTER_AREA)\n",
    "    patches_prediction_resize.append(i)\n",
    "\n",
    "  predicted_patches_reshaped = np.reshape(patches_prediction_resize, (patches.shape[0], patches.shape[1], patch_size,patch_size) )\n",
    "  print(predicted_patches_reshaped.shape)\n",
    "\n",
    "  reconstructed_image = unpatchify(predicted_patches_reshaped, large_image.shape)\n",
    "  plt.imshow(np.squeeze(reconstructed_image), cmap='gray')\n",
    "  return reconstructed_image\n",
    "\n",
    "def filter_FP(y_pred, thresh):\n",
    "  y_pred_filter = y_pred.copy()\n",
    "  kernel = np.ones((3,3),np.uint8)\n",
    "  y_pred_filter = cv.erode(y_pred_filter, kernel)\n",
    "\n",
    "  contours, _ = cv.findContours(y_pred_filter.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "  n = 0\n",
    "  for ct in contours:\n",
    "      contour_area = cv.contourArea(ct)\n",
    "      if (contour_area>= thresh):\n",
    "          n += 1\n",
    "      else:\n",
    "        y_pred_filter = cv.fillPoly(y_pred_filter, pts=[ct], color=(0, 0))\n",
    "  y_pred_filter =  cv.dilate(y_pred_filter, kernel)\n",
    "  return y_pred_filter, n\n",
    "\n",
    "\n",
    "def draw_contour_pred_and_truth(large_image, pred, roi):\n",
    "  img_copy = large_image.copy()\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  cv.drawContours(img_copy, contours_roi , -1, (255,0,0), 3)\n",
    "  cv.drawContours(img_copy, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "  return img_copy\n",
    "\n",
    "def check_Left_Orient(img, roi):\n",
    "    left_nonzero = cv.countNonZero(img[:, 0:int(img.shape[1] / 2)])\n",
    "    right_nonzero = cv.countNonZero(img[:, int(img.shape[1] / 2):])\n",
    "\n",
    "    if (left_nonzero <= right_nonzero):\n",
    "            img = cv.flip(img, 1)\n",
    "            roi = cv.flip(roi, 1)\n",
    "\n",
    "    return img, roi\n",
    "\n",
    "def cal_overlap_per_large_img(roi, overlap_img):\n",
    "  bitwise_and_roi_pred = cv.bitwise_and(overlap_img, roi)\n",
    "  area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "  overlap = round(area_truth / np.count_nonzero(roi), 4)*100\n",
    "  return bitwise_and_roi_pred, area_truth, overlap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYs3js_nMTgx"
   },
   "outputs": [],
   "source": [
    "def cal_overlaps_per_large_img(roi, pred, large_image):\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  img = large_image.copy()\n",
    "\n",
    "  overlap_list = []\n",
    "\n",
    "  roi_num_cnt = len(contours_roi)\n",
    "\n",
    "  if  roi_num_cnt == 1:\n",
    "       bitwise_and_roi_pred = cv.bitwise_and(pred, roi)\n",
    "       area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "       overlap = round(area_truth/np.count_nonzero(roi) * 100,2)\n",
    "       overlap_list.append(overlap)\n",
    "       print(\"overlap\", overlap)\n",
    "       cv.drawContours(img, contours_roi , -1, (255,0,0), 3)\n",
    "       cv.drawContours(img, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "       if overlap!=0:\n",
    "\n",
    "           contours_overlaps, _ = cv.findContours(bitwise_and_roi_pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "           c = max(contours_overlaps, key = cv.contourArea)\n",
    "\n",
    "           x, y, w, h = cv.boundingRect(c)\n",
    "\n",
    "           font = cv.FONT_HERSHEY_SIMPLEX\n",
    "           org = (x-10, y-10)\n",
    "           fontScale = 3\n",
    "           color = (0, 0, 255)\n",
    "           thickness = 2\n",
    "           text = str(overlap)\n",
    "           img = cv.putText(img, text, org, font, fontScale, color, thickness, cv.LINE_AA)\n",
    "\n",
    "  else:\n",
    "       bitwise_and_roi_pred = cv.bitwise_and(pred, roi)\n",
    "       for ct in contours_roi:\n",
    "            each_roi= np.zeros(roi.shape, dtype=\"uint8\")\n",
    "            each_roi = cv.fillPoly(each_roi, pts=[ct], color=(255, 255, 255))\n",
    "            # plt.imshow(each_roi, 'gray')\n",
    "            # plt.show()\n",
    "            cv.drawContours(img, ct , -1, (255,0,0), 3)\n",
    "\n",
    "            for ct_pred in contours_pred:\n",
    "                  each_pred = np.zeros(pred.shape, dtype=\"uint8\")\n",
    "                  each_pred = cv.fillPoly(each_pred, pts=[ct_pred], color=(255, 255, 255))\n",
    "\n",
    "                  # plt.imshow(each_pred, 'gray')\n",
    "                  # plt.show()\n",
    "\n",
    "                  bitwise_and_roi_pred_1 = cv.bitwise_and(each_pred, each_roi)\n",
    "\n",
    "                  area_truth = np.count_nonzero(bitwise_and_roi_pred_1)\n",
    "                  overlap = round(area_truth/np.count_nonzero(each_roi) *100,3)\n",
    "                  cv.drawContours(img, ct_pred, -1, (0,255,0), 3)\n",
    "\n",
    "                  # cv.drawContours(img, ct_pred , -1, (255,0,0), 3)\n",
    "\n",
    "                  if overlap>0:\n",
    "                       overlap_list.append(overlap)\n",
    "                       print(\"overlap\", overlap)\n",
    "\n",
    "                       x, y, w, h = cv.boundingRect(ct_pred)\n",
    "\n",
    "                      #  overlap_img_anotation = cv.fillPoly(overlap_img_anotation, pts=[ct_pred], color=(0, 0))\n",
    "\n",
    "                      #  overlap_img_anotation = ImageDraw.Draw(overlap_img_anotation)\n",
    "                      #  overlap_img_anotation.text((x, y), overlap, fill=(0 , 0, 255))\n",
    "                       font = cv.FONT_HERSHEY_SIMPLEX\n",
    "                       org = (x-10, y-20)\n",
    "                       fontScale = 3\n",
    "                       color = (0, 0, 255)\n",
    "                       thickness = 2\n",
    "                       text = str(overlap)\n",
    "                       img = cv.putText(img, text, org, font, fontScale, color, thickness, cv.LINE_AA)\n",
    "  # cv.imshow(overlap_img_anotation, 0)\n",
    "  plt.imshow(bitwise_and_roi_pred, 'gray')\n",
    "  plt.show()\n",
    "  # plt.imshow(img)\n",
    "  # plt.show()\n",
    "  return bitwise_and_roi_pred, overlap_list, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "id": "noM9819FCmcX",
    "outputId": "bf54c307-3fb3-40c9-b95f-ed37c320366d"
   },
   "outputs": [],
   "source": [
    "predict_path =\"/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/original_predict/20586908.png\"\n",
    "roi_path = \"/content/INBreast roi 850 remove bkg/roi_thresh_2800_roi_850/20586908.png\"\n",
    "image_path = \"/content/INBreast roi 850 remove bkg/image_thresh_2800_roi_850/20586908.png\"\n",
    "\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "h_r, w_r = roi.shape\n",
    "\n",
    "\n",
    "\n",
    "h_i, w_i = predict.shape\n",
    "\n",
    "if (h_i>=h_r) or (w_i>=w_r):\n",
    "      predict = predict[0:h_r, 0:w_r]\n",
    "else:\n",
    "      roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "bitwise_and_roi_pred, overlap_list, img_anotation = cal_overlaps_per_large_img(roi, predict, image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n__tfvO6SGHk"
   },
   "outputs": [],
   "source": [
    "def detect_roi_by_patch_size(img, load_model_file, patch_size, step):\n",
    "\n",
    "        h,w = img.shape\n",
    "\n",
    "        roi_detect= np.zeros(img.shape, dtype=\"uint8\")\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img_by_patch_size = img[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        segmented_image_by_patch_size = prediction(load_model_file, img_by_patch_size, patch_size , step)\n",
    "        h_1, w_1 = segmented_image_by_patch_size.shape\n",
    "        roi_detect[0:h_1, 0:w_1] = segmented_image_by_patch_size\n",
    "\n",
    "\n",
    "        return roi_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "M4odWY6bPMns",
    "outputId": "8d3aa0d8-e489-4fd4-951e-c8e0871d0311"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/img_mask_path_roi_850_remove_bkg.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/draw contour'\n",
    "overlap_anotation_path = '/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/overlap anotation'\n",
    "\n",
    "import time\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # roi = cv.imread(roi_file, 0)\n",
    "        # roi= np.uint8(roi)\n",
    "        # print(roi.shape)\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "        print(roi_predict_384.shape)\n",
    "        roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        if w_i < 1024:\n",
    "          roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "        else:\n",
    "          roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "\n",
    "        print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "\n",
    "        combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(roi_predict_384, roi_predict_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, roi_predict_1024).astype(np.uint8)\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        # overlap_img_anotation = 1*overlap_img_anotation\n",
    "        img_overlap_anotation_path = os.path.join(overlap_anotation_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_overlap_anotation_path, img_anotation_1, cmap='gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.show()\n",
    "        # print(overlap)\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        # overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        # combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "        # plt.imshow(img_draw_contour)\n",
    "\n",
    "        # plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "        # plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "\n",
    "print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JELqXW5Wbi4C"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "img = data[\"img\"]\n",
    "roi = data[\"roi\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/overlap_combine_98_images.csv'\n",
    "df = pd.DataFrame({'img': img, 'roi': roi, 'overlap': area_truth_list, 'num_FP': num_P_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnOt93MWIb-A",
    "outputId": "f64da802-20cd-4266-ac81-b83dd4fa69c7"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/img_mask_path_roi_850_remove_bkg.csv'\n",
    "predict_path = '/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/original_predict/'\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "iou_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        pred_path= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "\n",
    "        pred = cv.imread(pred_path, 0)\n",
    "        pred, n_1 = filter_FP(pred, 300)\n",
    "\n",
    "        iou = cal_iou(roi, pred)\n",
    "\n",
    "        print(iou)\n",
    "        iou_list.append(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhMx5X0zLyJd",
    "outputId": "85022502-c7bf-4bbd-eb89-d0316ed5ca85"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/img_mask_path_roi_850_remove_bkg.csv'\n",
    "predict_path = '/content/drive/MyDrive/Test_INBreast_Predict/Model without 2nd skip connection/original_predict/'\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "iou_list_2nd = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        pred_path= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "\n",
    "        pred = cv.imread(pred_path, 0)\n",
    "        pred, n_1 = filter_FP(pred, 300)\n",
    "\n",
    "        iou = cal_iou(roi, pred)\n",
    "\n",
    "        print(iou)\n",
    "        iou_list_2nd.append(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TpVannaIMyXZ",
    "outputId": "cdae0401-abb2-4792-9722-392213173cd7"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/img_mask_path_roi_850_remove_bkg.csv'\n",
    "predict_path = '/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/original_predict/'\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "dice_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        pred_path= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "\n",
    "        pred = cv.imread(pred_path, 0)\n",
    "        pred, n_1 = filter_FP(pred, 300)\n",
    "\n",
    "        dice = cal_dice(roi, pred)\n",
    "\n",
    "        print(dice)\n",
    "        dice_list.append(dice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGn3rUigPcud",
    "outputId": "cce94f34-91d1-42a3-d5c3-0e197898b985"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test Dataset INbreast/img_mask_path_roi_850_remove_bkg.csv'\n",
    "predict_path = '/content/drive/MyDrive/Test_INBreast_Predict/Model without 2nd skip connection/original_predict/'\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "dice_list_2nd = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        pred_path= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "\n",
    "        pred = cv.imread(pred_path, 0)\n",
    "        pred, n_1 = filter_FP(pred, 300)\n",
    "\n",
    "        dice = cal_dice(roi, pred)\n",
    "\n",
    "        print(dice)\n",
    "        dice_list_2nd.append(dice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTK3FkpXP3ZV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'standard_dice': dice_list, '2nd_dice': dice_list_2nd, 'standard_iou': iou_list,'2nd_iou': iou_list_2nd })\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/dice_iou_INBREAST.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ss3aLMDq_NGb"
   },
   "source": [
    "#### v trn c 2 m hnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "tFnK3EFn_sgz",
    "outputId": "4ba2b1fa-8bfd-44e9-95d1-0e6a287eb87b"
   },
   "outputs": [],
   "source": [
    "image_path = \"/content/INBreast roi 850 remove bkg/image_thresh_2800_roi_850/50995762.png\"\n",
    "roi_path = \"/content/INBreast roi 850 remove bkg/roi_thresh_2800_roi_850/50995762.png\"\n",
    "predict_path = \"/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/original_predict/50995762.png\"\n",
    "predict_2nd_path =\"/content/drive/MyDrive/Test_INBreast_Predict/Model without 2nd skip connection/original_predict/50995762.png\"\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Test DDSM 185 Images\"\n",
    "name_file_saver = os.path.basename(image_path)\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "predict_2nd = cv.imread(predict_2nd_path, 0).astype(np.uint8)\n",
    "predict_2nd = np.array(predict_2nd)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "large_image_roi_predict_pred_2nd_overlap(image, roi, predict, predict_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2GYb3mblbIC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "3Fphz_7mCNxj",
    "outputId": "82e5f56c-d493-4a72-cfea-de1ef51d1228"
   },
   "outputs": [],
   "source": [
    "image_path = \"/content/INBreast roi 850 remove bkg/image_thresh_2800_roi_850/24055445.png\"\n",
    "roi_path = \"/content/INBreast roi 850 remove bkg/roi_thresh_2800_roi_850/24055445.png\"\n",
    "predict_path = \"/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/original_predict/24055445.png\"\n",
    "predict_2nd_path =\"/content/drive/MyDrive/Test_INBreast_Predict/Model without 2nd skip connection/original_predict/24055445.png\"\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Test DDSM 185 Images\"\n",
    "name_file_saver = os.path.basename(image_path)\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "predict_2nd = cv.imread(predict_2nd_path, 0).astype(np.uint8)\n",
    "predict_2nd = np.array(predict_2nd)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "large_image_roi_predict_pred_2nd_overlap(image, roi, predict, predict_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "O8RyXIR9CV6O",
    "outputId": "28870d1b-c83b-4c13-d3c2-1469fed46da3"
   },
   "outputs": [],
   "source": [
    "image_path = \"/content/INBreast roi 850 remove bkg/image_thresh_2800_roi_850/50996406.png\"\n",
    "roi_path = \"/content/INBreast roi 850 remove bkg/roi_thresh_2800_roi_850/50996406.png\"\n",
    "predict_path = \"/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/original_predict/50996406.png\"\n",
    "predict_2nd_path =\"/content/drive/MyDrive/Test_INBreast_Predict/Model without 2nd skip connection/original_predict/50996406.png\"\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Test DDSM 185 Images\"\n",
    "name_file_saver = os.path.basename(image_path)\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "predict_2nd = cv.imread(predict_2nd_path, 0).astype(np.uint8)\n",
    "predict_2nd = np.array(predict_2nd)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "large_image_roi_predict_pred_2nd_overlap(image, roi, predict, predict_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "jtFblarnCdoW",
    "outputId": "756f9e0c-3e62-4824-8ac9-74404985458c"
   },
   "outputs": [],
   "source": [
    "image_path = \"/content/INBreast roi 850 remove bkg/image_thresh_2800_roi_850/50996352.png\"\n",
    "roi_path = \"/content/INBreast roi 850 remove bkg/roi_thresh_2800_roi_850/50996352.png\"\n",
    "predict_path = \"/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/original_predict/50996352.png\"\n",
    "predict_2nd_path =\"/content/drive/MyDrive/Test_INBreast_Predict/Model without 2nd skip connection/original_predict/50996352.png\"\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Test DDSM 185 Images\"\n",
    "name_file_saver = os.path.basename(image_path)\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "predict_2nd = cv.imread(predict_2nd_path, 0).astype(np.uint8)\n",
    "predict_2nd = np.array(predict_2nd)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "large_image_roi_predict_pred_2nd_overlap(image, roi, predict, predict_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "n9UyNeC0CoWo",
    "outputId": "bedfb479-afe2-40b1-9e85-32448d2ccf65"
   },
   "outputs": [],
   "source": [
    "image_path = \"/content/INBreast roi 850 remove bkg/image_thresh_2800_roi_850/20586986.png\"\n",
    "roi_path = \"/content/INBreast roi 850 remove bkg/roi_thresh_2800_roi_850/20586986.png\"\n",
    "predict_path = \"/content/drive/MyDrive/Test_INBreast_Predict/Standard Model/original_predict/20586986.png\"\n",
    "predict_2nd_path =\"/content/drive/MyDrive/Test_INBreast_Predict/Model without 2nd skip connection/original_predict/20586986.png\"\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Test DDSM 185 Images\"\n",
    "name_file_saver = os.path.basename(image_path)\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "predict_2nd = cv.imread(predict_2nd_path, 0).astype(np.uint8)\n",
    "predict_2nd = np.array(predict_2nd)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "large_image_roi_predict_pred_2nd_overlap(image, roi, predict, predict_2nd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47bJlqpQgrTC"
   },
   "source": [
    "###Final Solution for DDSM (NORMAL FROM DDSM, MULTITUMOR FROM TEST SET CBIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erU_89nEoUjg"
   },
   "source": [
    "####Test Patch (133 mass images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wRFG-4-Aocb-",
    "outputId": "19f36430-0961-41fe-cac8-9d0df94469fe"
   },
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQJrF6ffoo37"
   },
   "outputs": [],
   "source": [
    "!unrar x \"//content/drive/MyDrive/Mammo dataset/Test DDSM/Test_bkg.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YopEY2qouq6"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'Test_bkg', 'Patch', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'Test_bkg', 'Mask', '*')))\n",
    "\n",
    "test_y_pred= sorted(glob(os.path.join(drive_path, 'Mammo dataset', 'predict test 133 images patch', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtZo662eKPdH",
    "outputId": "1014356e-3223-4d87-8aea-728034a84260"
   },
   "outputs": [],
   "source": [
    "print(len(test_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvC1C7vIIa6X"
   },
   "outputs": [],
   "source": [
    "test_set_y_pred = np.ndarray(shape = (len(test_y_pred), 256, 256, 1), dtype= np.uint8)\n",
    "for n, file_path in enumerate(test_y_pred):\n",
    "        roi = cv.imread(file_path, 0)\n",
    "        roi = np.array(roi)\n",
    "        # roi = roi / 255.\n",
    "        # print(file_path)\n",
    "        roi = np.expand_dims(roi, -1)\n",
    "        test_set_y_pred[n] = roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcoNJgEYPxjY"
   },
   "outputs": [],
   "source": [
    "test_y_pred_2nd= sorted(glob(os.path.join(drive_path, 'Mammo dataset', 'predict test 133 images patch without 2 nd', '*')))\n",
    "test_set_y_pred_2nd = np.ndarray(shape = (len(test_y_pred_2nd), 256, 256, 1), dtype= np.uint8)\n",
    "for n, file_path in enumerate(test_y_pred_2nd):\n",
    "        roi = cv.imread(file_path, 0)\n",
    "        roi = np.array(roi)\n",
    "        # roi = roi / 255.\n",
    "        # print(file_path)\n",
    "        roi = np.expand_dims(roi, -1)\n",
    "        test_set_y_pred_2nd[n] = roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VS1ONWnFo7DN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test DDSM/patch_mask_Test_set_bkg.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9IP1gPMvp2tn"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_dataset = tf_dataset(test_x, test_y, batch = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7L5PAxbUqdV6"
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "for x, y in test_dataset:\n",
    "  if n in [1,5, 7, 8, 9]:\n",
    "  # print(x.shape, y.shape)\n",
    "  # print(y[0].dtype)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(x[0], cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(np.squeeze(y[0]), cmap='gray')\n",
    "    plt.show()\n",
    "  n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_e_7QhRr8bH"
   },
   "outputs": [],
   "source": [
    "def create_h5_file1(csv_file, h5_path, filename_x, filename_y):\n",
    "    col_list = [filename_x, filename_y]\n",
    "    df = pd.read_csv(csv_file, usecols=col_list)\n",
    "\n",
    "    x_train = df[filename_x]\n",
    "    y_train = df[filename_y]\n",
    "\n",
    "    # x_train.sort()\n",
    "    # y_train.sort()\n",
    "\n",
    "    IMG_HEIGHT=256\n",
    "    IMG_WIDTH=256\n",
    "    IMG_CHANNELS=3\n",
    "\n",
    "\n",
    "    # X_train = np.zeros((len(x_train), IMG_HEIGHT, IMG_WIDTH, 3), dtype= np.uint8)\n",
    "    X_train = np.ndarray(shape = (len(x_train), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.float32)\n",
    "    Y_train = np.ndarray(shape = (len(y_train), IMG_HEIGHT, IMG_WIDTH, 1), dtype= np.bool_)\n",
    "\n",
    "    x_train.sort_values()\n",
    "    y_train.sort_values()\n",
    "\n",
    "    for n, file_path in enumerate(x_train):\n",
    "        img = cv.imread(file_path)\n",
    "        img = np.array(img)\n",
    "        img = img / 255.\n",
    "        # print(file_path)\n",
    "        X_train[n] = img\n",
    "    #\n",
    "    for n, file_path in enumerate(y_train):\n",
    "        roi = cv.imread(file_path, 0)\n",
    "        roi = np.array(roi)\n",
    "        # roi = roi / 255.\n",
    "        # print(file_path)\n",
    "        roi = np.expand_dims(roi, -1)\n",
    "        Y_train[n] = roi\n",
    "\n",
    "    print(\"number of X examples = \" + str(X_train.shape[0]))\n",
    "    print(\"X shape: \" + str(X_train.shape))\n",
    "    print(\"Y shape: \" + str(Y_train.shape))\n",
    "    # print('pixel values in the mask are: ', np.unique(Y_train))\n",
    "\n",
    "    # return X_train, Y_train\n",
    "\n",
    "    with h5py.File(h5_path, 'w') as hf:\n",
    "        dset_x_train = hf.create_dataset('x', data=X_train, shape=(X_train.shape), compression='gzip',\n",
    "                                         chunks=True)\n",
    "        dset_y_train = hf.create_dataset('y', data=Y_train, shape=(Y_train.shape), compression='gzip',\n",
    "                                         chunks=True)\n",
    "    hf.close()\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-rg0k3es1pD",
    "outputId": "707b31f6-9af5-4053-c916-c9dc7a77d4cc"
   },
   "outputs": [],
   "source": [
    "create_h5_file1('/content/drive/MyDrive/Mammo dataset/Test DDSM/patch_mask_Test_set_bkg.csv', '/content/drive/MyDrive/Mammo dataset/Test DDSM/patch_mask_Test_set.h5','img', 'roi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bk0_xS42tO5P"
   },
   "outputs": [],
   "source": [
    "def read_h5_file(h5_path):\n",
    "    test_dataset = h5py.File(h5_path, \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"x\"][:])  # your train set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"y\"][:])\n",
    "\n",
    "    print(\"number of training examples = \" + str(test_set_x_orig.shape[0]))\n",
    "    print(\"X_train shape: \" + str(test_set_x_orig.shape))\n",
    "    print(\"Y_train shape: \" + str(test_set_y_orig.shape))\n",
    "\n",
    "    return test_set_x_orig, test_set_y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9QZikJxAniz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUxvZidAtkTk",
    "outputId": "31ef86f7-4b16-4409-cfaf-1f215ebf2e90"
   },
   "outputs": [],
   "source": [
    "test_set_x, test_set_y = read_h5_file('/content/drive/MyDrive/Mammo dataset/Test DDSM/patch_mask_Test_set.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9_PNVEpXxpL"
   },
   "outputs": [],
   "source": [
    "def show_roi_predict_dice(roi, predict, name):\n",
    "    dice = dice_coef(roi, predict )\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(roi,'gray')\n",
    "    plt.title('roi' + str(dice))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(predict, 'gray')\n",
    "    plt.title('pred ' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iNgp8FwxZXa"
   },
   "outputs": [],
   "source": [
    "def show_image_roi(randomlist, x, y, name):\n",
    "  fg, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "  fg.suptitle(name)\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[0, i].imshow(x[index], 'gray')\n",
    "    ax[0, i].set_xlabel('Image ' + str(i+1))\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[1, i].imshow(np.squeeze(y[index]), 'gray')\n",
    "    ax[1, i].set_xlabel('ROI ' + str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "zdj97RDZxhU6",
    "outputId": "c3e2b072-c244-42e3-e9b8-4684df4ee364"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, len(test_set_x)),5)\n",
    "print(randomlist)\n",
    "show_image_roi(randomlist, test_set_x, test_set_y,'Image and ROi of Train Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fzFnEf_pMWd"
   },
   "outputs": [],
   "source": [
    "load_model_file = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEtHMpR9uYpR",
    "outputId": "1cbc754d-046a-421a-bbec-99996336762f"
   },
   "outputs": [],
   "source": [
    "loss, acc= load_model_file.evaluate(test_dataset, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uJG4gb-vuyyP",
    "outputId": "33a197b7-8225-4a72-9207-1f2290d8277b"
   },
   "outputs": [],
   "source": [
    "preds_test = load_model_file.predict(test_set_x, verbose=1)\n",
    "test_set_y_pred = (preds_test > 0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rXW2dq4o_NN",
    "outputId": "06ceb909-30d8-4150-db45-23a1815e68af"
   },
   "outputs": [],
   "source": [
    "print(len(test_set_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTMos1oApBds",
    "outputId": "aa00e5e6-de16-4da1-e03f-08c8344d5aa6"
   },
   "outputs": [],
   "source": [
    "print(test_set_y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yu1XrQlRoMeX"
   },
   "outputs": [],
   "source": [
    "def dice_coef(groundtruth_mask, pred_mask):\n",
    "    intersect = np.sum(pred_mask*groundtruth_mask)\n",
    "    total_sum = np.sum(pred_mask) + np.sum(groundtruth_mask)\n",
    "    dice = np.mean(100*2*intersect/total_sum)\n",
    "    return round(dice, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnUnT_KVuLUY"
   },
   "outputs": [],
   "source": [
    "def compute_dice(label_img, pred_img, p_threshold=0.5):\n",
    "    p = pred_img.astype(np.float)\n",
    "    l = label_img.astype(np.float)\n",
    "    if p.max() > 127:\n",
    "        p /= 255.\n",
    "    if l.max() > 127:\n",
    "        l /= 255.\n",
    "\n",
    "    p = np.clip(p, 0, 1.0)\n",
    "    l = np.clip(l, 0, 1.0)\n",
    "    p[p > 0.5] = 1.0\n",
    "    p[p < 0.5] = 0.0\n",
    "    l[l > 0.5] = 1.0\n",
    "    l[l < 0.5] = 0.0\n",
    "    product = np.dot(l.flatten(), p.flatten())\n",
    "    dice_num = 2 * product + 1\n",
    "    pred_sum = p.sum()\n",
    "    label_sum = l.sum()\n",
    "    dice_den = pred_sum + label_sum + 1\n",
    "    dice_val = 100*dice_num / dice_den\n",
    "    return round(dice_val,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpPC_JIXlN5J"
   },
   "outputs": [],
   "source": [
    "def compute_dice_1(label_img, pred_img, p_threshold=0.5):\n",
    "    p = pred_img.astype(np.float)\n",
    "    l = label_img.astype(np.float)\n",
    "    if p.max() > 127:\n",
    "        p /= 255.\n",
    "    if l.max() > 127:\n",
    "        l /= 255.\n",
    "\n",
    "    p = np.clip(p, 0, 1.0)\n",
    "    l = np.clip(l, 0, 1.0)\n",
    "    p[p > 0.5] = 1.0\n",
    "    p[p < 0.5] = 0.0\n",
    "    l[l > 0.5] = 1.0\n",
    "    l[l < 0.5] = 0.0\n",
    "    product = ((l.flatten())*(p.flatten())).sum()\n",
    "    dice_num = 2 * product + 1\n",
    "    pred_sum = p.sum()\n",
    "    label_sum = l.sum()\n",
    "    dice_den = pred_sum + label_sum + 1\n",
    "    dice_val = 100*dice_num / dice_den\n",
    "    return round(dice_val,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZKXfHpwo4CG"
   },
   "outputs": [],
   "source": [
    "def compute_iou(label_img, pred_img, p_threshold=0.5):\n",
    "    p = pred_img.astype(np.float)\n",
    "    l = label_img.astype(np.float)\n",
    "    if p.max() > 127:\n",
    "        p /= 255.\n",
    "    if l.max() > 127:\n",
    "        l /= 255.\n",
    "\n",
    "    p = np.clip(p, 0, 1.0)\n",
    "    l = np.clip(l, 0, 1.0)\n",
    "    p[p > 0.5] = 1.0\n",
    "    p[p < 0.5] = 0.0\n",
    "    l[l > 0.5] = 1.0\n",
    "    l[l < 0.5] = 0.0\n",
    "\n",
    "    product = ((l.flatten())* (p.flatten())).sum()\n",
    "    iou_num = product + 1\n",
    "    pred_sum = p.sum()\n",
    "    label_sum = l.sum()\n",
    "    iou_den = pred_sum + label_sum + 1 - product\n",
    "    iou = 100*iou_num / iou_den\n",
    "\n",
    "    return round(iou,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llvrGQm8USDv",
    "outputId": "0488d973-cef6-4470-b35a-e8d32724530b"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/patch_mask_Test_set_bkg.csv'\n",
    "predict_path = \"/content/drive/MyDrive/Mammo dataset/predict test 133 images patch/\"\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "dice_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        pred_path= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "\n",
    "\n",
    "\n",
    "        roi = cv.imread(roi_file)\n",
    "        # roi_bw = cv.threshold(roi, 1 , 255, cv.THRESH_BINARY)\n",
    "        # roi = np.array(roi_bw)\n",
    "\n",
    "\n",
    "        pred = cv.imread(pred_path)\n",
    "        # kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        # pred = cv.morphologyEx(pred, cv.MORPH_CLOSE, kernel)\n",
    "        # pred = cv.morphologyEx(pred, cv.MORPH_OPEN, kernel)\n",
    "        # pred_bw = cv.threshold(pred, 1 , 255, cv.THRESH_BINARY)\n",
    "        # pred1 = np.array(pred_bw)\n",
    "\n",
    "        dice = compute_dice_1(roi, pred)\n",
    "\n",
    "        # pred_bw = cv.threshold(pred, 1 , 255, cv.THRESH_BINARY)\n",
    "        # show_roi_predict_dice(roi, pred, name_file_saver)\n",
    "\n",
    "\n",
    "        print(dice)\n",
    "        dice_list.append(dice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FiOcQQDCoaIB",
    "outputId": "3200a1ba-317b-4286-a6d7-0dab7d616264"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/patch_mask_Test_set_bkg.csv'\n",
    "predict_path = \"/content/drive/MyDrive/Mammo dataset/predict test 133 images patch without 2 nd/\"\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "dice_list_2nd = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        pred_path= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "\n",
    "        roi = cv.imread(roi_file)\n",
    "\n",
    "        pred = cv.imread(pred_path)\n",
    "\n",
    "        dice = compute_dice_1(roi, pred)\n",
    "\n",
    "        print(dice)\n",
    "        dice_list_2nd.append(dice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8GUf5OWtTSE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'standard': dice_list, '2nd': dice_list_2nd })\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/dice_cbis_test_set_bkg_5670_1.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbfJU0tuDcFI"
   },
   "outputs": [],
   "source": [
    "def show_image_roi_predict(randomlist, x, y, predict, name):\n",
    "  fg, ax = plt.subplots(3, 5, figsize=(20, 8))\n",
    "  fg.suptitle(name)\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[0, i].imshow(x[index], 'gray')\n",
    "    ax[0, i].set_xlabel('Image ' + str(index))\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[1, i].imshow(np.squeeze(y[index]), 'gray')\n",
    "    ax[1, i].set_xlabel('ROI ' + str(index))\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[2, i].imshow(np.squeeze(predict[index]), 'gray')\n",
    "    ax[2, i].set_xlabel('Predict ' + str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "cQPy_W_Kh9ZM",
    "outputId": "1010b243-9bc0-4fb0-d806-d71bc936b210"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 100),5)\n",
    "print(randomlist)\n",
    "show_image_roi_predict(randomlist, test_set_x, test_set_y, test_set_y_pred, 'Train set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "UkQLwhZ175FR",
    "outputId": "d5558260-f0e5-456d-f18e-7f7d155b9b0e"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 100),5)\n",
    "print(randomlist)\n",
    "show_image_roi_predict(randomlist, test_set_x, test_set_y, test_set_y_pred, 'Train set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "yE73NR0h78_x",
    "outputId": "455154bb-0a98-495a-e814-8ac675b88222"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 100),5)\n",
    "print(randomlist)\n",
    "show_image_roi_predict(randomlist, test_set_x, test_set_y, test_set_y_pred, 'Train set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "bepIaCwzDf7s",
    "outputId": "379c5670-9568-46d8-ca14-7b09c5c3230e"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 100),5)\n",
    "print(randomlist)\n",
    "show_image_roi_predict(randomlist, test_set_x, test_set_y, test_set_y_pred, 'Train set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEsWVUjctOCJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'overlap': overlap_list, 'iou': iou_list, 'dice': dice_list })\n",
    "df.to_csv ('/content/drive/MyDrive/test INBreast patch/overlap_iou_dice_inbreast_bb_850.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5x2nT_V287t6"
   },
   "outputs": [],
   "source": [
    "def cal_overlap(x,y,y_pred):\n",
    "  bitwise_and_roi_patch = np.logical_and(np.squeeze(y), np.squeeze(y_pred))\n",
    "  overlap = round(np.sum(bitwise_and_roi_patch) / np.sum(np.squeeze(y)), 2)\n",
    "  return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "tDqbvGnC8qRf",
    "outputId": "c6a8154f-e0b6-435a-dc0a-37f97d866d0b"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(42, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "zE9zuOdZMsaA",
    "outputId": "d90a873c-79ca-4990-81e0-d1055041e928"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(42, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "wRIwkjyX9AAC",
    "outputId": "2fead321-12d3-4d98-c5ac-f97c82f99b47"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(6, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "a9PIbIl0OU1m",
    "outputId": "2d6dd5b6-ac8c-4f98-f881-acf2d79d43bd"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(6, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "IwGkpLIJ9IZ6",
    "outputId": "b89527e8-9ab7-403e-cd65-27228e49dbcb"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(99, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "NV7LqN2SOY2F",
    "outputId": "40703d8f-56fc-49d8-c2e0-8c64a47c65fb"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(99, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "J8gPbxRh9LT3",
    "outputId": "1f4a80e9-f865-49b8-d8ca-29b1a9a7ae3b"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(8, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "hTCcMHZxOd0f",
    "outputId": "a268c362-b9e1-472a-c662-acd59346ce26"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(8, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "WEkdm2Zb9a_n",
    "outputId": "43d65006-bb78-4d7b-e601-58b831ed098e"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(13, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "5Z3MQPMF9jj6",
    "outputId": "9e71de8c-9924-4f90-8b39-18252ab1583c"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(30, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "xdziVXW1OqEt",
    "outputId": "0891c43f-33ca-439a-b27c-f643b9aa654c"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(30, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "mAXMlgdLTcOa",
    "outputId": "5169c9b5-de62-4e02-d01f-880f1c254e5e"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(7, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "vm5orIDqOumh",
    "outputId": "822f7297-4f93-49f0-b7dc-fb871077d933"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(9, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "jrsMe-s0Ox1F",
    "outputId": "83617fb5-c44a-4d04-de4f-65477b0493fc"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(29, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "qL5KNhIZO3lu",
    "outputId": "214e874c-2737-488e-ae29-ff66ffa80aec"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(153, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "AeEPnRz7O5wv",
    "outputId": "e8b21af9-8cb3-4275-e154-77cc0c408ddc"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(248, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "UaJHIbxoO8f-",
    "outputId": "0ad32cf6-e136-4221-c912-0ec701e6bddb"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(55, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "Q-PAQxe3PAWN",
    "outputId": "a4282928-c7f3-45fc-9ddf-1624ce7ecf6a"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(75, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "hmHsyUiyPErF",
    "outputId": "f2011fdc-5eaf-4d9b-a9ad-74fc0c74b680"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(149, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "iXh2sPq6PGpw",
    "outputId": "ec249787-2f0b-4621-9923-eb6a454f610a"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(26, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "VxmtTdDhPJqw",
    "outputId": "94e48cdd-2a23-47d4-cc58-f886826b3387"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(133, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "pyY5YxlhPMGF",
    "outputId": "ef436607-3287-4718-fb1f-a317a975ba64"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(149, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "lId2OZGXPOKl",
    "outputId": "aff20c32-c8d1-4a7f-8104-c512ac660a6c"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(168, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "VmrLaz28PUqe",
    "outputId": "9dff98c2-48bf-48c7-dec9-7f96a8ac786a"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(30, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "Eivgg8MyPWk8",
    "outputId": "4b319719-84a4-43bc-b719-3bebf2e87a2e"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1798, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "66YwlcngPZSb",
    "outputId": "5615b93d-cc7a-4b31-c300-7835032f4dbe"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1065, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "mSYKX1KPPbU5",
    "outputId": "7ee95e18-1d37-421e-ccf6-1fc8cd8f8fdc"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(5118, test_set_x, test_set_y, test_set_y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "AiJxQTpBPgxO",
    "outputId": "5bb43522-8ceb-48d9-c14b-b561b38a618a"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(989, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "TRoDCNBBPjT3",
    "outputId": "1ad3b954-e3f1-487c-95df-626b9aa994d5"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1208, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "OcULVB2-PmlW",
    "outputId": "65e621b7-e274-4991-b5ae-aa4ff1e9170a"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1065, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kC4ZNP5n9nQa",
    "outputId": "9ae1824f-2bba-4aad-b8c0-b6eadbb5a796"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 5470),5)\n",
    "\n",
    "for i, index in enumerate(randomlist):\n",
    "    show_image_roi_predict1_img(index, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2XY_VQ5N-j6i",
    "outputId": "ed0d1a80-0e21-458c-a5f1-c40b26878912"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 5470),5)\n",
    "\n",
    "for i, index in enumerate(randomlist):\n",
    "    show_image_roi_predict1_img(index, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9mfMjkRn-n1h",
    "outputId": "8031a6ca-2d70-4fe6-d179-2178fb59b7a3"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 5470),5)\n",
    "\n",
    "for i, index in enumerate(randomlist):\n",
    "    show_image_roi_predict1_img(index, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "J1sBTL_a-tOG",
    "outputId": "032f12e2-d164-49ad-f782-467d88ed2342"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 5470),5)\n",
    "\n",
    "for i, index in enumerate(randomlist):\n",
    "    show_image_roi_predict1_img(index, test_set_x, test_set_y, test_set_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IV4YdWmbQwDN"
   },
   "source": [
    "####Calculate overlap test set pacth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quhp_p-DQxJ2"
   },
   "outputs": [],
   "source": [
    "def image_roi_predict_overlap(index, x, y, predict):\n",
    "    overlap = cal_overlap(x[index], y[index], predict[index])\n",
    "    print (overlap)\n",
    "\n",
    "    roi = np.squeeze(y[index])\n",
    "    plt.subplot(131)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(roi, 'gray')\n",
    "    plt.title('ROI ' + str(index))\n",
    "    image_8bit = np.uint8(roi * 255)\n",
    "    _, binarized = cv.threshold(image_8bit, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_roi, hierarchy = cv.findContours(binarized, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    roi_pred = np.squeeze(predict[index])\n",
    "    plt.subplot(132)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(roi_pred)\n",
    "    plt.title('ROI pred ' + str(index))\n",
    "    image_8bit = np.uint8(roi_pred * 255)\n",
    "    _, binarized = cv.threshold(image_8bit, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_pred, hierarchy = cv.findContours(binarized,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    img = x[index]\n",
    "    img_copy = img.copy()\n",
    "    cv.drawContours(img_copy, contours_roi,-1,(255,0,0),2)\n",
    "    cv.drawContours(img_copy, contours_pred,-1, (0,255,0), 2)\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(img_copy)\n",
    "    plt.title('Image' + str(index))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUwiDJGiQ1J8"
   },
   "outputs": [],
   "source": [
    "def cal_overlap_label(x,y,y_pred):\n",
    "  overlap = 0\n",
    "  label_y = 0\n",
    "  label_y_pred = 0\n",
    "  num_y = np.sum(np.squeeze(y))\n",
    "\n",
    "\n",
    "  kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "  y_pred_filter = cv.morphologyEx(np.squeeze(y_pred), cv.MORPH_CLOSE, kernel)\n",
    "  y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "  num_y_pred = np.sum(y_pred_filter)\n",
    "\n",
    "  bitwise_and_roi_patch = np.logical_and(np.squeeze(y), np.squeeze(y_pred_filter))\n",
    "\n",
    "\n",
    "  if (num_y == 0) & (num_y_pred == 0):\n",
    "    label_y = 0\n",
    "    label_y_pred = 0\n",
    "    overlap = 1.0\n",
    "  elif (num_y == 0) & (num_y_pred != 0):\n",
    "    label_y = 0\n",
    "    label_y_pred = 1\n",
    "    overlap = 0\n",
    "  elif (num_y != 0) & (num_y_pred == 0):\n",
    "    label_y = 1\n",
    "    label_y_pred = 0\n",
    "    overlap = 0\n",
    "  else:\n",
    "    overlap = round(np.sum(bitwise_and_roi_patch) / np.sum(np.squeeze(y)), 2)\n",
    "    if overlap>= 0.5:\n",
    "          label_y = 1\n",
    "          label_y_pred = 1\n",
    "    else:\n",
    "          label_y = 1\n",
    "          label_y_pred = 0\n",
    "\n",
    "  return overlap, label_y, label_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYOAmLMiQ2PV"
   },
   "outputs": [],
   "source": [
    "overlaps = []\n",
    "labels_y = []\n",
    "labels_y_pred = []\n",
    "for i in range(len(test_set_y)):\n",
    "  x = test_set_x[i]\n",
    "  y = test_set_y[i]\n",
    "  y_pred = test_set_y_pred[i]\n",
    "  overlap, label_y, label_y_pred = cal_overlap_label(x,y,y_pred)\n",
    "  overlaps.append(overlap)\n",
    "  labels_y.append(label_y)\n",
    "  labels_y_pred.append(label_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SD4C069lQ9FN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'overlap': overlaps, 'label_y': labels_y, 'label_y_pred': labels_y_pred })\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test DDSM/overlap_Test_set_bkg_label_1.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyE65ZqNRB_g"
   },
   "outputs": [],
   "source": [
    "def create_label(data):\n",
    "  y_label = []\n",
    "  for i in range(len(data)):\n",
    "    patch_pixel_non_zero = np.sum(np.squeeze(data[i]))\n",
    "    if (patch_pixel_non_zero == 0):\n",
    "      y_label.append(0)\n",
    "    else:\n",
    "      y_label.append(1)\n",
    "  print(len(y_label))\n",
    "  return y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iESPnBtWRGnq",
    "outputId": "d443ec3b-a5b1-48ab-e27d-8f04944f0a49"
   },
   "outputs": [],
   "source": [
    "test_set_y_label = create_label(test_set_y)\n",
    "test_set_y_pred_label = create_label(test_set_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "2vo0XWX-RIHM",
    "outputId": "45dff416-ec29-4151-e676-4916530408b6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import seaborn as sn\n",
    "cm = confusion_matrix(test_set_y_label, test_set_y_pred_label) # rows = truth, cols = prediction\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title('confusion matrix - Test data')\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UK0R_RJwROQe",
    "outputId": "5c79a4f1-0d1e-4f12-a8d3-ad4d7daf2c2f"
   },
   "outputs": [],
   "source": [
    "total1=sum(sum(cm))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1=(cm[0,0]+cm[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdUd12pgXXNF"
   },
   "outputs": [],
   "source": [
    "def cal_overlap_label(x,y,y_pred):\n",
    "  overlap = 0\n",
    "  label_y = 0\n",
    "  label_y_pred = 0\n",
    "  num_y = np.sum(np.squeeze(y))\n",
    "\n",
    "\n",
    "  kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "  y_pred_filter = cv.morphologyEx(np.squeeze(y_pred), cv.MORPH_CLOSE, kernel)\n",
    "  y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "  num_y_pred = np.sum(y_pred_filter)\n",
    "\n",
    "  bitwise_and_roi_patch = np.logical_and(np.squeeze(y), np.squeeze(y_pred_filter))\n",
    "\n",
    "  if (num_y == 0) & (num_y_pred == 0):\n",
    "    label_y = 0\n",
    "    label_y_pred = 0\n",
    "    overlap = 1.0\n",
    "  elif (num_y == 0) & (num_y_pred != 0):\n",
    "    label_y = 0\n",
    "    label_y_pred = 1\n",
    "    overlap = 0\n",
    "  elif (num_y != 0) & (num_y_pred == 0):\n",
    "    label_y = 1\n",
    "    label_y_pred = 0\n",
    "    overlap = 0\n",
    "  else:\n",
    "    overlap = round(np.sum(bitwise_and_roi_patch) / np.sum(np.squeeze(y)), 2)\n",
    "    if overlap>= 0.5:\n",
    "          label_y = 1\n",
    "          label_y_pred = 1\n",
    "    else:\n",
    "          label_y = 1\n",
    "          label_y_pred = 0\n",
    "\n",
    "  return overlap, label_y, label_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RggFJ141RQHD"
   },
   "outputs": [],
   "source": [
    "def create_label_map(y, y_pred):\n",
    "  y_label = []\n",
    "  y_pred_label = []\n",
    "\n",
    "  for i in range(len(y)):\n",
    "    patch_pixel_non_zero_y = np.sum(np.squeeze(y[i]))\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "    y_pred_filter = cv.morphologyEx(np.squeeze(y_pred[i]), cv.MORPH_CLOSE, kernel)\n",
    "    y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "    patch_pixel_non_zero_y_pred = np.sum(y_pred_filter)\n",
    "\n",
    "    if (patch_pixel_non_zero_y == 0)& (patch_pixel_non_zero_y_pred == 0):\n",
    "      y_label.append(0)\n",
    "      y_pred_label.append(0)\n",
    "    elif (patch_pixel_non_zero_y == 0)& (patch_pixel_non_zero_y_pred != 0):\n",
    "      y_label.append(0)\n",
    "      y_pred_label.append(1)\n",
    "\n",
    "    elif (patch_pixel_non_zero_y != 0)& (patch_pixel_non_zero_y_pred == 0):\n",
    "      y_label.append(1)\n",
    "      y_pred_label.append(0)\n",
    "\n",
    "    else:\n",
    "      bitwise_and_roi_patch = np.logical_and(np.squeeze(y), np.squeeze(y_pred))\n",
    "      overlap = round(np.sum(bitwise_and_roi_patch) / np.sum(np.squeeze(y)), 2)\n",
    "\n",
    "      if overlap >= 0.5:\n",
    "         y_label.append(1)\n",
    "         y_pred_label.append(1)\n",
    "      else:\n",
    "         y_label.append(1)\n",
    "         y_pred_label.append(0)\n",
    "\n",
    "  return y_label, y_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XN4fFTefRWs2"
   },
   "outputs": [],
   "source": [
    "y_label, y_pred_label = create_label_map(test_set_y,test_set_y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "aF8Jg4aERZ64",
    "outputId": "d36215c9-dfec-49a1-f6eb-819db3ec677a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import seaborn as sn\n",
    "cm = confusion_matrix(y_label, y_pred_label) # rows = truth, cols = prediction\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title('confusion matrix - Test data')\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlGGQb_ORcu2",
    "outputId": "99d9dc21-3a7a-4471-96bf-a2fcafc7ff8e"
   },
   "outputs": [],
   "source": [
    "total1=sum(sum(cm))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1=(cm[0,0]+cm[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqF0H3HsR1MF",
    "outputId": "2f8e5456-991c-4dab-93ba-b87d3f2a1a71"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_pred_2 = test_set_y_pred.ravel()\n",
    "# test_set_y_2 = test_set_y.ravel()\n",
    "cm=confusion_matrix(labels_y, labels_y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "4Un8PzupWx6t",
    "outputId": "54d0ad5e-26ba-468a-c5a2-f94f4a3f248d"
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title('confusion matrix - Test data')\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmyrb1UGW7AN",
    "outputId": "69bd1383-f1f6-46a3-dffb-1cbcfe992a13"
   },
   "outputs": [],
   "source": [
    "total1=sum(sum(cm))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1=(cm[0,0]+cm[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1KJD4fGetEs"
   },
   "outputs": [],
   "source": [
    "def image_roi_predict_pred_2nd_overlap(index, x, y, predict, pred_2nd):\n",
    "    # overlap = cal_overlap(x[index], y[index], predict[index])\n",
    "    # print (overlap)\n",
    "\n",
    "    roi = np.squeeze(y[index])\n",
    "    # print(roi.dtype)\n",
    "    image_8bit = np.uint8(roi*255)\n",
    "    _, binarized = cv.threshold(image_8bit, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_roi, hierarchy = cv.findContours(binarized, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "    y_pred_filter = cv.morphologyEx(np.squeeze(predict[index]), cv.MORPH_CLOSE, kernel)\n",
    "    y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "    # roi_pred = np.squeeze(predict[index])\n",
    "    # print(roi_pred.dtype)\n",
    "    # image_8bit = np.uint8(roi_pred*255)\n",
    "    _, binarized = cv.threshold(y_pred_filter, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_pred, hierarchy = cv.findContours(binarized,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    y_pred_filter_2nd = cv.morphologyEx(np.squeeze(pred_2nd[index]), cv.MORPH_CLOSE, kernel)\n",
    "    y_pred_filter_2nd = cv.morphologyEx(y_pred_filter_2nd, cv.MORPH_OPEN, kernel)\n",
    "    # roi_pred_2nd = np.squeeze(pred_2nd[index])\n",
    "    # print(roi_pred_2nd.dtype)\n",
    "    # image_8bit_2nd = np.uint8(roi_pred_2nd*255)\n",
    "    _, binarized_2nd = cv.threshold(y_pred_filter_2nd, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_pred_2nd, hierarchy = cv.findContours(binarized_2nd,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    img = x[index]\n",
    "    img_copy = img.copy()\n",
    "    cv.drawContours(img_copy, contours_roi,-1,(255,0,0),2)\n",
    "    cv.drawContours(img_copy, contours_pred,-1, (0,255,0), 2)\n",
    "    cv.drawContours(img_copy, contours_pred_2nd,-1, (0,0,255), 2)\n",
    "    plt.imshow(img_copy)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image' + str(index))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "Jpc9kBF0flG6",
    "outputId": "8ffdfa27-f42c-4510-d4ff-c8c7fa58819a"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(6, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "ZwtTER2OkNnV",
    "outputId": "810c89e4-31fa-4173-aa61-bafd24a4d01c"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(38, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "ojdau_zGkVV2",
    "outputId": "faaa05df-5222-410c-8d69-8ea4d70459a9"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(69, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "E2Ct-wZNkbcM",
    "outputId": "c46e9bd3-7944-4584-d82d-3b13f500614b"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(112, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "MabU3icvkkpF",
    "outputId": "538bd129-b7ea-4a18-e65a-6ea9c839b351"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(158, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "2pasErOhkoiP",
    "outputId": "177498ea-9e51-415f-a7a4-4d617c85e3f9"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(286, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "it1MupdIlZJn",
    "outputId": "6e80f4ed-4e9d-40a1-85af-bf5b6347bdcb"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(284, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "Tn1S-rpIlhIO",
    "outputId": "e4625e5d-0db6-4736-ae90-ab5ee3683246"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(359, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "nqVaDhiyloxx",
    "outputId": "f3fec089-62c0-4b21-d1b8-0da749fb092e"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(365, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "foexD1_0lrO1",
    "outputId": "d14b3177-79b2-41ab-f63a-37f2d7e5d123"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(426, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "UvlrnkaSlv1y",
    "outputId": "573be233-567b-4b68-8433-47d1d7d5e3c6"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(481, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "4OjPhdo_l9Y-",
    "outputId": "be732251-e4be-4575-b19f-0b2bdbaed4c6"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(495, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "3FFl0nwFmy13",
    "outputId": "5238161a-6db1-4f7f-b562-6feb927a7d0f"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(522, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "19QK4ss-m3hy",
    "outputId": "a1454f07-2a40-45de-e229-cb6445c43438"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(594, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "HOl0FiVl6OUi",
    "outputId": "c1e0b1b3-62be-4592-fb5d-1497e3c6f8f3"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(42, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "MpLvoD5q6XXZ",
    "outputId": "c32880ba-f488-4d03-e805-1bba8860ad43"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(1789, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "dbbfUMJ56Ym3",
    "outputId": "a0617ee6-61a6-4aed-8801-78fd25c8a544"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(1065, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "KoOETmyr6cDL",
    "outputId": "9db966dd-89dd-49ec-a4cd-5cc3859ec452"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(989, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "aEG7gt1C6kQs",
    "outputId": "8f5ab08c-567d-4ca7-e3d2-95d9527b3942"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(3513, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "KokkW_BV6lqj",
    "outputId": "a98b4f4c-82b4-4a00-bed6-c88481b55da6"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(1310, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "anTAoNJtFmKI",
    "outputId": "a48cfff3-3241-47e5-913e-5315d4ad1fc8"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(4027, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "hd08nI5iFqtb",
    "outputId": "cd203b77-8682-4f61-e527-3783ecd855b4"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(4151, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "q2m6cIO9FzXj",
    "outputId": "d481a3c4-b4b3-4526-8cb1-7686f455b161"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(2085, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "PIedggeD69-c",
    "outputId": "596ed767-7f14-431d-a460-c847315a7066"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(4275, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "H3OiysW1GLPv",
    "outputId": "3e5b7932-8a31-457e-c376-ae5e3a5ca0f6"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(4242, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "KnOMCmSEGEZ6",
    "outputId": "2111c233-6fee-4560-e451-92514e1156ec"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(2034, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "01m-P3wbGVd3",
    "outputId": "2a463691-504b-46bb-eefc-7460d43bf3f5"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(575, test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TRzGPOuqHOuK",
    "outputId": "055253c0-1660-41ae-a979-d55cfc34ce7e"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 5470),5)\n",
    "\n",
    "for i, index in enumerate(randomlist):\n",
    "  image_roi_predict_pred_2nd_overlap(index,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mbDgmLJeIkrx",
    "outputId": "a4571dbe-0218-4b56-b742-6318bae3eda2"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 5470),5)\n",
    "\n",
    "for i, index in enumerate(randomlist):\n",
    "  image_roi_predict_pred_2nd_overlap(index,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FCTA3te6Ix_h",
    "outputId": "c05cc15b-b752-41b5-929a-26369285a179"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 5470),5)\n",
    "\n",
    "for i, index in enumerate(randomlist):\n",
    "  image_roi_predict_pred_2nd_overlap(index,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "L5MUrEPpI6GL",
    "outputId": "0f575f49-3af6-4011-fcb8-b4bbe2ee03d6"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(149,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "YLn2DyoyJA8x",
    "outputId": "6af18658-b5b2-4f4d-bce4-2b596f435c93"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(133,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "xTWuBcsoJMFx",
    "outputId": "67882c1e-ed45-4c24-b18c-f28372448b2f"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(26,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "G6Po97qRhXjd",
    "outputId": "f261d9ed-7434-41fd-e2db-a424c19761e5"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(4986,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "9ZrXhgI0jMEx",
    "outputId": "6bca856b-a84a-43d4-8653-d7606a8e3f1a"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(4027,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "83MtYGFUk6pm",
    "outputId": "3bdf2bf1-b207-4f94-b4f8-868b7101e824"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(11,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "uVTWA7gBllXF",
    "outputId": "47e1b407-d983-49fd-8750-87c4d8777ffc"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(51,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "5xjUFVhfl-G6",
    "outputId": "f72f2d39-fb77-4b75-df1d-67869486e015"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(54,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "d-LbShURmREU",
    "outputId": "efad3133-9332-48a7-d6aa-e716b4ad7863"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(70,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "OtHJS6tUmf8a",
    "outputId": "80b4e716-ebb1-4e5d-b2d7-8ebda1d61b99"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(129,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "IVzYvRPhnBHi",
    "outputId": "1c364b68-f5f1-468d-b5e0-816356e55bf4"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(152,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "CZ9_1ecMnPq4",
    "outputId": "a3e6dd50-eefb-4588-f733-c26b4777a707"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(162,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "VSQ1Gd5jnjfC",
    "outputId": "1fa1ac22-0476-4f3d-8d79-fe3fbeebdf0c"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(275,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "W64gED_ZnyI9",
    "outputId": "a486c6fa-7bab-4ebc-a5b4-8b1b105ca050"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(311,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "SFym_2_1oyIz",
    "outputId": "1895e989-f9e0-4815-8f76-4e998600cec8"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(762,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "0WZ_9q-TpOF8",
    "outputId": "c12ed425-2e28-435e-e4d8-b2a43c66d885"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(771,\n",
    "  test_set_x, test_set_y, test_set_y_pred, test_set_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6I2HE1StmrB3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOWong9UyQZe"
   },
   "source": [
    "#### plot ROC, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3tsycTP0Hqb"
   },
   "outputs": [],
   "source": [
    "train_x = sorted(glob(os.path.join(dataset_path, 'New_Training_20k_bkg', 'Patch', '*')))\n",
    "train_y = sorted(glob(os.path.join(dataset_path, 'New_Training_20k_bkg', 'Mask', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZu6uP-q1isB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': train_x, 'roi': train_y})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/patch_mask_Train_set.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ni4CE5xk1KVK",
    "outputId": "6bd3ecc7-e67d-493c-c8b9-863511df4d61"
   },
   "outputs": [],
   "source": [
    "train_set_x, train_set_y =  create_h5_file1('/content/drive/MyDrive/Mammo dataset/patch_mask_Train_set.csv','img', 'roi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sprxQlswySxf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbDSRETw9WwK",
    "outputId": "4cf61687-1f72-40fe-ba32-5e3ffcf1b22e"
   },
   "outputs": [],
   "source": [
    "y_preds = load_model_file.predict(test_set_x).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybVJ7QPX9tjL"
   },
   "outputs": [],
   "source": [
    "test_set_y_1 = test_set_y.ravel()\n",
    "# test_set_y_pred_1 = test_set_y_pred.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhwcjpIp9qUr"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_set_y_1, y_preds)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'y--')\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpPVpCh5_Pqb"
   },
   "outputs": [],
   "source": [
    "test_set_y_pred_2nd_1 = test_set_y_pred_2nd.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "K-Y-vgOR_T_b",
    "outputId": "e34c90c4-3155-477a-bd16-2f5e81f1bbe0"
   },
   "outputs": [],
   "source": [
    "fpr_2nd, tpr_2nd, thresholds_2nd = roc_curve(test_set_y_1, test_set_y_pred_2nd_1)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'y--')\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "8nsWs2VL6FXj",
    "outputId": "be7d8ae7-1f0a-413b-f2c5-f5e0686eb393"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(np.squeeze(test_set_y),  np.squeeze(test_set_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLBhDfgeyZcJ"
   },
   "outputs": [],
   "source": [
    "log_regression = LogisticRegression()\n",
    "\n",
    "#fit the model using the training data\n",
    "log_regression.fit(train_set_x,train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-mV7hkGyayv"
   },
   "outputs": [],
   "source": [
    "y_pred_proba = log_regression.predict_proba(test_set_x)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(test_set_y,  y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsVfvKsDydSh"
   },
   "outputs": [],
   "source": [
    "#define metrics\n",
    "y_pred_proba = log_regression.predict_proba(test_set_x)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(test_set_y,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(test_set_y, y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJ_8kujucBr_"
   },
   "source": [
    "#### tnh li dice, iou, overlap, confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9OjyJfjL2z8"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/predict test 133 images patch.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAJe4uhQL_vX"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/predict test 133 images patch without 2 nd.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3tmvB5DMUjM"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'Test_bkg', 'Patch', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'Test_bkg', 'Mask', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALoXjxvCMXHB"
   },
   "outputs": [],
   "source": [
    "test_y_pred= sorted(glob(os.path.join(dataset_path, 'predict test 133 images patch', '*')))\n",
    "test_y_pred_2nd= sorted(glob(os.path.join(dataset_path, 'predict test 133 images patch without 2 nd', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bW1_x4SPC6w"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y, 'y_pred': test_y_pred, 'y_pred_2nd': test_y_pred_2nd})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test DDSM/patch_mask__pred_Test_set_bkg.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LyuOXZr8OUl5",
    "outputId": "708aa671-b29e-48e3-f348-0050d6aeffb2"
   },
   "outputs": [],
   "source": [
    "test_set_x, test_set_y = read_h5_file('/content/drive/MyDrive/Mammo dataset/Test DDSM/patch_mask_Test_set.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyEffHSPh07a"
   },
   "outputs": [],
   "source": [
    "def compute_dice_1(label_img, pred_img, p_threshold=0.5):\n",
    "    p = pred_img.astype(np.float)\n",
    "    l = label_img.astype(np.float)\n",
    "    if p.max() > 127:\n",
    "        p /= 255.\n",
    "    if l.max() > 127:\n",
    "        l /= 255.\n",
    "\n",
    "    p = np.clip(p, 0, 1.0)\n",
    "    l = np.clip(l, 0, 1.0)\n",
    "    p[p > 0.5] = 1.0\n",
    "    p[p < 0.5] = 0.0\n",
    "    l[l > 0.5] = 1.0\n",
    "    l[l < 0.5] = 0.0\n",
    "    product = ((l.flatten())*(p.flatten())).sum()\n",
    "    dice_num = 2 * product + 1\n",
    "    pred_sum = p.sum()\n",
    "    label_sum = l.sum()\n",
    "    dice_den = pred_sum + label_sum + 1\n",
    "    dice_val = 100*dice_num / dice_den\n",
    "    return round(dice_val,2)\n",
    "def compute_iou(label_img, pred_img, p_threshold=0.5):\n",
    "    p = pred_img.astype(np.float)\n",
    "    l = label_img.astype(np.float)\n",
    "    if p.max() >= 127:\n",
    "        p /= 255.\n",
    "    if l.max() >= 127:\n",
    "        l /= 255.\n",
    "\n",
    "    p = np.clip(p, 0, 1.0)\n",
    "    l = np.clip(l, 0, 1.0)\n",
    "    p[p >= 0.5] = 1.0\n",
    "    p[p < 0.5] = 0.0\n",
    "    l[l >= 0.5] = 1.0\n",
    "    l[l < 0.5] = 0.0\n",
    "\n",
    "    product = ((l.flatten())* (p.flatten())).sum()\n",
    "    iou_num = product + 1\n",
    "    pred_sum = p.sum()\n",
    "    label_sum = l.sum()\n",
    "    iou_den = pred_sum + label_sum + 1 - product\n",
    "    iou = 100*iou_num / iou_den\n",
    "\n",
    "    return round(iou,2)\n",
    "def compute_overlap(label_img, pred_img):\n",
    "    p = pred_img.astype(np.float)\n",
    "    l = label_img.astype(np.float)\n",
    "    if p.max() >= 127:\n",
    "        p /= 255.\n",
    "    if l.max() >= 127:\n",
    "        l /= 255.\n",
    "\n",
    "    p = np.clip(p, 0, 1.0)\n",
    "    l = np.clip(l, 0, 1.0)\n",
    "    p[p >= 0.5] = 1.0\n",
    "    p[p < 0.5] = 0.0\n",
    "    l[l >= 0.5] = 1.0\n",
    "    l[l < 0.5] = 0.0\n",
    "\n",
    "    # product = ((l.flatten())* (p.flatten())).sum()\n",
    "    # label_sum = l.sum()\n",
    "    # overlap = 100*product /label_sum\n",
    "    bitwise_and_roi_patch = np.logical_and(l, p).sum()\n",
    "    overlap = 100*(bitwise_and_roi_patch + 1)/(np.sum(l)+1)\n",
    "\n",
    "    return round(overlap,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmYwvMAFcL8u"
   },
   "outputs": [],
   "source": [
    "def compute_iou(label_img, pred_img):\n",
    "    product = ((label_img.flatten())* (pred_img.flatten())).sum()\n",
    "    iou_num = product + 1\n",
    "    pred_sum = pred_img.sum()\n",
    "    label_sum = label_img.sum()\n",
    "    iou_den = pred_sum + label_sum + 1 - product\n",
    "    iou = 100*iou_num / iou_den\n",
    "\n",
    "    return round(iou,2)\n",
    "def compute_dice_1(label_img, pred_img):\n",
    "    product = ((label_img.flatten())* (pred_img.flatten())).sum()\n",
    "    dice_num = 2 * product + 1\n",
    "    pred_sum = pred_img.sum()\n",
    "    label_sum = label_img.sum()\n",
    "    dice_den = pred_sum + label_sum + 1\n",
    "    dice_val = 100*dice_num / dice_den\n",
    "    return round(dice_val,2)\n",
    "\n",
    "def compute_overlap(label_img, pred_img):\n",
    "    bitwise_and_roi_patch = np.logical_and(label_img, pred_img)\n",
    "    overlap = 100*np.sum(bitwise_and_roi_patch)/np.sum(label_img)\n",
    "    return round(overlap,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEDr6rVsTkaD"
   },
   "outputs": [],
   "source": [
    "def cal_dice_iou_overlap(roi, pred):\n",
    "\n",
    "  _, roi_bina = cv.threshold(roi, 1, 255, cv.THRESH_BINARY)\n",
    "  _, pred_bina = cv.threshold(pred, 1, 255, cv.THRESH_BINARY)\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred_bina, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi_bina, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # pred = cv.fillPoly(pred, pts= contours_pred, color=(255, 255))\n",
    "  # contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  dice_list = []\n",
    "  iou_list =[]\n",
    "  overlap_list = []\n",
    "  roi_num_cnt = len(contours_roi)\n",
    "  num_y_pred = len(contours_pred)\n",
    "  label_y = 999\n",
    "  label_y_pred = 999\n",
    "  print(\"num ground truth\", roi_num_cnt)\n",
    "  print(\"num Predict:\", num_y_pred)\n",
    "\n",
    "  if (roi_num_cnt == 0) & (num_y_pred == 0):\n",
    "     label_y = 0\n",
    "     label_y_pred = 0\n",
    "  elif (roi_num_cnt == 0) & (num_y_pred != 0):\n",
    "    label_y = 0\n",
    "    label_y_pred = 1\n",
    "  elif (roi_num_cnt != 0) & (num_y_pred == 0):\n",
    "    label_y = 1\n",
    "    label_y_pred = 0\n",
    "  else:\n",
    "       for ct in contours_roi:\n",
    "              each_roi= np.zeros(roi.shape, dtype=\"uint8\")\n",
    "              each_roi = cv.fillPoly(each_roi, pts=[ct], color=(255, 255))\n",
    "              for ct_pred in contours_pred:\n",
    "                  each_pred = np.zeros(pred.shape, dtype=\"uint8\")\n",
    "                  each_pred = cv.fillPoly(each_pred, pts=[ct_pred], color=(255, 255))\n",
    "\n",
    "                  dice = compute_dice_1(each_roi, each_pred)\n",
    "                  iou = compute_iou(each_roi, each_pred)\n",
    "                  overlap = compute_overlap(each_roi, each_pred)\n",
    "                  dice_list.append(dice)\n",
    "                  iou_list.append(iou)\n",
    "                  overlap_list.append(overlap)\n",
    "                  if dice >= 50:\n",
    "                    label_y = 1\n",
    "                    label_y_pred = 1\n",
    "\n",
    "\n",
    "  return dice_list, iou_list, overlap_list, label_y, label_y_pred, roi_num_cnt, num_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNXKYTjURf4E",
    "outputId": "a4fe2d94-bf40-44cc-e027-39b26c770de4"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/patch_mask__pred_Test_set_bkg.csv'\n",
    "\n",
    "predict_path = \"/content/predict test 133 images patch\"\n",
    "predict_2nd_path = \"/content/predict test 133 images patch without 2 nd\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "dice_list = []\n",
    "iou_list = []\n",
    "overlap_list = []\n",
    "label_y_list = []\n",
    "label_y_pred_list = []\n",
    "num_roi_list = []\n",
    "num_pred_list = []\n",
    "\n",
    "dice_2nd_list = []\n",
    "iou_2nd_list = []\n",
    "overlap_2nd_list = []\n",
    "label_y_2nd_list = []\n",
    "label_y_pred_2nd_list = []\n",
    "num_roi_2nd_list = []\n",
    "num_pred_2nd_list = []\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "        # pred_file = row['y_pred']\n",
    "        # pred_2nd_file = row['y_pred_2nd']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        pred_file= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "        pred_2nd_file= os.path.join(predict_2nd_path,''.join([name_file_saver]))\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi = cv.morphologyEx(roi, cv.MORPH_CLOSE, kernel)\n",
    "        roi = cv.morphologyEx(roi, cv.MORPH_OPEN, kernel)\n",
    "        # roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "\n",
    "        y_pred = cv.imread(pred_file, 0)\n",
    "        y_pred = cv.morphologyEx(y_pred, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred = cv.morphologyEx(y_pred, cv.MORPH_OPEN, kernel)\n",
    "        # y_pred, n_2 = filter_FP(pred, 300)\n",
    "\n",
    "        y_pred_2nd = cv.imread(pred_2nd_file, 0)\n",
    "        y_pred_2nd = cv.morphologyEx(y_pred_2nd, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_2nd = cv.morphologyEx(y_pred_2nd, cv.MORPH_OPEN, kernel)\n",
    "        # y_pred_2nd, n_3 = filter_FP(pred, 300)\n",
    "\n",
    "        dice, iou, overlap, label_y, label_y_pred, roi_num_cnt, num_y_pred = cal_dice_iou_overlap(roi, y_pred)\n",
    "        dice_2nd, iou_2nd, overlap_2nd, label_y_2nd, label_y_pred_2nd, roi_num_cnt_2nd, num_y_pred_2nd = cal_dice_iou_overlap(roi, y_pred_2nd)\n",
    "\n",
    "        print(dice, iou, overlap)\n",
    "\n",
    "        dice_list.append(dice)\n",
    "        iou_list.append(iou)\n",
    "        overlap_list.append(overlap)\n",
    "        label_y_list.append(label_y)\n",
    "        label_y_pred_list.append(label_y_pred)\n",
    "        num_roi_list.append(roi_num_cnt)\n",
    "        num_pred_list.append(num_y_pred)\n",
    "\n",
    "        print(dice_2nd, iou_2nd, overlap_2nd)\n",
    "        dice_2nd_list.append(dice_2nd)\n",
    "        iou_2nd_list.append(iou_2nd)\n",
    "        overlap_2nd_list.append(overlap_2nd)\n",
    "        label_y_2nd_list.append(label_y_2nd)\n",
    "        label_y_pred_2nd_list.append(label_y_pred_2nd)\n",
    "        num_roi_2nd_list.append(roi_num_cnt_2nd)\n",
    "        num_pred_2nd_list.append(num_y_pred_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-fg6Lx9qyOt"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "test_x = data[\"img\"]\n",
    "test_y = data[\"roi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "To_W5kLTdHGa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'x':test_x, 'y': test_y,'dice': dice_list, 'iou': iou_list, 'overlap': overlap_list, 'label_y':label_y_list, 'label_y_pred':label_y_pred_list, 'roi_num_cnt':num_roi_list, 'num_y_pred': num_pred_list,\n",
    "                   'dice_2nd': dice_2nd_list, 'iou_2nd': iou_2nd_list, 'overlap_2nd': overlap_2nd_list, 'label_y_2nd':label_y_2nd_list, 'label_y_pred_2nd':label_y_pred_2nd_list, 'roi_num_cnt_2nd':num_roi_2nd_list, 'num_y_pred_2nd': num_pred_2nd_list,})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test DDSM/dice_iou_overlap_Test_set_patch_8.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSx108z8p9rE"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUuSfL3Mgc_v"
   },
   "source": [
    "#### cal for 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woZFm9p7gfdO"
   },
   "outputs": [],
   "source": [
    "overlaps = []\n",
    "labels_y = []\n",
    "labels_y_pred_2nd = []\n",
    "for i in range(len(test_set_y)):\n",
    "  x = test_set_x[i]\n",
    "  y = test_set_y[i]\n",
    "  y_pred_2nd = test_set_y_pred_2nd[i]\n",
    "  overlap, label_y, label_y_pred_2nd = cal_overlap_label(x,y,y_pred_2nd)\n",
    "  overlaps.append(overlap)\n",
    "  labels_y.append(label_y)\n",
    "  labels_y_pred_2nd.append(label_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDiP8Y8bg1jI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'overlap': overlaps, 'label_y': labels_y, 'label_y_pred': labels_y_pred_2nd })\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test DDSM/overlap_Test_set_bkg_label_2nd_1.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "3Hq3Y_ldhDEH",
    "outputId": "9575cd72-b3c1-4587-8d34-b19cedfd61e2"
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_pred_2 = test_set_y_pred.ravel()\n",
    "# test_set_y_2 = test_set_y.ravel()\n",
    "cm=confusion_matrix(labels_y, labels_y_pred_2nd)\n",
    "print(cm)\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title('confusion matrix - Test data')\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SgUji3_ahNMn",
    "outputId": "715022a1-15f2-4a96-975a-67152f04173c"
   },
   "outputs": [],
   "source": [
    "total1=sum(sum(cm))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1=(cm[0,0]+cm[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tB31lMpZ7T5j"
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8mJYzfGThVQy",
    "outputId": "92bae8a3-d1d8-4bb1-fc10-d0f779807d72"
   },
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIUYkRKFoxXz",
    "outputId": "9ffe90fe-8bf2-462e-9837-2ad62e705931"
   },
   "outputs": [],
   "source": [
    "!unrar x \"//content/drive/MyDrive/Mammo dataset/Test DDSM/test_set_ddsm_remove_bkg.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPh7O0vaozSi"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'test_set_ddsm_remove_bkg', 'image', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'test_set_ddsm_remove_bkg', 'mask', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wr3_5WXzpgYb",
    "outputId": "70f998ec-3ab0-40bf-e566-df24329826a3"
   },
   "outputs": [],
   "source": [
    "print(len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWCOesimo38o"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test DDSM/img_mask_test_set_remove_bkg.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyYmILqwo48y"
   },
   "outputs": [],
   "source": [
    "load_model_file = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1lDxPZAo7EK"
   },
   "outputs": [],
   "source": [
    "def show_y_predict(randomlist, y, y_pred):\n",
    "  fg, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[0, i].imshow(np.squeeze(y[index]), 'gray')\n",
    "    ax[0, i].set_xlabel('y ' + str(index))\n",
    "    # print(y[index].shape)\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[1, i].imshow(np.squeeze(y_pred[index]), 'gray')\n",
    "    ax[1, i].set_xlabel('y_pred ' + str(index))\n",
    "\n",
    "def prediction(model, large_image, patch_size, step):\n",
    "  patches = patchify(large_image, (patch_size, patch_size), step=step)  #Step=256 for 256 patches means no overlap\n",
    "\n",
    "  print(patches.shape)\n",
    "\n",
    "  redicted_patches = []\n",
    "  patches_input = []\n",
    "  for i in range(patches.shape[0]):\n",
    "    for j in range(patches.shape[1]):\n",
    "        # print(i,j)\n",
    "        single_patch = patches[i,j,:,:]\n",
    "        single_patch_input=np.expand_dims(single_patch, -1)\n",
    "        # single_patch = np.array(single_patch)\n",
    "        # print(single_patch.shape)\n",
    "        #Predict and threshold for values above 0.5 probability\n",
    "\n",
    "        single_patch_input = np.zeros((patch_size,patch_size,3), dtype=\"float32\")\n",
    "        single_patch_input[:,:,0] = single_patch\n",
    "        single_patch_input[:,:,1] = single_patch\n",
    "        single_patch_input[:,:,2] = single_patch\n",
    "\n",
    "        single_patch_input = cv.resize(single_patch_input, (256,256), cv.INTER_AREA)\n",
    "        single_patch_input = np.array(single_patch_input)\n",
    "        patches_input.append(single_patch_input)\n",
    "\n",
    "  patches_input = np.array(patches_input)\n",
    "\n",
    "  patches_prediction = (model.predict(patches_input, batch_size = 8) >= 0.5).astype(np.uint8)\n",
    "  # randomlist = random.sample(range(0, len(patches_prediction)),5)\n",
    "  # show_y_predict(randomlist, patches_input, patches_prediction)\n",
    "  # plt.show()\n",
    "\n",
    "  patches_prediction_resize = []\n",
    "  for i in patches_prediction:\n",
    "    i = cv.resize(i, (patch_size,patch_size), cv.INTER_AREA)\n",
    "    patches_prediction_resize.append(i)\n",
    "\n",
    "  predicted_patches_reshaped = np.reshape(patches_prediction_resize, (patches.shape[0], patches.shape[1], patch_size,patch_size) )\n",
    "  print(predicted_patches_reshaped.shape)\n",
    "\n",
    "  reconstructed_image = unpatchify(predicted_patches_reshaped, large_image.shape)\n",
    "  plt.imshow(np.squeeze(reconstructed_image), cmap='gray')\n",
    "  return reconstructed_image\n",
    "\n",
    "def filter_FP(y_pred, thresh):\n",
    "  y_pred_filter = y_pred.copy()\n",
    "  kernel = np.ones((3,3),np.uint8)\n",
    "  y_pred_filter = cv.erode(y_pred_filter, kernel)\n",
    "\n",
    "  contours, _ = cv.findContours(y_pred_filter.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "  n = 0\n",
    "  y_pred_filter_new = np.zeros(y_pred.shape, dtype=\"uint8\")\n",
    "  for ct in contours:\n",
    "      contour_area = cv.contourArea(ct)\n",
    "      if (contour_area>= thresh):\n",
    "          n += 1\n",
    "          y_pred_filter_new = cv.fillPoly(y_pred_filter_new, pts= [ct], color=(255, 255))\n",
    "      # else:\n",
    "      #   y_pred_filter = cv.fillPoly(y_pred_filter, pts=[ct], color=(0, 0))\n",
    "  y_pred_filter_new =  cv.dilate(y_pred_filter_new, kernel)\n",
    "  print(\"n = \", n)\n",
    "  return y_pred_filter_new, n\n",
    "\n",
    "\n",
    "def draw_contour_pred_and_truth(large_image, pred, roi):\n",
    "  img_copy = large_image.copy()\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  cv.drawContours(img_copy, contours_roi , -1, (255,0,0), 3)\n",
    "  cv.drawContours(img_copy, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "  return img_copy\n",
    "\n",
    "def check_Left_Orient(img, roi):\n",
    "    left_nonzero = cv.countNonZero(img[:, 0:int(img.shape[1] / 2)])\n",
    "    right_nonzero = cv.countNonZero(img[:, int(img.shape[1] / 2):])\n",
    "\n",
    "    if (left_nonzero <= right_nonzero):\n",
    "            img = cv.flip(img, 1)\n",
    "            roi = cv.flip(roi, 1)\n",
    "\n",
    "    return img, roi\n",
    "\n",
    "def cal_overlap_per_large_img(roi, overlap_img):\n",
    "  bitwise_and_roi_pred = cv.bitwise_and(overlap_img, roi)\n",
    "  area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "  overlap = round(area_truth / np.count_nonzero(roi), 4)*100\n",
    "  return bitwise_and_roi_pred, area_truth, overlap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4F87itfo-Jb"
   },
   "outputs": [],
   "source": [
    "def cal_overlaps_per_large_img(roi, pred, large_image):\n",
    "\n",
    "  pred, n = filter_FP(pred, 2000)\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  img = large_image.copy()\n",
    "\n",
    "  overlap_list = []\n",
    "\n",
    "  roi_num_cnt = len(contours_roi)\n",
    "  print(\"num Predict:\", len(contours_pred))\n",
    "\n",
    "  bitwise_and_roi_pred = cv.bitwise_and(pred, roi)\n",
    "\n",
    "  if  roi_num_cnt == 1:\n",
    "       area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "       overlap = round(area_truth/np.count_nonzero(roi) * 100,3)\n",
    "       overlap_list.append(overlap)\n",
    "       print(\"overlap\", overlap)\n",
    "       cv.drawContours(img, contours_roi , -1, (255,0,0), 3)\n",
    "       cv.drawContours(img, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "       if overlap!=0:\n",
    "\n",
    "           contours_overlaps, _ = cv.findContours(bitwise_and_roi_pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "           c = max(contours_overlaps, key = cv.contourArea)\n",
    "\n",
    "           x, y, w, h = cv.boundingRect(c)\n",
    "\n",
    "           font = cv.FONT_HERSHEY_SIMPLEX\n",
    "           org = (x-10, y-10)\n",
    "           fontScale = 3\n",
    "           color = (0, 0, 255)\n",
    "           thickness = 2\n",
    "           text = str(overlap)\n",
    "           img = cv.putText(img, text, org, font, fontScale, color, thickness, cv.LINE_AA)\n",
    "\n",
    "  elif roi_num_cnt == 0:\n",
    "       cv.drawContours(img, contours_pred, -1, (0,255,0), 3)\n",
    "  else:\n",
    "       bitwise_and_roi_pred = cv.bitwise_and(pred, roi)\n",
    "       area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "       overlap = round(area_truth/np.count_nonzero(roi) * 100,3)\n",
    "       if overlap == 0:\n",
    "          cv.drawContours(img, contours_roi , -1, (255,0,0), 3)\n",
    "          cv.drawContours(img, contours_pred, -1, (0,255,0), 3)\n",
    "       else :\n",
    "          cv.drawContours(img, contours_roi , -1, (255,0,0), 3)\n",
    "          cv.drawContours(img, contours_pred, -1, (0,255,0), 3)\n",
    "          for ct in contours_roi:\n",
    "            each_roi= np.zeros(roi.shape, dtype=\"uint8\")\n",
    "            each_roi = cv.fillPoly(each_roi, pts=[ct], color=(255, 255, 255))\n",
    "            # plt.imshow(each_roi, 'gray')\n",
    "            # plt.show()\n",
    "            # cv.drawContours(img, ct , -1, (255,0,0), 3)\n",
    "\n",
    "            for ct_pred in contours_pred:\n",
    "                  each_pred = np.zeros(pred.shape, dtype=\"uint8\")\n",
    "                  each_pred = cv.fillPoly(each_pred, pts=[ct_pred], color=(255, 255, 255))\n",
    "\n",
    "                  # plt.imshow(each_pred, 'gray')\n",
    "                  # plt.show()\n",
    "\n",
    "                  bitwise_and_roi_pred_1 = cv.bitwise_and(each_pred, each_roi)\n",
    "\n",
    "                  area_truth = np.count_nonzero(bitwise_and_roi_pred_1)\n",
    "                  overlap = round(area_truth/np.count_nonzero(each_roi) *100,3)\n",
    "                  # cv.drawContours(img, ct_pred, -1, (0,255,0), 3)\n",
    "\n",
    "                  # cv.drawContours(img, ct_pred , -1, (255,0,0), 3)\n",
    "\n",
    "                  if overlap>10:\n",
    "                       overlap_list.append(overlap)\n",
    "                       print(\"overlap\", overlap)\n",
    "\n",
    "                       x, y, w, h = cv.boundingRect(ct_pred)\n",
    "\n",
    "                      #  overlap_img_anotation = cv.fillPoly(overlap_img_anotation, pts=[ct_pred], color=(0, 0))\n",
    "\n",
    "                      #  overlap_img_anotation = ImageDraw.Draw(overlap_img_anotation)\n",
    "                      #  overlap_img_anotation.text((x, y), overlap, fill=(0 , 0, 255))\n",
    "                       font = cv.FONT_HERSHEY_SIMPLEX\n",
    "                       org = (x-10, y-20)\n",
    "                       fontScale = 3\n",
    "                       color = (0, 0, 255)\n",
    "                       thickness = 2\n",
    "                       text = str(overlap)\n",
    "                       img = cv.putText(img, text, org, font, fontScale, color, thickness, cv.LINE_AA)\n",
    "  # cv.imshow(overlap_img_anotation, 0)\n",
    "  plt.imshow(bitwise_and_roi_pred, 'gray')\n",
    "  plt.show()\n",
    "  # plt.imshow(img)\n",
    "  # plt.show()\n",
    "  return bitwise_and_roi_pred, overlap_list, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAMpbhzB4mne"
   },
   "outputs": [],
   "source": [
    "image_path = \"/content/test_set_ddsm_remove_bkg/image/Mass-Test_P_00116_RIGHT_CC.png\"\n",
    "roi_path = \"/content/test_set_ddsm_remove_bkg/mask/Mass-Test_P_00116_RIGHT_CC.png\"\n",
    "predict_path =\"/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/overlap/Mass-Test_P_00116_RIGHT_CC.png\"\n",
    "\n",
    "\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "h_r, w_r = roi.shape\n",
    "\n",
    "\n",
    "\n",
    "h_i, w_i = predict.shape\n",
    "\n",
    "if (h_i>=h_r) or (w_i>=w_r):\n",
    "      predict = predict[0:h_r, 0:w_r]\n",
    "else:\n",
    "      roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "bitwise_and_roi_pred, overlap_list, img_anotation = cal_overlaps_per_large_img(roi, predict, image)\n",
    "plt.imshow(bitwise_and_roi_pred)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(img_anotation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqXa7vd-pBeb"
   },
   "outputs": [],
   "source": [
    "def detect_roi_by_patch_size(img, load_model_file, patch_size, step):\n",
    "\n",
    "        h,w = img.shape\n",
    "\n",
    "        roi_detect= np.zeros(img.shape, dtype=\"uint8\")\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img_by_patch_size = img[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        segmented_image_by_patch_size = prediction(load_model_file, img_by_patch_size, patch_size , step)\n",
    "        h_1, w_1 = segmented_image_by_patch_size.shape\n",
    "        roi_detect[0:h_1, 0:w_1] = segmented_image_by_patch_size\n",
    "\n",
    "\n",
    "        return roi_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0up5nGbpFGr"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/normal_image.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Normal/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Normal/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Normal/draw contour'\n",
    "overlap_anotation_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Normal/overlap anotation'\n",
    "\n",
    "import time\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "small_image = []\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # roi = cv.imread(roi_file, 0)\n",
    "        # roi= np.uint8(roi)\n",
    "        # print(roi.shape)\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "\n",
    "        if 600 < w_i < 1024:\n",
    "          roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        elif w_i <= 600:\n",
    "          print(\"image < 512\", name_file_saver)\n",
    "          small_image.append(name_file_saver)\n",
    "          continue\n",
    "        else:\n",
    "          roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        # print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "\n",
    "        # combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(roi_predict_384, roi_predict_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, roi_predict_1024).astype(np.uint8)\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        # overlap_img_anotation = 1*overlap_img_anotation\n",
    "        img_overlap_anotation_path = os.path.join(overlap_anotation_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_overlap_anotation_path, img_anotation_1, cmap='gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.show()\n",
    "        # print(overlap)\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        # overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        # combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "        # plt.imshow(img_draw_contour)\n",
    "\n",
    "        # plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "        # plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "\n",
    "print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FTiakxQ654l"
   },
   "source": [
    "#### Detect patches and calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJz1jFIq65CX"
   },
   "outputs": [],
   "source": [
    "def prediction(model, large_image, groundtruth_uint8, patch_size, step):\n",
    "  patches = patchify(large_image, (patch_size, patch_size), step=step)  #Step=256 for 256 patches means no overlap\n",
    "  gt_patches = patchify(groundtruth_uint8, (patch_size, patch_size), step=step)\n",
    "\n",
    "  print(patches.shape)\n",
    "  # print(gt_patches.shape)\n",
    "\n",
    "  redicted_patches = []\n",
    "  patches_input = []\n",
    "  gt_patches_input = []\n",
    "  for i in range(patches.shape[0]):\n",
    "    for j in range(patches.shape[1]):\n",
    "        # print(i,j)\n",
    "        single_patch = patches[i,j,:,:]\n",
    "        single_patch_input=np.expand_dims(single_patch, -1)\n",
    "        # single_patch = np.array(single_patch)\n",
    "        # print(single_patch.shape)\n",
    "        #Predict and threshold for values above 0.5 probability\n",
    "\n",
    "        single_patch_input = np.zeros((patch_size,patch_size,3), dtype=\"float32\")\n",
    "        single_patch_input[:,:,0] = single_patch\n",
    "        single_patch_input[:,:,1] = single_patch\n",
    "        single_patch_input[:,:,2] = single_patch\n",
    "\n",
    "        single_patch_input = cv.resize(single_patch_input, (256,256), cv.INTER_AREA)\n",
    "        single_patch_input = np.array(single_patch_input)\n",
    "        patches_input.append(single_patch_input)\n",
    "\n",
    "  for i in range(gt_patches.shape[0]):\n",
    "      for j in range(gt_patches.shape[1]):\n",
    "        # print(i,j)\n",
    "        single_patch = gt_patches[i,j,:,:]\n",
    "        single_patch_input=np.expand_dims(single_patch, -1)\n",
    "\n",
    "        single_patch_input = np.zeros((patch_size,patch_size), dtype=\"uint8\")\n",
    "        single_patch_input[:,:] = single_patch\n",
    "        single_patch_input = np.array(single_patch_input)\n",
    "        gt_patches_input.append(single_patch_input)\n",
    "\n",
    "  patches_input = np.array(patches_input)\n",
    "  gt_patches_input = np.array(gt_patches_input)\n",
    "  print(\"patches size\", gt_patches_input.shape)\n",
    "  print(\"GT patches size\", patches_input.shape)\n",
    "\n",
    "  patches_prediction = (model.predict(patches_input) >= 0.5).astype(np.uint8)\n",
    "\n",
    "  # randomlist = random.sample(range(0, len(patches_prediction)),5)\n",
    "  # show_y_predict(randomlist, patches_input, patches_prediction)\n",
    "  # plt.show()\n",
    "\n",
    "  patches_prediction_resize = []\n",
    "  for i in patches_prediction:\n",
    "    i = cv.resize(i, (patch_size,patch_size), cv.INTER_AREA)\n",
    "    patches_prediction_resize.append(i)\n",
    "  # print(\"patches size\", patches_prediction_resize.shape)\n",
    "\n",
    "  intersection = np.logical_and(gt_patches_input, patches_prediction_resize)\n",
    "  union = np.logical_or(gt_patches_input, patches_prediction_resize)\n",
    "  iou_score = np.sum(intersection) / np.sum(union)\n",
    "  print(\"IoU socre is: \", iou_score)\n",
    "\n",
    "  predicted_patches_reshaped = np.reshape(patches_prediction_resize, (patches.shape[0], patches.shape[1], patch_size,patch_size) )\n",
    "  print(predicted_patches_reshaped.shape)\n",
    "\n",
    "  reconstructed_image = unpatchify(predicted_patches_reshaped, large_image.shape)\n",
    "  plt.imshow(np.squeeze(reconstructed_image), cmap='gray')\n",
    "  return reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CIeM-LxC34R"
   },
   "outputs": [],
   "source": [
    "from patchify import patchify,  unpatchify\n",
    "image_path = \"/content/test_set_ddsm_remove_bkg/image/Mass-Test_P_00116_RIGHT_CC.png\"\n",
    "roi_path = \"/content/test_set_ddsm_remove_bkg/mask/Mass-Test_P_00116_RIGHT_CC.png\"\n",
    "\n",
    "patch_size = 512\n",
    "step = 64\n",
    "\n",
    "img = cv.imread(image_path, 0)\n",
    "# image= np.float32(image)\n",
    "# img = image/255.0\n",
    "\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.imshow(roi)\n",
    "plt.show()\n",
    "\n",
    "# h_r, w_r = roi.shape\n",
    "# h_i, w_i = image.shape\n",
    "\n",
    "# if (h_i>=h_r) or (w_i>=w_r):\n",
    "#       img = img[0:h_r, 0:w_r]\n",
    "# else:\n",
    "#       roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "# h,w = img.shape\n",
    "# row = int(( h - patch_size)/step)\n",
    "# col = int(( w - patch_size)/step)\n",
    "# new_img_h = row * step + patch_size\n",
    "# new_img_w = col * step + patch_size\n",
    "\n",
    "# img_by_patch_size = img[0:new_img_h, 0: new_img_w]\n",
    "# roi_by_patch_size = roi[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "# img_predict = prediction(load_model_file, img_by_patch_size, roi_by_patch_size, patch_size, step)\n",
    "\n",
    "# plt.imshow(img_predict)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPJAndZypbGq"
   },
   "source": [
    "#### normal image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDs_ukTWpzR4"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/Test DDSM/Normal.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oER9VZ09pyM4"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'Normal', 'image', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'Normal', 'mask', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8l48Vc_GqLw9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test DDSM/normal_image.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MIH1q8F8rjeH",
    "outputId": "88ec8924-eef1-4e82-e505-9e61e3f0e8ac"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/normal_image.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Normal/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Normal/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Normal/draw contour'\n",
    "overlap_anotation_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Normal/overlap anotation'\n",
    "\n",
    "import time\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "small_image = []\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # roi = cv.imread(roi_file, 0)\n",
    "        # roi= np.uint8(roi)\n",
    "        # print(roi.shape)\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "\n",
    "        if 600 < w_i < 1024:\n",
    "          roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        elif w_i <= 600:\n",
    "          print(\"image < 512\", name_file_saver)\n",
    "          small_image.append(name_file_saver)\n",
    "          continue\n",
    "        else:\n",
    "          roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        # print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "\n",
    "        # combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(roi_predict_384, roi_predict_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, roi_predict_1024).astype(np.uint8)\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        # overlap_img_anotation = 1*overlap_img_anotation\n",
    "        img_overlap_anotation_path = os.path.join(overlap_anotation_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_overlap_anotation_path, img_anotation_1, cmap='gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.show()\n",
    "        # print(overlap)\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        # overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        # combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "        # plt.imshow(img_draw_contour)\n",
    "\n",
    "        # plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "        # plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "\n",
    "print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MaRKouMbuW9T",
    "outputId": "683f31c0-59d7-4a4d-c5b0-ee1606b935ad"
   },
   "outputs": [],
   "source": [
    "print(small_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iv9ihnKlvcFv"
   },
   "outputs": [],
   "source": [
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    imgs = []\n",
    "    rois = []\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "        if name_file_saver!= \"A_0002_1.LEFT_CC.png\":\n",
    "          imgs.append(img_file)\n",
    "          rois.append(roi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bT_EYIZnv6Q5",
    "outputId": "86341765-88cf-4f6b-9952-783dba97b454"
   },
   "outputs": [],
   "source": [
    "print(len(imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDqgdss-Hgce"
   },
   "source": [
    "25G; 15G ram, v100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sr3Mdkp3t_zO"
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(csv_path)\n",
    "# img = data[\"img\"]\n",
    "# roi = data[\"roi\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Normal/predict_normal.csv'\n",
    "df = pd.DataFrame({'img': imgs, 'roi': rois, 'overlap': area_truth_list, 'num_FP': num_P_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1mhY_QgyGml"
   },
   "source": [
    "#### normal image 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6SPb7mYKyGmm"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/Test DDSM/new normal test ddsm.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ty1J_l2ayGmm"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'new normal test ddsm', 'image', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'new normal test ddsm', 'mask', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tN-sct2L0DKu"
   },
   "outputs": [],
   "source": [
    "load_model_file = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7bucAkbyGmm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test DDSM/normal_144_image.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XMS6k_AyGmn"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/normal_144_image.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/144 normal/original_predict'\n",
    "\n",
    "draw_contour_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/144 normal/draw contour'\n",
    "\n",
    "import time\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "small_image = []\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # roi = cv.imread(roi_file, 0)\n",
    "        # roi= np.uint8(roi)\n",
    "        # print(roi.shape)\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "\n",
    "        if 600 < w_i < 1024:\n",
    "          roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        elif w_i <= 600:\n",
    "          print(\"image < 512\", name_file_saver)\n",
    "          small_image.append(name_file_saver)\n",
    "          continue\n",
    "        else:\n",
    "          roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        # print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "\n",
    "        # combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(roi_predict_384, roi_predict_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, roi_predict_1024).astype(np.uint8)\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "\n",
    "print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHvG4Ibx-lcq"
   },
   "outputs": [],
   "source": [
    "pred_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model'\n",
    "\n",
    "pred = sorted(glob(os.path.join(pred_path, '144 normal', 'original_predict', '*')))\n",
    "draw_image = sorted(glob(os.path.join(pred_path, '144 normal', 'draw contour', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kkpkt9HU-Q7p"
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(csv_path)\n",
    "# img = data[\"img\"]\n",
    "# roi = data[\"roi\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/144 normal/144_predict_normal.csv'\n",
    "df = pd.DataFrame({'pred': pred, 'draw contour': draw_image, 'num_Predict': num_P_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot7OgCL4Azxt"
   },
   "source": [
    "###### 2nd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogah_oYTA1kq"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg_unet_without_skip')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-without-skip.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'new normal test ddsm', 'image', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'new normal test ddsm', 'mask', '*')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwBLgOYTBMhE"
   },
   "outputs": [],
   "source": [
    "load_model_file_2nd = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_uGT2PIJBVGi",
    "outputId": "7d03de9d-d7d5-43c7-d12d-68b50cef45d6"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/normal_144_image.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/144 normal/original_predict_2nd'\n",
    "\n",
    "draw_contour_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/144 normal/draw contour 2 nd'\n",
    "\n",
    "import time\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "small_image = []\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # roi = cv.imread(roi_file, 0)\n",
    "        # roi= np.uint8(roi)\n",
    "        # print(roi.shape)\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file_2nd, 348, 64)\n",
    "\n",
    "        if 600 < w_i < 1024:\n",
    "          roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file_2nd, 512, 64)\n",
    "\n",
    "        elif w_i <= 600:\n",
    "          print(\"image < 512\", name_file_saver)\n",
    "          small_image.append(name_file_saver)\n",
    "          continue\n",
    "        else:\n",
    "          roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file_2nd, 1024, 128)\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file_2nd, 512, 64)\n",
    "\n",
    "        # print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "\n",
    "        # combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(roi_predict_384, roi_predict_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, roi_predict_1024).astype(np.uint8)\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "        plt.imshow(img_draw_contour)\n",
    "\n",
    "        plt.title(name_file_saver + \"num pred = \"+ str(n))\n",
    "        plt.show()\n",
    "\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "\n",
    "print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQn0EQxlyGmn",
    "outputId": "683f31c0-59d7-4a4d-c5b0-ee1606b935ad"
   },
   "outputs": [],
   "source": [
    "print(small_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6Ruuwo4yGmn"
   },
   "outputs": [],
   "source": [
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    imgs = []\n",
    "    rois = []\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "        if name_file_saver!= \"A_0002_1.LEFT_CC.png\":\n",
    "          imgs.append(img_file)\n",
    "          rois.append(roi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xx_ICf0uyGmn",
    "outputId": "86341765-88cf-4f6b-9952-783dba97b454"
   },
   "outputs": [],
   "source": [
    "print(len(imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbJRNZXLyGmn"
   },
   "source": [
    "25G; 15G ram, v100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZnKlXn_yGmo"
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(csv_path)\n",
    "# img = data[\"img\"]\n",
    "# roi = data[\"roi\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Normal/predict_normal.csv'\n",
    "df = pd.DataFrame({'img': imgs, 'roi': rois, 'overlap': area_truth_list, 'num_FP': num_P_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRSmmsEZwc59"
   },
   "source": [
    "#### Abnormal image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5L2aleXzwc6J",
    "outputId": "952bba2b-a471-40e3-facf-274f4ad7139d"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/Test DDSM/Abnormal.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PyYauT1wc6J"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'Abnormal', 'image', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'Abnormal', 'mask', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ER8P5QUwc6J"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5aL5JhGtI8CK"
   },
   "outputs": [],
   "source": [
    "def count_num_roi(roi):\n",
    "  contours_roi, _ = cv.findContours(roi, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  num_roi = len(contours_roi)\n",
    "  print(\"num ground truth\", num_roi)\n",
    "  return num_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3sOx0-OJ59b"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "\n",
    "num_roi_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        roi_file = row['roi']\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi, n = filter_FP (roi, 300)\n",
    "        roi = np.array(roi)\n",
    "        num_roi = count_num_roi(roi)\n",
    "        num_roi_list.append(num_roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBnPh4e4K_WZ"
   },
   "outputs": [],
   "source": [
    "save_csv_path= '/content/drive/MyDrive/Mammo dataset/Test DDSM/118_num_roi_abnormal.csv'\n",
    "df = pd.DataFrame({'num_roi': num_roi_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whgx60xM0IwV"
   },
   "outputs": [],
   "source": [
    "def cal_overlaps_per_large_img_1(roi, pred, large_image):\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # for ct_roi in contours_roi:\n",
    "  #       area = cv.contourArea(ct_roi)\n",
    "  #       if (area < 500)\n",
    "  #            roi = cv.fillPoly(roi, pts= [ct_pred], color=(0, 0))\n",
    "\n",
    "  pred = cv.fillPoly(pred, pts= contours_pred, color=(255, 255))\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # roi = cv.fillPoly(roi, pts= contours_roi, color=(255, 255))\n",
    "  # contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "  img = large_image.copy()\n",
    "\n",
    "  overlap_list = []\n",
    "\n",
    "  roi_num_cnt = len(contours_roi)\n",
    "  print(\"num ground truth\", roi_num_cnt)\n",
    "  print(\"num Predict:\", len(contours_pred))\n",
    "\n",
    "  bitwise_and_roi_pred = cv.bitwise_and(pred, roi)\n",
    "\n",
    "\n",
    "\n",
    "  if  roi_num_cnt == 1:\n",
    "       print(\"one ground truth\")\n",
    "       area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "       overlap = round(area_truth/np.count_nonzero(roi) * 100,3)\n",
    "       overlap_list.append(overlap)\n",
    "       print(\"overlap\", overlap)\n",
    "       cv.drawContours(img, contours_roi , -1, (255,0,0), 3)\n",
    "       cv.drawContours(img, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "       if overlap!=0:\n",
    "\n",
    "           contours_overlaps, _ = cv.findContours(bitwise_and_roi_pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "           c = max(contours_overlaps, key = cv.contourArea)\n",
    "\n",
    "           x, y, w, h = cv.boundingRect(c)\n",
    "\n",
    "           font = cv.FONT_HERSHEY_SIMPLEX\n",
    "           org = (x-10, y-10)\n",
    "           fontScale = 3\n",
    "           color = (0, 0, 255)\n",
    "           thickness = 2\n",
    "           text = str(overlap)\n",
    "           img = cv.putText(img, text, org, font, fontScale, color, thickness, cv.LINE_AA)\n",
    "\n",
    "  elif roi_num_cnt == 0:\n",
    "       print(\"normal\")\n",
    "       cv.drawContours(img, contours_pred, -1, (0,255,0), 3)\n",
    "  else:\n",
    "       area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "       overlap = round(area_truth/np.count_nonzero(roi) * 100,3)\n",
    "       if overlap == 0:\n",
    "          cv.drawContours(img, contours_roi , -1, (255,0,0), 3)\n",
    "          cv.drawContours(img, contours_pred, -1, (0,255,0), 3)\n",
    "       else :\n",
    "          a = 0\n",
    "          cv.drawContours(img, contours_roi , -1, (255,0,0), 3)\n",
    "          cv.drawContours(img, contours_pred, -1, (0,255,0), 3)\n",
    "          for ct in contours_roi:\n",
    "              a = a + 1\n",
    "              each_roi= np.zeros(roi.shape, dtype=\"uint8\")\n",
    "              each_roi = cv.fillPoly(each_roi, pts=[ct], color=(255, 255))\n",
    "\n",
    "              # plt.imshow(each_roi, 'gray')\n",
    "              # plt.title(a)\n",
    "              # plt.show()\n",
    "              # cv.drawContours(img, ct , -1, (255,0,0), 3)\n",
    "              # plt.imshow(img, 'gray')\n",
    "              # plt.title(a)\n",
    "              # plt.show()\n",
    "\n",
    "\n",
    "              for ct_pred in contours_pred:\n",
    "                  each_pred = np.zeros(pred.shape, dtype=\"uint8\")\n",
    "                  each_pred = cv.fillPoly(each_pred, pts=[ct_pred], color=(255, 255))\n",
    "\n",
    "                  # plt.imshow(each_pred, 'gray')\n",
    "                  # plt.show()\n",
    "\n",
    "                  bitwise_and_roi_pred_1 = cv.bitwise_and(each_pred, each_roi)\n",
    "\n",
    "                  area_truth = np.count_nonzero(bitwise_and_roi_pred_1)\n",
    "                  overlap = round(area_truth/np.count_nonzero(each_roi) *100,3)\n",
    "                  # cv.drawContours(img, ct_pred, -1, (0,255,0), 3)\n",
    "\n",
    "                  # cv.drawContours(img, ct_pred , -1, (255,0,0), 3)\n",
    "\n",
    "                  if overlap > 0:\n",
    "                       overlap_list.append(overlap)\n",
    "                       print(\"overlap\", overlap)\n",
    "\n",
    "                       x, y, w, h = cv.boundingRect(ct_pred)\n",
    "\n",
    "                      #  overlap_img_anotation = cv.fillPoly(overlap_img_anotation, pts=[ct_pred], color=(0, 0))\n",
    "\n",
    "                      #  overlap_img_anotation = ImageDraw.Draw(overlap_img_anotation)\n",
    "                      #  overlap_img_anotation.text((x, y), overlap, fill=(0 , 0, 255))\n",
    "                       font = cv.FONT_HERSHEY_SIMPLEX\n",
    "                       org = (x-10, y-20)\n",
    "                       fontScale = 3\n",
    "                       color = (0, 0, 255)\n",
    "                       thickness = 2\n",
    "                       text = str(overlap)\n",
    "                       img = cv.putText(img, text, org, font, fontScale, color, thickness, cv.LINE_AA)\n",
    "\n",
    "  # plt.imshow(pred)\n",
    "  # plt.show()\n",
    "  plt.imshow(bitwise_and_roi_pred, 'gray')\n",
    "  plt.title('bitwise_and')\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "  # plt.imshow(img)\n",
    "  # plt.show()\n",
    "  return bitwise_and_roi_pred, overlap_list, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JPV6bwQ7_5j"
   },
   "outputs": [],
   "source": [
    "def cal_overlaps_per_large_img_3(roi, pred, large_image):\n",
    "\n",
    "  cal_overlaps_per_large_img_3\n",
    "  contours_pred, _ = cv.findContours(pred, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # pred = cv.fillPoly(pred, pts= contours_pred, color=(255, 255))\n",
    "  # contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  img = large_image.copy()\n",
    "\n",
    "  overlap_list = []\n",
    "\n",
    "  roi_num_cnt = len(contours_roi)\n",
    "  print(\"num ground truth\", roi_num_cnt)\n",
    "  print(\"num Predict:\", len(contours_pred))\n",
    "\n",
    "  bitwise_and_roi_pred = cv.bitwise_and(pred, roi)\n",
    "\n",
    "  cv.drawContours(img, contours_roi , -1, (255,0,0), 3)\n",
    "  cv.drawContours(img, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "  for ct in contours_roi:\n",
    "              each_roi= np.zeros(roi.shape, dtype=\"uint8\")\n",
    "              each_roi = cv.fillPoly(each_roi, pts=[ct], color=(255, 255))\n",
    "\n",
    "              for ct_pred in contours_pred:\n",
    "                  each_pred = np.zeros(pred.shape, dtype=\"uint8\")\n",
    "                  each_pred = cv.fillPoly(each_pred, pts=[ct_pred], color=(255, 255))\n",
    "\n",
    "                  bitwise_and_roi_pred_1 = cv.bitwise_and(each_pred, each_roi)\n",
    "                  area_truth = np.count_nonzero(bitwise_and_roi_pred_1)\n",
    "\n",
    "                  if area_truth > 0:\n",
    "                       overlap = round(area_truth/np.count_nonzero(each_roi) * 100,3)\n",
    "                       overlap_list.append(overlap)\n",
    "                       print(\"overlap\", overlap)\n",
    "\n",
    "                       x, y, w, h = cv.boundingRect(ct_pred)\n",
    "\n",
    "                       font = cv.FONT_HERSHEY_SIMPLEX\n",
    "                       org = (x-10, y-20)\n",
    "                       fontScale = 3\n",
    "                       color = (0, 0, 255)\n",
    "                       thickness = 2\n",
    "                       text = str(overlap)\n",
    "                       img = cv.putText(img, text, org, font, fontScale, color, thickness, cv.LINE_AA)\n",
    "\n",
    "  # plt.imshow(bitwise_and_roi_pred, 'gray')\n",
    "  # plt.title('bitwise_and')\n",
    "  # plt.axis('off')\n",
    "  # plt.show()\n",
    "  # plt.imshow(img)\n",
    "  # plt.show()\n",
    "  return bitwise_and_roi_pred, overlap_list, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oetJjIMq61M-"
   },
   "outputs": [],
   "source": [
    "def cal_overlaps_per_large_img_2(roi, pred, large_image):\n",
    "\n",
    "  pred, n = filter_FP(pred, 2000)\n",
    "  roi_filter, n = filter_FP(roi, 100)\n",
    "  roi_filter_1 = np.zeros(roi.shape, dtype=\"uint8\")\n",
    "\n",
    "  roi_filter = roi.copy()\n",
    "  kernel = np.ones((3,3),np.uint8)\n",
    "  roi_filter = cv.erode(roi_filter, kernel)\n",
    "\n",
    "  contours, _ = cv.findContours(roi_filter.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "  n = 0\n",
    "  for ct in contours:\n",
    "      contour_area = cv.contourArea(ct)\n",
    "      if (contour_area>= 100):\n",
    "          n += 1\n",
    "          roi_filter_1 = cv.fillPoly(roi_filter_1, pts= [ct], color=(255, 255))\n",
    "\n",
    "      # else:\n",
    "      #   roi_filter = cv.fillPoly(roi_filter, pts=[ct], color=(0, 0))\n",
    "  roi_filter_1 =  cv.dilate(roi_filter_1, kernel)\n",
    "\n",
    "  plt.imshow(roi_filter_1)\n",
    "  plt.show()\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi_filter_1, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # for ct_roi in contours_roi:\n",
    "  #       area = cv.contourArea(ct_roi)\n",
    "  #       if (area < 500):\n",
    "  #            print(area)\n",
    "  #            roi = cv.fillPoly(roi_filter, pts= [ct_roi], color=(0, 0))\n",
    "\n",
    "  pred = cv.fillPoly(pred, pts= contours_pred, color=(255, 255))\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # roi_filter = cv.fillPoly(roi_filter, pts= contours_roi, color=(255, 255))\n",
    "  # contours_roi, _ = cv.findContours(roi_filter.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "  img = large_image.copy()\n",
    "\n",
    "  overlap_list = []\n",
    "\n",
    "  roi_num_cnt = len(contours_roi)\n",
    "  print(\"num ground truth\", roi_num_cnt)\n",
    "  print(\"num Predict:\", len(contours_pred))\n",
    "\n",
    "  bitwise_and_roi_pred = cv.bitwise_and(pred, roi_filter_1)\n",
    "\n",
    "  # plt.imshow(pred)\n",
    "  # plt.show()\n",
    "  # plt.imshow(bitwise_and_roi_pred, 'gray')\n",
    "  # plt.show()\n",
    "  # plt.imshow(img)\n",
    "  # plt.show()\n",
    "  return bitwise_and_roi_pred, overlap_list, img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOz4dhSEy2Om"
   },
   "outputs": [],
   "source": [
    "predict_path =\"/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/original_predict/Mass-Test_P_00116_RIGHT_CC.png\"\n",
    "image_path = \"/content/Abnormal/image/Mass-Test_P_00116_RIGHT_CC.png\"\n",
    "roi_path = \"/content/Abnormal/mask/Mass-Test_P_00116_RIGHT_CC.png\"\n",
    "\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "h_r, w_r = roi.shape\n",
    "\n",
    "\n",
    "\n",
    "h_i, w_i = predict.shape\n",
    "\n",
    "if (h_i>=h_r) or (w_i>=w_r):\n",
    "      predict = predict[0:h_r, 0:w_r]\n",
    "else:\n",
    "      roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "bitwise_and_roi_pred, overlap_list, img_anotation = cal_overlaps_per_large_img_1(roi, predict, image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3eMDcfM1doY"
   },
   "outputs": [],
   "source": [
    "def cal_dice(roi, pred):\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "  # pred = cv.fillPoly(pred, pts= contours_pred, color=(255, 255))\n",
    "  # contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  dice_list = []\n",
    "\n",
    "  roi_num_cnt = len(contours_roi)\n",
    "  print(\"num ground truth\", roi_num_cnt)\n",
    "  print(\"num Predict:\", len(contours_pred))\n",
    "\n",
    "  for ct in contours_roi:\n",
    "              each_roi= np.zeros(roi.shape, dtype=\"uint8\")\n",
    "              each_roi = cv.fillPoly(each_roi, pts=[ct], color=(255, 255))\n",
    "\n",
    "              for ct_pred in contours_pred:\n",
    "                  each_pred = np.zeros(pred.shape, dtype=\"uint8\")\n",
    "                  each_pred = cv.fillPoly(each_pred, pts=[ct_pred], color=(255, 255))\n",
    "\n",
    "                  dice = compute_dice_1(each_roi, each_pred)\n",
    "\n",
    "                  if dice > 0:\n",
    "                       dice_list.append(dice)\n",
    "\n",
    "  return dice_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbg73rdb_T4g"
   },
   "outputs": [],
   "source": [
    "def cal_iou(roi, pred):\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "  # pred = cv.fillPoly(pred, pts= contours_pred, color=(255, 255))\n",
    "  # contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  iou_list = []\n",
    "\n",
    "  roi_num_cnt = len(contours_roi)\n",
    "  print(\"num ground truth\", roi_num_cnt)\n",
    "  print(\"num Predict:\", len(contours_pred))\n",
    "\n",
    "  for ct in contours_roi:\n",
    "              each_roi= np.zeros(roi.shape, dtype=\"uint8\")\n",
    "              each_roi = cv.fillPoly(each_roi, pts=[ct], color=(255, 255))\n",
    "\n",
    "              for ct_pred in contours_pred:\n",
    "                  each_pred = np.zeros(pred.shape, dtype=\"uint8\")\n",
    "                  each_pred = cv.fillPoly(each_pred, pts=[ct_pred], color=(255, 255))\n",
    "\n",
    "                  iou = compute_iou(each_roi, each_pred)\n",
    "\n",
    "                  if iou > 0:\n",
    "                       iou_list.append(iou)\n",
    "\n",
    "  return iou_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AKDnwoAGPr5"
   },
   "outputs": [],
   "source": [
    "def cal_dice_iou(roi, pred):\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "  # pred = cv.fillPoly(pred, pts= contours_pred, color=(255, 255))\n",
    "  # contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  dice_list = []\n",
    "  iou_list =[]\n",
    "  roi_num_cnt = len(contours_roi)\n",
    "  print(\"num ground truth\", roi_num_cnt)\n",
    "  print(\"num Predict:\", len(contours_pred))\n",
    "\n",
    "  for ct in contours_roi:\n",
    "              each_roi= np.zeros(roi.shape, dtype=\"uint8\")\n",
    "              each_roi = cv.fillPoly(each_roi, pts=[ct], color=(255, 255))\n",
    "\n",
    "              for ct_pred in contours_pred:\n",
    "                  each_pred = np.zeros(pred.shape, dtype=\"uint8\")\n",
    "                  each_pred = cv.fillPoly(each_pred, pts=[ct_pred], color=(255, 255))\n",
    "\n",
    "                  dice = compute_dice_1(each_roi, each_pred)\n",
    "                  iou = compute_iou(each_roi, each_pred)\n",
    "                  if dice > 0:\n",
    "                       dice_list.append(dice)\n",
    "                  if iou > 0:\n",
    "                       iou_list.append(iou)\n",
    "\n",
    "  return dice_list, iou_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYxfDQWIyP1n",
    "outputId": "531a2464-949c-481c-941f-5d77a0acce78"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "predict_path = \"/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/original_predict/\"\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "dice_list = []\n",
    "iou_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        pred_path= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "\n",
    "        pred = cv.imread(pred_path, 0)\n",
    "        pred, n_1 = filter_FP(pred, 300)\n",
    "\n",
    "        dice, iou = cal_dice_iou(roi, pred)\n",
    "\n",
    "        print(dice, iou)\n",
    "        dice_list.append(dice)\n",
    "        iou_list.append(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPD6bYRzShgv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'standard_dice': dice_list, 'standard_iou': iou_list})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/dice_iou_cbis_test_set_118_standard.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HQeAOErL8KrN",
    "outputId": "d4e7e573-cfd0-4abc-fddb-67b7feed0803"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "predict_path = \"/content/drive/MyDrive/Test DDSM 185 Images/without 2 skip connection/Abnormal/original_predict/\"\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "dice_list_2nd = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        pred_path= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "\n",
    "        pred = cv.imread(pred_path, 0)\n",
    "        pred, n_1 = filter_FP(pred, 300)\n",
    "\n",
    "        dice = cal_dice(roi, pred)\n",
    "\n",
    "        print(dice)\n",
    "        dice_list_2nd.append(dice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3mkNpRS_f-X",
    "outputId": "3d3d4eb3-9534-483e-c89d-edce40d81ce0"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "predict_path = \"/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/original_predict/\"\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "iou_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        pred_path= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "\n",
    "        pred = cv.imread(pred_path, 0)\n",
    "        pred, n_1 = filter_FP(pred, 300)\n",
    "\n",
    "        iou = cal_iou(roi, pred)\n",
    "\n",
    "        print(iou)\n",
    "        iou_list.append(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qdxj7dhaFkMl",
    "outputId": "95ade393-fd5f-4fb9-a62a-3650eced291b"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "predict_path = \"/content/drive/MyDrive/Test DDSM 185 Images/without 2 skip connection/Abnormal/original_predict/\"\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "iou_list_2nd = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        pred_path= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "\n",
    "        pred = cv.imread(pred_path, 0)\n",
    "        pred, n_1 = filter_FP(pred, 300)\n",
    "\n",
    "        iou = cal_iou(roi, pred)\n",
    "\n",
    "        print(iou)\n",
    "        iou_list_2nd.append(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpNq5C7jH7nW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'standard_dice': dice_list, '2nd_dice': dice_list_2nd, 'standard_iou': iou_list,'2nd_iou': iou_list_2nd })\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/dice_iou_cbis_test_set_118.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXPbcE-HH7Xn"
   },
   "source": [
    "40G ram, GPU , A100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKNkx01pxwt0"
   },
   "source": [
    "#####predict whole for each patch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OQ3FKH-FMyF"
   },
   "outputs": [],
   "source": [
    "load_model_file= tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ByHS-ip2wqfL"
   },
   "outputs": [],
   "source": [
    "patch_384 = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch 384'\n",
    "patch_512 = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch 512'\n",
    "patch_1024 = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch 1024'\n",
    "\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/draw contour'\n",
    "overlap_anotation_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/overlap anotation'\n",
    "\n",
    "import time\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "small_image = []\n",
    "num_FP_384 = []\n",
    "num_FP_512 = []\n",
    "num_FP_1024 = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # roi = cv.imread(roi_file, 0)\n",
    "        # roi= np.uint8(roi)\n",
    "        # print(roi.shape)\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "\n",
    "        y_pred_filter_384, n_384 = filter_FP(roi_predict_384, 2000)\n",
    "        num_FP_384.append(n_384)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter_384 = cv.morphologyEx(y_pred_filter_384, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter_384 = cv.morphologyEx(y_pred_filter_384, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        file_patch_384_path = os.path.join(patch_384,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_patch_384_path, y_pred_filter_384, cmap='gray')\n",
    "\n",
    "\n",
    "\n",
    "#         if 600 < w_i < 1024:\n",
    "#           roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "#           roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "\n",
    "#         elif w_i <= 600:\n",
    "#           print(\"image < 512\", name_file_saver)\n",
    "#           small_image.append(name_file_saver)\n",
    "#           continue\n",
    "#         else:\n",
    "#           roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "#           roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "#         y_pred_filter_512, n_512 = filter_FP(roi_predict_512, 2000)\n",
    "#         num_FP_512.append(n_512)\n",
    "#         y_pred_filter_512 = cv.morphologyEx(y_pred_filter_512, cv.MORPH_CLOSE, kernel)\n",
    "#         y_pred_filter_512 = cv.morphologyEx(y_pred_filter_512, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "#         file_patch_512_path = os.path.join(patch_512,\n",
    "#                                  ''.join([name_file_saver]))\n",
    "#         plt.imsave(file_patch_512_path, y_pred_filter_512, cmap='gray')\n",
    "\n",
    "\n",
    "#         y_pred_filter_1024, n_1024 = filter_FP(roi_predict_1024, 2000)\n",
    "#         num_FP_1024.append(n_1024)\n",
    "#         y_pred_filter_1024 = cv.morphologyEx(y_pred_filter_1024, cv.MORPH_CLOSE, kernel)\n",
    "#         y_pred_filter_1024 = cv.morphologyEx(y_pred_filter_1024, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "#         file_patch_1024_path = os.path.join(patch_1024,\n",
    "#                                  ''.join([name_file_saver]))\n",
    "#         plt.imsave(file_patch_1024_path, y_pred_filter_1024, cmap='gray')\n",
    "\n",
    "#         # print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "\n",
    "#         # combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "#         combine_1 = np.logical_or(roi_predict_384, roi_predict_512).astype(np.uint8)\n",
    "#         combine = np.logical_or(combine_1, roi_predict_1024).astype(np.uint8)\n",
    "\n",
    "\n",
    "#         y_pred_filter, n = filter_FP(combine, 2000)\n",
    "#         roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "#         kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "#         y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "#         y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "#         num_P_list.append(n)\n",
    "\n",
    "#         pred_file_path = os.path.join(pred_path,\n",
    "#                                  ''.join([name_file_saver]))\n",
    "#         plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "#         overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img_1(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "#         # overlap_img_anotation = 1*overlap_img_anotation\n",
    "#         img_overlap_anotation_path = os.path.join(overlap_anotation_path,\n",
    "#                                  ''.join([name_file_saver]))\n",
    "#         plt.imsave(img_overlap_anotation_path, img_anotation_1, cmap='gray')\n",
    "#         plt.title(name_file_saver)\n",
    "#         plt.imshow(img_anotation_1)\n",
    "#         plt.show()\n",
    "#         # print(overlap)\n",
    "#         area_truth_list.append(overlap_list)\n",
    "\n",
    "#         # overlap_img = 1*overlap_img\n",
    "#         file_overlap_img_path = os.path.join(overlap_path,\n",
    "#                                  ''.join([name_file_saver]))\n",
    "#         plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "#         img_draw = cv.imread(img_file)\n",
    "#         # combine_predict = cv.imread(pred_file_path, 0)\n",
    "#         img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "#         # plt.imshow(img_draw_contour)\n",
    "\n",
    "#         # plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "#         # plt.show()\n",
    "#         img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "#                                  ''.join([name_file_saver]))\n",
    "#         plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "\n",
    "# print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "q0ymN_ZBwc6K",
    "outputId": "8fee8e11-0264-45da-e141-377b6ae70f7b"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/draw contour'\n",
    "overlap_anotation_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/overlap anotation'\n",
    "\n",
    "import time\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "small_image = []\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # roi = cv.imread(roi_file, 0)\n",
    "        # roi= np.uint8(roi)\n",
    "        # print(roi.shape)\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "\n",
    "        y_pred_filter_384, n = filter_FP(roi_predict_384, 2000)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter_384 = cv.morphologyEx(y_pred_filter_384, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter_384 = cv.morphologyEx(y_pred_filter_384, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "\n",
    "\n",
    "        if 600 < w_i < 1024:\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "          roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "\n",
    "        elif w_i <= 600:\n",
    "          print(\"image < 512\", name_file_saver)\n",
    "          small_image.append(name_file_saver)\n",
    "          continue\n",
    "        else:\n",
    "          roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        # print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "\n",
    "        # combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(roi_predict_384, roi_predict_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, roi_predict_1024).astype(np.uint8)\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img_1(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        # overlap_img_anotation = 1*overlap_img_anotation\n",
    "        img_overlap_anotation_path = os.path.join(overlap_anotation_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_overlap_anotation_path, img_anotation_1, cmap='gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.show()\n",
    "        # print(overlap)\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        # overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        # combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "        # plt.imshow(img_draw_contour)\n",
    "\n",
    "        # plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "        # plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "\n",
    "print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_SUmC-0WrRt"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/original_predict'\n",
    "\n",
    "import time\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "num_P_list_1 = []\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        predict_path = pred_path + \"//\" + name_file_saver\n",
    "\n",
    "        predict = cv.imread(predict_path, 0)\n",
    "        contours, _ = cv.findContours(predict.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        FP = len(contours)\n",
    "        num_P_list_1.append(FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTN9wCaLvDH1"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "\n",
    "import time\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "num_groundtruth_list = []\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi_1, n_1 = filter_FP(roi, 300)\n",
    "        # contours, _ = cv.findContours(roi_1.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        # FP = len(contours)\n",
    "        num_groundtruth_list.append(n_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8h-hwmpwPJl",
    "outputId": "f1178dba-daf9-4d76-8ab2-78356a568b97"
   },
   "outputs": [],
   "source": [
    "len(num_groundtruth_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1PGQtJ7wHmH"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "img = data[\"img\"]\n",
    "roi = data[\"roi\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/num_GT_abnormal.csv'\n",
    "df = pd.DataFrame({'img': img, 'roi': roi, 'num_GT': num_groundtruth_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWGEgy3_X3Sj",
    "outputId": "bbda1ff3-495f-409e-8eba-37797edd0f1b"
   },
   "outputs": [],
   "source": [
    "print(len(num_P_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qkx1nafCwc6M"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "img = data[\"img\"]\n",
    "roi = data[\"roi\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/predict_abnormal.csv'\n",
    "df = pd.DataFrame({'img': img, 'roi': roi, 'overlap': area_truth_list, 'num_FP': num_P_list_1})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rueBel9b2vvG"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from csv import DictReader\n",
    "csv_path= '/content/predict_abnormal_v1.csv'\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    outwriter=csv.writer(csvfile, delimiter=',')\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        num_overlap = row['num overlap']\n",
    "        num_row_insert = int(num_overlap)\n",
    "        for n in range(num_row_insert):\n",
    "                 outwriter.writerow([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mG7hUwye41vo"
   },
   "source": [
    "##### Combine whole image - each patch size-cbis-abnormal-standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDEZubeC5BQp"
   },
   "outputs": [],
   "source": [
    "drive_path_1 = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model'\n",
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "# patch_384 = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch 384'\n",
    "# patch_512 = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch 512'\n",
    "# patch_1024 = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch 1024'\n",
    "\n",
    "predict_patch_384= sorted(glob(os.path.join(drive_path_1, 'Abnormal_each_patch_size', 'patch 384', '*')))\n",
    "predict_patch_512= sorted(glob(os.path.join(drive_path_1, 'Abnormal_each_patch_size', 'patch 512', '*')))\n",
    "predict_patch_1024= sorted(glob(os.path.join(drive_path_1, 'Abnormal_each_patch_size', 'patch 1024', '*')))\n",
    "\n",
    "img= sorted(glob(os.path.join(dataset_path, 'Abnormal', 'image', '*')))\n",
    "mask= sorted(glob(os.path.join(dataset_path, 'Abnormal', 'mask', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UA9zfmdN5NSo",
    "outputId": "cfa4f122-5c84-44c1-8593-32e31010f2ea"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': img, 'mask' : mask  ,'predict_patch_384': predict_patch_384 ,'predict_patch_512': predict_patch_512, 'predict_patch_1024': predict_patch_1024})\n",
    "df.to_csv ('/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/combine_384_512_1024_predict_whole_cbis.csv', index = False, header=True)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZpiJCKLM69cC",
    "outputId": "2d78f79d-7de8-4e74-9c45-e1eada1b9766"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/combine_384_512_1024_predict_whole_cbis.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/draw contour'\n",
    "overlap_anotation_path = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/overlap anotation'\n",
    "\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['mask']\n",
    "\n",
    "        image_anotation = cv.imread(img_file)\n",
    "\n",
    "        mask_patch_384_file = row['predict_patch_384']\n",
    "        mask_patch_512_file = row['predict_patch_512']\n",
    "        mask_patch_1024_file = row['predict_patch_1024']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0)\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        mask_512 = cv.imread(mask_patch_512_file, 0)\n",
    "        mask_1024 = cv.imread(mask_patch_1024_file, 0)\n",
    "        mask_384 = cv.imread(mask_patch_384_file, 0)\n",
    "\n",
    "        # mask_384 = np.array(mask_384)\n",
    "\n",
    "        # h,w = mask_512.shape\n",
    "\n",
    "        # mask_384 = mask_384[0:h, 0: w]\n",
    "\n",
    "        combine = np.zeros(mask_1024.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(mask_384, mask_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, mask_1024).astype(np.uint8)\n",
    "        # combine = np.array(combine)\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000 )\n",
    "\n",
    "        plt.imshow(y_pred_filter, 'gray')\n",
    "        plt.title(name_file_saver + \" - combine predict\")\n",
    "        plt.show()\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img_3(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        img_overlap_anotation_path = os.path.join(overlap_anotation_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_overlap_anotation_path, img_anotation_1, cmap='gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.show()\n",
    "\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        # overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        # combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kvxAS3bZ__v",
    "outputId": "120c6d46-c92b-44e2-fa12-d0a15f29a386"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "predict_path = \"/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/original_predict/\"\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "dice_list = []\n",
    "iou_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        pred_path= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "\n",
    "        roi = cv.imread(roi_file, 0)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "\n",
    "        pred = cv.imread(pred_path, 0)\n",
    "        pred, n_1 = filter_FP(pred, 2000)\n",
    "\n",
    "        dice, iou = cal_dice_iou(roi, pred)\n",
    "\n",
    "        print(dice, iou)\n",
    "        dice_list.append(dice)\n",
    "        iou_list.append(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsMosvnQepWf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'standard_dice': dice_list, 'standard_iou': iou_list})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/dice_iou_cbis_test_set_118_standard_13.9.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4nbDOk3aBZv"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Mammo dataset/Abnormal_each_patch_size.rar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJ285V6jS4ZE"
   },
   "source": [
    "#### tnh li overlap, iou, dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hnOLKlzzkplD",
    "outputId": "febf6296-aa79-4852-f9aa-e198b4165d0a"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Predict 118 images.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFj-COjClJLR"
   },
   "outputs": [],
   "source": [
    "drive_path_1 = '/content/Predict 118 images'\n",
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "origin_predict_standard = sorted(glob(os.path.join(drive_path_1, 'standard', 'original_predict', '*')))\n",
    "origin_predict_2nd = sorted(glob(os.path.join(drive_path_1, 'without 2 skip connection', 'original_predict', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEP802J4kxBS",
    "outputId": "f4d7b091-9074-4afa-c077-6285b658149f"
   },
   "outputs": [],
   "source": [
    "print(len(origin_predict_standard), len(origin_predict_2nd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9IBpUEFmq9i"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'origin_predict_standard': origin_predict_standard, 'origin_predict_2nd': origin_predict_2nd})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test DDSM/origin_predict_abnormal_image.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqvusjiKm5Q9"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/origin_predict_abnormal_image.csv'\n",
    "\n",
    "\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "num_Pre_standard_list = []\n",
    "num_Pre_2nd_list = []\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        origin_predict_standard_file = row['origin_predict_standard']\n",
    "        origin_predict_2nd_file = row['origin_predict_2nd']\n",
    "\n",
    "        origin_predict_standard = cv.imread(origin_predict_standard_file, 0)\n",
    "        origin_predict_2nd = cv.imread(origin_predict_2nd_file, 0)\n",
    "        # roi, n = filter_FP (roi, 300)\n",
    "        contours_standard, _ = cv.findContours(origin_predict_standard, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        contours_2nd, _ = cv.findContours(origin_predict_2nd, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        num_Pre_standard = len(contours_standard)\n",
    "        num_Pre_2nd = len(contours_2nd)\n",
    "\n",
    "        num_Pre_2nd_list.append(num_Pre_2nd)\n",
    "        num_Pre_standard_list.append(num_Pre_standard)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7A1WnfpZmQe0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'num_Pre_standard': num_Pre_standard_list, 'num_Pre_2nd': num_Pre_2nd_list})\n",
    "df.to_csv ('/content/drive/MyDrive/Mammo dataset/Test DDSM/num_predict_118__abnormal_image.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7VaJ6QVMiht"
   },
   "source": [
    "#### test abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EaxRhwtvDoY"
   },
   "outputs": [],
   "source": [
    "Mass-Training_P_00710_LEFT_CC.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yWixmqR3wFIi",
    "outputId": "16859311-d109-43e5-dc2b-e566dc177ba6"
   },
   "outputs": [],
   "source": [
    "        from patchify import patchify,  unpatchify\n",
    "        image_path = \"/content/Abnormal/image/Mass-Training_P_00710_LEFT_CC.png\"\n",
    "        roi_path = \"/content/Abnormal/mask/Mass-Training_P_00710_LEFT_CC.png\"\n",
    "\n",
    "        patch_size = 512\n",
    "        step = 64\n",
    "\n",
    "\n",
    "        large_image_1 = cv.imread(image_path, 0)\n",
    "        image_anotation = cv.imread(image_path)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_path,0)\n",
    "        roi = np.uint8(roi)\n",
    "\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "        plt.title('patch 384')\n",
    "        plt.imshow(roi_predict_384, 'gray')\n",
    "        plt.show()\n",
    "\n",
    "        if 600 < w_i < 1024:\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "          roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "\n",
    "        roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "        plt.title('patch 1024')\n",
    "        plt.imshow(roi_predict_1024, 'gray')\n",
    "        plt.show()\n",
    "\n",
    "        roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "        plt.title('patch 512')\n",
    "        plt.imshow(roi_predict_1024, 'gray')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        # print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "\n",
    "        # combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(roi_predict_384, roi_predict_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, roi_predict_1024).astype(np.uint8)\n",
    "\n",
    "        plt.title('before filter')\n",
    "        plt.imshow(combine, 'gray')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        plt.title('after filter')\n",
    "        plt.imshow(y_pred_filter, 'gray')\n",
    "        plt.show()\n",
    "\n",
    "        # num_P_list.append(n)\n",
    "\n",
    "        # pred_file_path = os.path.join(pred_path,\n",
    "        #                          ''.join([name_file_saver]))\n",
    "        # plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img_1(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        # overlap_img_anotation = 1*overlap_img_anotation\n",
    "        # img_overlap_anotation_path = os.path.join(overlap_anotation_path,\n",
    "        #                          ''.join([name_file_saver]))\n",
    "        # plt.imsave(img_overlap_anotation_path, img_anotation_1, cmap='gray')\n",
    "        plt.title('anotation 1')\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.show()\n",
    "        # print(overlap)\n",
    "        # area_truth_list.append(overlap_list)\n",
    "\n",
    "        # overlap_img = 1*overlap_img\n",
    "        # file_overlap_img_path = os.path.join(overlap_path,\n",
    "        #                          ''.join([name_file_saver]))\n",
    "        # plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "\n",
    "\n",
    "        img_draw = cv.imread(image_path)\n",
    "        # combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "\n",
    "        # plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "        plt.show()\n",
    "\n",
    "        roi = cv.imread(roi_path,0)\n",
    "        plt.imshow(roi,'gray')\n",
    "        plt.title(\"roi\")\n",
    "        plt.show()\n",
    "        # img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "        #                          ''.join([name_file_saver]))\n",
    "        # plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_Ih_b4kGF0f"
   },
   "outputs": [],
   "source": [
    "load_model_file = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8ts4kQ4wFQq"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "patch_384 = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch 384'\n",
    "patch_512 = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch 512'\n",
    "patch_1024 = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch 1024'\n",
    "\n",
    "import time\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "small_image = []\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # roi = cv.imread(roi_file, 0)\n",
    "        # roi= np.uint8(roi)\n",
    "        # print(roi.shape)\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "\n",
    "\n",
    "        if 600 < w_i < 1024:\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "          roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "\n",
    "        elif w_i <= 600:\n",
    "          print(\"image < 512\", name_file_saver)\n",
    "          small_image.append(name_file_saver)\n",
    "          continue\n",
    "        else:\n",
    "          roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "          roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        # print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "\n",
    "        # combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(roi_predict_384, roi_predict_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, roi_predict_1024).astype(np.uint8)\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img_1(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        # overlap_img_anotation = 1*overlap_img_anotation\n",
    "        img_overlap_anotation_path = os.path.join(overlap_anotation_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_overlap_anotation_path, img_anotation_1, cmap='gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.show()\n",
    "        # print(overlap)\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        # overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        # combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "        # plt.imshow(img_draw_contour)\n",
    "\n",
    "        # plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "        # plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "\n",
    "print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "It6Di4FFieR2",
    "outputId": "9861bed7-691c-4747-b6a8-aa29662156c1"
   },
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqgVTPXsNuve"
   },
   "outputs": [],
   "source": [
    "os.putenv('TF_GPU_ALLOCATOR', 'cuda_malloc_async')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "R6IThVknP4kF",
    "outputId": "556288a6-0ebb-4efc-99e9-b684259c3c93"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image_1.csv'\n",
    "# pred_path = '/content/drive/MyDrive/Test CBIS Predict/original_predict'\n",
    "# overlap_path = '/content/drive/MyDrive/Test CBIS Predict/overlap'\n",
    "# draw_contour_path = '/content/drive/MyDrive/Test CBIS Predict/draw contour'\n",
    "patch_384 = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch 384'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file,0)\n",
    "        roi = np.uint8(roi)\n",
    "\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "        # plt.title('patch 384')\n",
    "        # plt.imshow(roi_predict_384, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        y_pred_filter, n = filter_FP(roi_predict_384, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        file_patch_384_path = os.path.join(patch_384,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_patch_384_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img_1(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        area_truth_list.append(overlap_list)\n",
    "        plt.title(name_file_saver)\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        # img_draw = cv.imread(img_file)\n",
    "        # img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        # plt.imshow(img_draw_contour, 'gray')\n",
    "        # plt.title(name_file_saver)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuTg4nkdhZlB",
    "outputId": "0a9d2681-c798-4ecf-e363-e8571db27501"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0zVqdWYfVOQ",
    "outputId": "12a7cf11-722a-4fd1-ae93-bb2344a8a1cf"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNcASAudgPwZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EA8Xqn13oko0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ClearCache:\n",
    "    def __enter__(self):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Use the context manager\n",
    "with ClearCache():\n",
    "    # Define and train the PyTorch model\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_h4cHZ5z4Gx"
   },
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-8tRHAD-NQZ9",
    "outputId": "1a80cbe7-b25a-467a-a606-759d055d30ec"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image_1.csv'\n",
    "# pred_path = '/content/drive/MyDrive/Test CBIS Predict/original_predict'\n",
    "# overlap_path = '/content/drive/MyDrive/Test CBIS Predict/overlap'\n",
    "# draw_contour_path = '/content/drive/MyDrive/Test CBIS Predict/draw contour'\n",
    "patch_512 = '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch 512'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file,0)\n",
    "        roi = np.uint8(roi)\n",
    "\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "        # plt.title('patch 384')\n",
    "        # plt.imshow(roi_predict_384, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        y_pred_filter, n = filter_FP(roi_predict_512, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "\n",
    "        file_patch_512_path = os.path.join(patch_512,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_patch_512_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img_1(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.title(name_file_saver)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        # img_draw = cv.imread(img_file)\n",
    "        # img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        # plt.imshow(img_draw_contour, 'gray')\n",
    "        # plt.title(name_file_saver)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wuWROgbuA81v",
    "outputId": "96b713a6-765a-4799-cfb7-e4cc08456d7f"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "# pred_path = '/content/drive/MyDrive/Test CBIS Predict/original_predict'\n",
    "# overlap_path = '/content/drive/MyDrive/Test CBIS Predict/overlap'\n",
    "# draw_contour_path = '/content/drive/MyDrive/Test CBIS Predict/draw contour'\n",
    "patch_1024= '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch 1024'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file,0)\n",
    "        roi = np.uint8(roi)\n",
    "\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "        # plt.title('patch 384')\n",
    "        # plt.imshow(roi_predict_384, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        y_pred_filter, n = filter_FP(roi_predict_1024, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "\n",
    "        file_patch_1024_path = os.path.join(patch_1024,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_patch_1024_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img_1(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.title(name_file_saver)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        # img_draw = cv.imread(img_file)\n",
    "        # img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        # plt.imshow(img_draw_contour, 'gray')\n",
    "        # plt.title(name_file_saver)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cLXKOFGsIQDd",
    "outputId": "afb71ed2-bc85-4672-c4e3-8fbff2409756"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "# pred_path = '/content/drive/MyDrive/Test CBIS Predict/original_predict'\n",
    "# overlap_path = '/content/drive/MyDrive/Test CBIS Predict/overlap'\n",
    "# draw_contour_path = '/content/drive/MyDrive/Test CBIS Predict/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file,0)\n",
    "        roi = np.uint8(roi)\n",
    "\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "        # plt.title('patch 384')\n",
    "        # plt.imshow(roi_predict_384, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        y_pred_filter, n = filter_FP(roi_predict_384, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img_1(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour, 'gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xf64GLFWKJBV"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "img = data[\"img\"]\n",
    "roi = data[\"roi\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch_384_118_cbis.csv'\n",
    "df = pd.DataFrame({'img': img, 'roi': roi, 'overlap': area_truth_list, 'num_FP': num_P_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZZdsEY_OGgdc",
    "outputId": "d6058af8-64ba-4bc8-e5fb-4dabb2e4659b"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "# pred_path = '/content/drive/MyDrive/Test CBIS Predict/original_predict'\n",
    "# overlap_path = '/content/drive/MyDrive/Test CBIS Predict/overlap'\n",
    "# draw_contour_path = '/content/drive/MyDrive/Test CBIS Predict/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file,0)\n",
    "        roi = np.uint8(roi)\n",
    "\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "        # plt.title('patch 384')\n",
    "        # plt.imshow(roi_predict_384, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        y_pred_filter, n = filter_FP(roi_predict_512, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img_1(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour, 'gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DaqhSimSZc6P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSzVKrTsMmII"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "img = data[\"img\"]\n",
    "roi = data[\"roi\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch_512_118_cbis.csv'\n",
    "df = pd.DataFrame({'img': img, 'roi': roi, 'overlap': area_truth_list, 'num_FP': num_P_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oNLmoKZpMsiv",
    "outputId": "ab0aee69-ee5d-4899-8c6b-1204ca122391"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Mammo dataset/Test DDSM/abnormal_image.csv'\n",
    "# pred_path = '/content/drive/MyDrive/Test CBIS Predict/original_predict'\n",
    "# overlap_path = '/content/drive/MyDrive/Test CBIS Predict/overlap'\n",
    "# draw_contour_path = '/content/drive/MyDrive/Test CBIS Predict/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file,0)\n",
    "        roi = np.uint8(roi)\n",
    "\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        if (h_i>=h_r) or (w_i>=w_r):\n",
    "          img = img[0:h_r, 0:w_r]\n",
    "          image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        else:\n",
    "          roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "        # plt.title('patch 384')\n",
    "        # plt.imshow(roi_predict_384, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        y_pred_filter, n = filter_FP(roi_predict_1024, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1 = cal_overlaps_per_large_img_1(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour, 'gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JR6HDHaZRNpH"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "img = data[\"img\"]\n",
    "roi = data[\"roi\"]\n",
    "import pandas as pd\n",
    "save_csv_path= '/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal_each_patch_size/patch_1024_118_cbis.csv'\n",
    "df = pd.DataFrame({'img': img, 'roi': roi, 'overlap': area_truth_list, 'num_FP': num_P_list})\n",
    "df.to_csv (save_csv_path, index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQdEJloD6c5e"
   },
   "source": [
    "####V trn c 2 m hnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2TQZkpS6jlh"
   },
   "outputs": [],
   "source": [
    "def large_image_roi_predict_pred_2nd_overlap(image, roi, pred, pred_2nd):\n",
    "\n",
    "    _, binarized = cv.threshold(roi, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_roi, hierarchy = cv.findContours(binarized, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    _, binarized = cv.threshold(pred, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_pred, hierarchy = cv.findContours(binarized,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    _, binarized_2nd = cv.threshold(pred_2nd, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_pred_2nd, hierarchy = cv.findContours(binarized_2nd,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    img_copy = image.copy()\n",
    "    cv.drawContours(img_copy, contours_roi,-1,(255,0,0),2)\n",
    "    cv.drawContours(img_copy, contours_pred,-1, (0,255,0), 2)\n",
    "    cv.drawContours(img_copy, contours_pred_2nd,-1, (0,0,255), 2)\n",
    "    plt.imshow(img_copy)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image')\n",
    "    plt.show()\n",
    "    pred_file_path = os.path.join(save_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "    plt.imsave(pred_file_path, img_copy, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "AsT0KZ8G7DWQ",
    "outputId": "7ee7367c-2172-463c-80e0-7be37c8ad51c"
   },
   "outputs": [],
   "source": [
    "image_path = \"/content/Abnormal/image/Mass-Training_P_01039_RIGHT_CC.png\"\n",
    "roi_path = \"/content/Abnormal/mask/Mass-Training_P_01039_RIGHT_CC.png\"\n",
    "predict_path = \"/content/Predict 118 images/standard/original_predict/Mass-Training_P_01039_RIGHT_CC.png\"\n",
    "predict_2nd_path =\"/content/Predict 118 images/without 2 skip connection/original_predict/Mass-Training_P_01039_RIGHT_CC.png\"\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Mammo dataset\"\n",
    "name_file_saver = os.path.basename(image_path)\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "predict_2nd = cv.imread(predict_2nd_path, 0).astype(np.uint8)\n",
    "predict_2nd = np.array(predict_2nd)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "large_image_roi_predict_pred_2nd_overlap(image, roi, predict, predict_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "sCyvsUFw7dAa",
    "outputId": "cc83f7bb-dd63-4f8a-f2af-8a3e3b1fac93"
   },
   "outputs": [],
   "source": [
    "image_path = \"/content/Abnormal/image/Mass-Training_P_01596_RIGHT_MLO.png\"\n",
    "roi_path = \"/content/Abnormal/mask/Mass-Training_P_01596_RIGHT_MLO.png\"\n",
    "predict_path = \"/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/original_predict/Mass-Training_P_01596_RIGHT_MLO.png\"\n",
    "predict_2nd_path =\"/content/drive/MyDrive/Test DDSM 185 Images/without 2 skip connection/Abnormal/original_predict/Mass-Training_P_01596_RIGHT_MLO.png\"\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Test DDSM 185 Images\"\n",
    "name_file_saver = os.path.basename(image_path)\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "predict_2nd = cv.imread(predict_2nd_path, 0).astype(np.uint8)\n",
    "predict_2nd = np.array(predict_2nd)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "large_image_roi_predict_pred_2nd_overlap(image, roi, predict, predict_2nd)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "vIf3T_i473_l",
    "outputId": "941aa1e5-10b9-4190-9396-e4e2efa9c600"
   },
   "outputs": [],
   "source": [
    "image_path = \"/content/Abnormal/image/P_01833_RIGHT_MLO.png\"\n",
    "roi_path = \"/content/Abnormal/mask/P_01833_RIGHT_MLO.png\"\n",
    "predict_path = \"/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/original_predict/P_01833_RIGHT_MLO.png\"\n",
    "predict_2nd_path =\"/content/drive/MyDrive/Test DDSM 185 Images/without 2 skip connection/Abnormal/original_predict/P_01833_RIGHT_MLO.png\"\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Test DDSM 185 Images\"\n",
    "name_file_saver = os.path.basename(image_path)\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "predict_2nd = cv.imread(predict_2nd_path, 0).astype(np.uint8)\n",
    "predict_2nd = np.array(predict_2nd)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "large_image_roi_predict_pred_2nd_overlap(image, roi, predict, predict_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "1827AJle8vVJ",
    "outputId": "b61d60dd-cacb-49a8-9c7a-fbed7a4e6fc2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_path = \"/content/Abnormal/image/Mass-Training_P_00573_RIGHT_MLO.png\"\n",
    "roi_path = \"/content/Abnormal/mask/Mass-Training_P_00573_RIGHT_MLO.png\"\n",
    "predict_path = \"/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/original_predict/Mass-Training_P_00573_RIGHT_MLO.png\"\n",
    "predict_2nd_path =\"/content/drive/MyDrive/Test DDSM 185 Images/without 2 skip connection/Abnormal/original_predict/Mass-Training_P_00573_RIGHT_MLO.png\"\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Test DDSM 185 Images\"\n",
    "name_file_saver = os.path.basename(image_path)\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "predict_2nd = cv.imread(predict_2nd_path, 0).astype(np.uint8)\n",
    "predict_2nd = np.array(predict_2nd)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "large_image_roi_predict_pred_2nd_overlap(image, roi, predict, predict_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "4AGWr4bt9G2H",
    "outputId": "d58031a5-31d1-415a-e529-1fc3c4ffc9be"
   },
   "outputs": [],
   "source": [
    "\n",
    "image_path = \"/content/Abnormal/image/Mass-Training_P_01152_RIGHT_CC.png\"\n",
    "roi_path = \"/content/Abnormal/mask/Mass-Training_P_01152_RIGHT_CC.png\"\n",
    "predict_path = \"/content/drive/MyDrive/Test DDSM 185 Images/Standard Model/Abnormal/original_predict/Mass-Training_P_01152_RIGHT_CC.png\"\n",
    "predict_2nd_path =\"/content/drive/MyDrive/Test DDSM 185 Images/without 2 skip connection/Abnormal/original_predict/Mass-Training_P_01152_RIGHT_CC.png\"\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Test DDSM 185 Images\"\n",
    "name_file_saver = os.path.basename(image_path)\n",
    "predict = cv.imread(predict_path, 0).astype(np.uint8)\n",
    "predict = np.array(predict)\n",
    "\n",
    "predict_2nd = cv.imread(predict_2nd_path, 0).astype(np.uint8)\n",
    "predict_2nd = np.array(predict_2nd)\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "roi = cv.imread(roi_path, 0).astype(np.uint8)\n",
    "roi = np.array(roi)\n",
    "\n",
    "large_image_roi_predict_pred_2nd_overlap(image, roi, predict, predict_2nd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFRLXvHuv7Jr"
   },
   "source": [
    "### CBIS Valid Whole Images - 285"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWUp-6fQ5cSE"
   },
   "source": [
    "####Standard model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29K10ob87Gf4"
   },
   "source": [
    "######read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vfbkEP558kV",
    "outputId": "5698a5aa-964d-4d9b-908c-6208f24eda4c"
   },
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0Lk3qPgwARN",
    "outputId": "5c65ce42-4404-4bd1-ba35-64b806d9d18d"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/CBIS Valid Whole Images 285/CBIS-Validation-Test-Whole-image.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWtsBK6y5fXD"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'Image', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'Mask', '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ud6Relyv5pLt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y})\n",
    "df.to_csv ('/content/drive/MyDrive/CBIS Valid Whole Images 285/CBIS Valid Whole images.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kp47Frwd54fl"
   },
   "outputs": [],
   "source": [
    "load_model_file = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udI14SPJ6DyQ"
   },
   "outputs": [],
   "source": [
    "def show_y_predict(randomlist, y, y_pred):\n",
    "  fg, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[0, i].imshow(np.squeeze(y[index]), 'gray')\n",
    "    ax[0, i].set_xlabel('y ' + str(index))\n",
    "    # print(y[index].shape)\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[1, i].imshow(np.squeeze(y_pred[index]), 'gray')\n",
    "    ax[1, i].set_xlabel('y_pred ' + str(index))\n",
    "\n",
    "def prediction(model, large_image, patch_size, step):\n",
    "  patches = patchify(large_image, (patch_size, patch_size), step=step)  #Step=256 for 256 patches means no overlap\n",
    "\n",
    "  print(patches.shape)\n",
    "\n",
    "  redicted_patches = []\n",
    "  patches_input = []\n",
    "  for i in range(patches.shape[0]):\n",
    "    for j in range(patches.shape[1]):\n",
    "        # print(i,j)\n",
    "        single_patch = patches[i,j,:,:]\n",
    "        single_patch_input=np.expand_dims(single_patch, -1)\n",
    "        # single_patch = np.array(single_patch)\n",
    "        # print(single_patch.shape)\n",
    "        #Predict and threshold for values above 0.5 probability\n",
    "\n",
    "        single_patch_input = np.zeros((patch_size,patch_size,3), dtype=\"float32\")\n",
    "        single_patch_input[:,:,0] = single_patch\n",
    "        single_patch_input[:,:,1] = single_patch\n",
    "        single_patch_input[:,:,2] = single_patch\n",
    "\n",
    "        single_patch_input = cv.resize(single_patch_input, (256,256), cv.INTER_AREA)\n",
    "        single_patch_input = np.array(single_patch_input)\n",
    "        patches_input.append(single_patch_input)\n",
    "\n",
    "  patches_input = np.array(patches_input)\n",
    "\n",
    "  patches_prediction = (model.predict(patches_input) >= 0.5).astype(np.uint8)\n",
    "\n",
    "  # randomlist = random.sample(range(0, len(patches_prediction)),5)\n",
    "  # show_y_predict(randomlist, patches_input, patches_prediction)\n",
    "  # plt.show()\n",
    "\n",
    "  patches_prediction_resize = []\n",
    "  for i in patches_prediction:\n",
    "    i = cv.resize(i, (patch_size,patch_size), cv.INTER_AREA)\n",
    "    patches_prediction_resize.append(i)\n",
    "\n",
    "  predicted_patches_reshaped = np.reshape(patches_prediction_resize, (patches.shape[0], patches.shape[1], patch_size,patch_size) )\n",
    "  # print(predicted_patches_reshaped.shape)\n",
    "\n",
    "  reconstructed_image = unpatchify(predicted_patches_reshaped, large_image.shape)\n",
    "  plt.imshow(np.squeeze(reconstructed_image), cmap='gray')\n",
    "  return reconstructed_image\n",
    "\n",
    "def filter_FP(y_pred, thresh):\n",
    "  y_pred_filter = y_pred.copy()\n",
    "  kernel = np.ones((3,3),np.uint8)\n",
    "  y_pred_filter = cv.erode(y_pred_filter, kernel)\n",
    "\n",
    "  contours, _ = cv.findContours(y_pred_filter.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "  n = 0\n",
    "  for ct in contours:\n",
    "      contour_area = cv.contourArea(ct)\n",
    "      if (contour_area>= thresh):\n",
    "          n += 1\n",
    "      else:\n",
    "        y_pred_filter = cv.fillPoly(y_pred_filter, pts=[ct], color=(0, 0))\n",
    "  y_pred_filter =  cv.dilate(y_pred_filter, kernel)\n",
    "  return y_pred_filter, n\n",
    "\n",
    "\n",
    "def draw_contour_pred_and_truth(large_image, pred, roi):\n",
    "  img_copy = large_image.copy()\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  cv.drawContours(img_copy, contours_roi , -1, (255,0,0), 3)\n",
    "  cv.drawContours(img_copy, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "  return img_copy\n",
    "\n",
    "def check_Left_Orient(img, roi):\n",
    "    left_nonzero = cv.countNonZero(img[:, 0:int(img.shape[1] / 2)])\n",
    "    right_nonzero = cv.countNonZero(img[:, int(img.shape[1] / 2):])\n",
    "\n",
    "    if (left_nonzero <= right_nonzero):\n",
    "            img = cv.flip(img, 1)\n",
    "            roi = cv.flip(roi, 1)\n",
    "\n",
    "    return img, roi\n",
    "\n",
    "def cal_overlap_per_large_img(roi, overlap_img):\n",
    "  bitwise_and_roi_pred = cv.bitwise_and(overlap_img, roi)\n",
    "  area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "  overlap = round(area_truth / np.count_nonzero(roi), 4)*100\n",
    "  return bitwise_and_roi_pred, area_truth, overlap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAtoFZsF6Xl8"
   },
   "outputs": [],
   "source": [
    "def detect_roi_by_patch_size(img, load_model_file, patch_size, step):\n",
    "\n",
    "        h,w = img.shape\n",
    "\n",
    "        roi_detect= np.zeros(img.shape, dtype=\"uint8\")\n",
    "\n",
    "        row = int(( h - patch_size)/step)\n",
    "        col = int(( w - patch_size)/step)\n",
    "        new_img_h = row * step + patch_size\n",
    "        new_img_w = col * step + patch_size\n",
    "\n",
    "        img_by_patch_size = img[0:new_img_h, 0: new_img_w]\n",
    "\n",
    "        segmented_image_by_patch_size = prediction(load_model_file, img_by_patch_size, patch_size , step)\n",
    "        h_1, w_1 = segmented_image_by_patch_size.shape\n",
    "        roi_detect[0:h_1, 0:w_1] = segmented_image_by_patch_size\n",
    "\n",
    "\n",
    "        return roi_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJsQIAvW6e4_"
   },
   "outputs": [],
   "source": [
    "def cal_overlaps_per_large_img(roi, pred, large_image):\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  img = large_image.copy()\n",
    "\n",
    "  overlap_list = []\n",
    "\n",
    "  roi_num_cnt = len(contours_roi)\n",
    "\n",
    "  if  roi_num_cnt == 1:\n",
    "       bitwise_and_roi_pred = cv.bitwise_and(pred, roi)\n",
    "       area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "       overlap = round(area_truth/np.count_nonzero(roi) * 100,2)\n",
    "       overlap_list.append(overlap)\n",
    "       print(\"overlap\", overlap)\n",
    "       cv.drawContours(img, contours_roi , -1, (255,0,0), 3)\n",
    "       cv.drawContours(img, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "       if overlap!=0:\n",
    "\n",
    "           contours_overlaps, _ = cv.findContours(bitwise_and_roi_pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "           c = max(contours_overlaps, key = cv.contourArea)\n",
    "\n",
    "           x, y, w, h = cv.boundingRect(c)\n",
    "\n",
    "           font = cv.FONT_HERSHEY_SIMPLEX\n",
    "           org = (x-10, y-10)\n",
    "           fontScale = 3\n",
    "           color = (0, 0, 255)\n",
    "           thickness = 2\n",
    "           text = str(overlap)\n",
    "           img = cv.putText(img, text, org, font, fontScale, color, thickness, cv.LINE_AA)\n",
    "\n",
    "  else:\n",
    "       bitwise_and_roi_pred = cv.bitwise_and(pred, roi)\n",
    "       for ct in contours_roi:\n",
    "            each_roi= np.zeros(roi.shape, dtype=\"uint8\")\n",
    "            each_roi = cv.fillPoly(each_roi, pts=[ct], color=(255, 255, 255))\n",
    "            # plt.imshow(each_roi, 'gray')\n",
    "            # plt.show()\n",
    "            cv.drawContours(img, ct , -1, (255,0,0), 3)\n",
    "\n",
    "            for ct_pred in contours_pred:\n",
    "                  each_pred = np.zeros(pred.shape, dtype=\"uint8\")\n",
    "                  each_pred = cv.fillPoly(each_pred, pts=[ct_pred], color=(255, 255, 255))\n",
    "\n",
    "                  # plt.imshow(each_pred, 'gray')\n",
    "                  # plt.show()\n",
    "\n",
    "                  bitwise_and_roi_pred_1 = cv.bitwise_and(each_pred, each_roi)\n",
    "\n",
    "                  area_truth = np.count_nonzero(bitwise_and_roi_pred_1)\n",
    "                  overlap = round(area_truth/np.count_nonzero(each_roi) *100,3)\n",
    "                  cv.drawContours(img, ct_pred, -1, (0,255,0), 3)\n",
    "\n",
    "                  # cv.drawContours(img, ct_pred , -1, (255,0,0), 3)\n",
    "\n",
    "                  if overlap>0:\n",
    "                       overlap_list.append(overlap)\n",
    "                       print(\"overlap\", overlap)\n",
    "\n",
    "                       x, y, w, h = cv.boundingRect(ct_pred)\n",
    "\n",
    "                      #  overlap_img_anotation = cv.fillPoly(overlap_img_anotation, pts=[ct_pred], color=(0, 0))\n",
    "\n",
    "                      #  overlap_img_anotation = ImageDraw.Draw(overlap_img_anotation)\n",
    "                      #  overlap_img_anotation.text((x, y), overlap, fill=(0 , 0, 255))\n",
    "                       font = cv.FONT_HERSHEY_SIMPLEX\n",
    "                       org = (x-10, y-20)\n",
    "                       fontScale = 3\n",
    "                       color = (0, 0, 255)\n",
    "                       thickness = 2\n",
    "                       text = str(overlap)\n",
    "                       img = cv.putText(img, text, org, font, fontScale, color, thickness, cv.LINE_AA)\n",
    "  # cv.imshow(overlap_img_anotation, 0)\n",
    "  plt.imshow(bitwise_and_roi_pred, 'gray')\n",
    "  plt.show()\n",
    "  # plt.imshow(img)\n",
    "  # plt.show()\n",
    "  return bitwise_and_roi_pred, overlap_list, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPLeEXPx6mr3"
   },
   "outputs": [],
   "source": [
    "def cal_overlaps_per_large_img_3(roi, pred, large_image):\n",
    "  roi, n_1 = filter_FP(roi, 300)\n",
    "  pred, n = filter_FP(pred, 2000)\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # pred = cv.fillPoly(pred, pts= contours_pred, color=(255, 255))\n",
    "  # contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  img = large_image.copy()\n",
    "\n",
    "  overlap_list = []\n",
    "\n",
    "  roi_num_cnt = len(contours_roi)\n",
    "  print(\"num ground truth\", roi_num_cnt)\n",
    "  print(\"num Predict:\", len(contours_pred))\n",
    "\n",
    "  bitwise_and_roi_pred = cv.bitwise_and(pred, roi)\n",
    "\n",
    "  cv.drawContours(img, contours_roi , -1, (255,0,0), 3)\n",
    "  cv.drawContours(img, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "  for ct in contours_roi:\n",
    "              each_roi= np.zeros(roi.shape, dtype=\"uint8\")\n",
    "              each_roi = cv.fillPoly(each_roi, pts=[ct], color=(255, 255))\n",
    "\n",
    "              for ct_pred in contours_pred:\n",
    "                  each_pred = np.zeros(pred.shape, dtype=\"uint8\")\n",
    "                  each_pred = cv.fillPoly(each_pred, pts=[ct_pred], color=(255, 255))\n",
    "\n",
    "                  bitwise_and_roi_pred_1 = cv.bitwise_and(each_pred, each_roi)\n",
    "                  area_truth = np.count_nonzero(bitwise_and_roi_pred_1)\n",
    "\n",
    "                  if area_truth > 0:\n",
    "                       overlap = round(area_truth/np.count_nonzero(each_roi) * 100,3)\n",
    "                       overlap_list.append(overlap)\n",
    "                       print(\"overlap\", overlap)\n",
    "\n",
    "                       x, y, w, h = cv.boundingRect(ct_pred)\n",
    "\n",
    "                       font = cv.FONT_HERSHEY_SIMPLEX\n",
    "                       org = (x-10, y-20)\n",
    "                       fontScale = 3\n",
    "                       color = (0, 0, 255)\n",
    "                       thickness = 2\n",
    "                       text = str(overlap)\n",
    "                       img = cv.putText(img, text, org, font, fontScale, color, thickness, cv.LINE_AA)\n",
    "\n",
    "  plt.imshow(bitwise_and_roi_pred, 'gray')\n",
    "  plt.title('bitwise_and')\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "  return bitwise_and_roi_pred, overlap_list, img, roi_num_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slhAsaIS7LhQ"
   },
   "source": [
    "##### predict full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjUXp8sGDBxr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# To RunOptions\n",
    "options = tf.RunOptions(report_tensor_allocations_upon_oom=True)\n",
    "\n",
    "# S dng RunOptions khi chy mt session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(your_operation, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKubeXopCQBy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "run_opts = tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HF-Wd0l06vnP",
    "outputId": "f1cf30f2-d8f5-4310-fea7-d821b0006444"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/CBIS Valid Whole images_1.csv'\n",
    "pred_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/draw contour'\n",
    "overlap_anotation_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/overlap anotation'\n",
    "\n",
    "patch_384 = '/content/drive/MyDrive/CBIS Valid Whole Images 285/patch 384'\n",
    "patch_512 = '/content/drive/MyDrive/CBIS Valid Whole Images 285/patch 512'\n",
    "patch_1024 = '/content/drive/MyDrive/CBIS Valid Whole Images 285/patch 1024'\n",
    "\n",
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "ground_truth = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # roi = cv.imread(roi_file, 0)\n",
    "        # roi= np.uint8(roi)\n",
    "        # print(roi.shape)\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        # if (h_i>=h_r) or (w_i>=w_r):\n",
    "        #   img = img[0:h_r, 0:w_r]\n",
    "        #   image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        # else:\n",
    "        #   roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "        y_pred_filter_384, n_384 = filter_FP(roi_predict_384, 2000)\n",
    "\n",
    "        pred_file_path_384 = os.path.join(patch_384,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path_384, y_pred_filter_384, cmap='gray')\n",
    "\n",
    "\n",
    "        roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        y_pred_filter_512, n_512 = filter_FP(roi_predict_512, 2000)\n",
    "\n",
    "        pred_file_path_512 = os.path.join(patch_512,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path_512, y_pred_filter_512, cmap='gray')\n",
    "\n",
    "        if w_i < 1024:\n",
    "          roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "        else:\n",
    "          roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "\n",
    "        y_pred_filter_1024, n_1024 = filter_FP(roi_predict_1024, 2000)\n",
    "\n",
    "        pred_file_path_1024 = os.path.join(patch_1024,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path_1024, y_pred_filter_1024, cmap='gray')\n",
    "\n",
    "\n",
    "        # print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "        combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(y_pred_filter_384, y_pred_filter_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, y_pred_filter_1024).astype(np.uint8)\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1, num_GT = cal_overlaps_per_large_img_3(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        ground_truth.append(num_GT)\n",
    "\n",
    "        # overlap_img_anotation = 1*overlap_img_anotation\n",
    "        img_overlap_anotation_path = os.path.join(overlap_anotation_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_overlap_anotation_path, img_anotation_1, cmap='gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.show()\n",
    "        # print(overlap)\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        # overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        # combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "        # plt.imshow(img_draw_contour)\n",
    "\n",
    "        # plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "        # plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "        torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aJUKuxBmFpoB",
    "outputId": "627f6841-7ede-47db-e13b-2ce22d2ca884"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/CBIS Valid Whole images_1.csv'\n",
    "pred_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/draw contour'\n",
    "overlap_anotation_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/overlap anotation'\n",
    "\n",
    "patch_384 = '/content/drive/MyDrive/CBIS Valid Whole Images 285/patch 384'\n",
    "patch_512 = '/content/drive/MyDrive/CBIS Valid Whole Images 285/patch 512'\n",
    "patch_1024 = '/content/drive/MyDrive/CBIS Valid Whole Images 285/patch 1024'\n",
    "\n",
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "ground_truth = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # roi = cv.imread(roi_file, 0)\n",
    "        # roi= np.uint8(roi)\n",
    "        # print(roi.shape)\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        # if (h_i>=h_r) or (w_i>=w_r):\n",
    "        #   img = img[0:h_r, 0:w_r]\n",
    "        #   image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        # else:\n",
    "        #   roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "        y_pred_filter_384, n_384 = filter_FP(roi_predict_384, 2000)\n",
    "\n",
    "        pred_file_path_384 = os.path.join(patch_384,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path_384, y_pred_filter_384, cmap='gray')\n",
    "\n",
    "\n",
    "        roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        y_pred_filter_512, n_512 = filter_FP(roi_predict_512, 2000)\n",
    "\n",
    "        pred_file_path_512 = os.path.join(patch_512,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path_512, y_pred_filter_512, cmap='gray')\n",
    "\n",
    "        if w_i < 1024:\n",
    "          roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "        else:\n",
    "          roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "\n",
    "        y_pred_filter_1024, n_1024 = filter_FP(roi_predict_1024, 2000)\n",
    "\n",
    "        pred_file_path_1024 = os.path.join(patch_1024,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path_1024, y_pred_filter_1024, cmap='gray')\n",
    "\n",
    "\n",
    "        # print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "        combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(y_pred_filter_384, y_pred_filter_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, y_pred_filter_1024).astype(np.uint8)\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1, num_GT = cal_overlaps_per_large_img_3(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        ground_truth.append(num_GT)\n",
    "\n",
    "        # overlap_img_anotation = 1*overlap_img_anotation\n",
    "        img_overlap_anotation_path = os.path.join(overlap_anotation_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_overlap_anotation_path, img_anotation_1, cmap='gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.show()\n",
    "        # print(overlap)\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        # overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        # combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "        # plt.imshow(img_draw_contour)\n",
    "\n",
    "        # plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "        # plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "x5rxfrhFLHRs",
    "outputId": "e832a6e0-3508-4638-c326-82a026e017aa"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/CBIS Valid Whole images_1.csv'\n",
    "pred_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/draw contour'\n",
    "overlap_anotation_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/overlap anotation'\n",
    "\n",
    "patch_384 = '/content/drive/MyDrive/CBIS Valid Whole Images 285/patch 384'\n",
    "patch_512 = '/content/drive/MyDrive/CBIS Valid Whole Images 285/patch 512'\n",
    "patch_1024 = '/content/drive/MyDrive/CBIS Valid Whole Images 285/patch 1024'\n",
    "\n",
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "ground_truth = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # roi = cv.imread(roi_file, 0)\n",
    "        # roi= np.uint8(roi)\n",
    "        # print(roi.shape)\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        # if (h_i>=h_r) or (w_i>=w_r):\n",
    "        #   img = img[0:h_r, 0:w_r]\n",
    "        #   image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        # else:\n",
    "        #   roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "        y_pred_filter_384, n_384 = filter_FP(roi_predict_384, 2000)\n",
    "\n",
    "        pred_file_path_384 = os.path.join(patch_384,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path_384, y_pred_filter_384, cmap='gray')\n",
    "\n",
    "\n",
    "        roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        y_pred_filter_512, n_512 = filter_FP(roi_predict_512, 2000)\n",
    "\n",
    "        pred_file_path_512 = os.path.join(patch_512,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path_512, y_pred_filter_512, cmap='gray')\n",
    "\n",
    "        if w_i < 1024:\n",
    "          roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "        else:\n",
    "          roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "\n",
    "        y_pred_filter_1024, n_1024 = filter_FP(roi_predict_1024, 2000)\n",
    "\n",
    "        pred_file_path_1024 = os.path.join(patch_1024,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path_1024, y_pred_filter_1024, cmap='gray')\n",
    "\n",
    "\n",
    "        # print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "        combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(y_pred_filter_384, y_pred_filter_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, y_pred_filter_1024).astype(np.uint8)\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1, num_GT = cal_overlaps_per_large_img_3(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        ground_truth.append(num_GT)\n",
    "\n",
    "        # overlap_img_anotation = 1*overlap_img_anotation\n",
    "        img_overlap_anotation_path = os.path.join(overlap_anotation_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_overlap_anotation_path, img_anotation_1, cmap='gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.show()\n",
    "        # print(overlap)\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        # overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        # combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "        # plt.imshow(img_draw_contour)\n",
    "\n",
    "        # plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "        # plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jKP5yCcxV_yZ",
    "outputId": "695efbd6-2474-4c31-bc07-8931f774d3b6"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/CBIS Valid Whole images_1.csv'\n",
    "pred_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/draw contour'\n",
    "overlap_anotation_path = '/content/drive/MyDrive/CBIS Valid Whole Images 285/Standard model/overlap anotation'\n",
    "\n",
    "patch_384 = '/content/drive/MyDrive/CBIS Valid Whole Images 285/patch 384'\n",
    "patch_512 = '/content/drive/MyDrive/CBIS Valid Whole Images 285/patch 512'\n",
    "patch_1024 = '/content/drive/MyDrive/CBIS Valid Whole Images 285/patch 1024'\n",
    "\n",
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "ground_truth = []\n",
    "num_P_list = []\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        # path = os.path.dirname(img_file)\n",
    "        name_file_saver = os.path.basename(img_file)\n",
    "\n",
    "        large_image_1 = cv.imread(img_file, 0)\n",
    "        image_anotation = cv.imread(img_file)\n",
    "        large_image= np.float32(large_image_1)\n",
    "        large_image = large_image/255.0\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        # roi = cv.imread(roi_file, 0)\n",
    "        # roi= np.uint8(roi)\n",
    "        # print(roi.shape)\n",
    "        h_r, w_r = roi.shape\n",
    "\n",
    "        large_image, roi= check_Left_Orient (large_image, roi)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h_i, w_i = img.shape\n",
    "\n",
    "        # if (h_i>=h_r) or (w_i>=w_r):\n",
    "        #   img = img[0:h_r, 0:w_r]\n",
    "        #   image_anotation = image_anotation[0:h_r, 0:w_r]\n",
    "        # else:\n",
    "        #   roi = roi[0:h_i, 0:w_i]\n",
    "\n",
    "        # print(img.shape)\n",
    "\n",
    "        roi_predict_384 = detect_roi_by_patch_size(img, load_model_file, 348, 64)\n",
    "        y_pred_filter_384, n_384 = filter_FP(roi_predict_384, 2000)\n",
    "\n",
    "        pred_file_path_384 = os.path.join(patch_384,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path_384, y_pred_filter_384, cmap='gray')\n",
    "\n",
    "\n",
    "        roi_predict_512 = detect_roi_by_patch_size(img, load_model_file, 512, 64)\n",
    "\n",
    "        y_pred_filter_512, n_512 = filter_FP(roi_predict_512, 2000)\n",
    "\n",
    "        pred_file_path_512 = os.path.join(patch_512,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path_512, y_pred_filter_512, cmap='gray')\n",
    "\n",
    "        if w_i < 1024:\n",
    "          roi_predict_1024 = np.zeros(img.shape, dtype=\"uint8\")\n",
    "        else:\n",
    "          roi_predict_1024 = detect_roi_by_patch_size(img, load_model_file, 1024, 128)\n",
    "\n",
    "        y_pred_filter_1024, n_1024 = filter_FP(roi_predict_1024, 2000)\n",
    "\n",
    "        pred_file_path_1024 = os.path.join(patch_1024,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path_1024, y_pred_filter_1024, cmap='gray')\n",
    "\n",
    "\n",
    "        # print(roi_predict_384.shape, roi_predict_512.shape, roi_predict_1024.shape)\n",
    "\n",
    "        combine = np.zeros(roi.shape, dtype=np.uint8)\n",
    "\n",
    "        combine_1 = np.logical_or(y_pred_filter_384, y_pred_filter_512).astype(np.uint8)\n",
    "        combine = np.logical_or(combine_1, y_pred_filter_1024).astype(np.uint8)\n",
    "\n",
    "\n",
    "        y_pred_filter, n = filter_FP(combine, 2000)\n",
    "        roi, n_1 = filter_FP(roi, 300)\n",
    "\n",
    "        num_P_list.append(n)\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "\n",
    "        overlap_img, overlap_list, img_anotation_1, num_GT = cal_overlaps_per_large_img_3(roi, y_pred_filter, image_anotation)\n",
    "\n",
    "        ground_truth.append(num_GT)\n",
    "\n",
    "        # overlap_img_anotation = 1*overlap_img_anotation\n",
    "        img_overlap_anotation_path = os.path.join(overlap_anotation_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_overlap_anotation_path, img_anotation_1, cmap='gray')\n",
    "        plt.title(name_file_saver)\n",
    "        plt.imshow(img_anotation_1)\n",
    "        plt.show()\n",
    "        # print(overlap)\n",
    "        area_truth_list.append(overlap_list)\n",
    "\n",
    "        # overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        # combine_predict = cv.imread(pred_file_path, 0)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw, y_pred_filter, roi)\n",
    "\n",
    "        # plt.imshow(img_draw_contour)\n",
    "\n",
    "        # plt.title(name_file_saver + \"- overlap = \"+ str(overlap))\n",
    "        # plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3QuUjOT7Dnn"
   },
   "source": [
    "###Test VinDr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlZQ4tdV7HGP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12ImeYJ62SqH"
   },
   "source": [
    "###Test Ultrasound BUSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXPQhmsw2VhW"
   },
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BIrZlNv2bTO"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/MyDrive/Test-Ultrasound-Busi/data_benign.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9hNubjk2f0Z",
    "outputId": "5d6f2beb-adc0-478c-c4e9-d5491763df6b"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'data_benign', 'img', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'data_benign', 'mask', '*')))\n",
    "\n",
    "print(len(test_x), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbWqHDpg2ikm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y})\n",
    "df.to_csv ('/content/drive/MyDrive/Test-Ultrasound-Busi/data_benign.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zSpgSaQ2xJu"
   },
   "outputs": [],
   "source": [
    "def show_y_predict(randomlist, y, y_pred):\n",
    "  fg, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[0, i].imshow(np.squeeze(y[index]), 'gray')\n",
    "    ax[0, i].set_xlabel('y ' + str(index))\n",
    "    # print(y[index].shape)\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[1, i].imshow(np.squeeze(y_pred[index]), 'gray')\n",
    "    ax[1, i].set_xlabel('y_pred ' + str(index))\n",
    "\n",
    "\n",
    "def filter_FP(y_pred, thresh):\n",
    "  y_pred_filter = y_pred.copy()\n",
    "  kernel = np.ones((3,3),np.uint8)\n",
    "  y_pred_filter = cv.erode(y_pred_filter, kernel)\n",
    "\n",
    "  contours, _ = cv.findContours(y_pred_filter.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "  n = 0\n",
    "  for ct in contours:\n",
    "      contour_area = cv.contourArea(ct)\n",
    "      if (contour_area>= thresh):\n",
    "          n += 1\n",
    "      else:\n",
    "        y_pred_filter = cv.fillPoly(y_pred_filter, pts=[ct], color=(0, 0))\n",
    "  y_pred_filter =  cv.dilate(y_pred_filter, kernel)\n",
    "  return y_pred_filter, n\n",
    "\n",
    "\n",
    "def draw_contour_pred_and_truth(large_image, pred, roi):\n",
    "  img_copy = large_image.copy()\n",
    "\n",
    "  contours_pred, _ = cv.findContours(pred.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  contours_roi, _ = cv.findContours(roi.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "  cv.drawContours(img_copy, contours_roi , -1, (255,0,0), 3)\n",
    "  cv.drawContours(img_copy, contours_pred, -1, (0,255,0), 3)\n",
    "\n",
    "  return img_copy\n",
    "\n",
    "def cal_overlap_per_large_img(roi, overlap_img):\n",
    "  bitwise_and_roi_pred = cv.bitwise_and(overlap_img, roi)\n",
    "  area_truth = np.count_nonzero(bitwise_and_roi_pred)\n",
    "  overlap = round(area_truth / np.count_nonzero(roi), 4)*100\n",
    "  return bitwise_and_roi_pred, area_truth, overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-KpqHh7-Vlf"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCPaqnMDLCNw"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Test-Ultrasound-Busi/data_benign.csv'\n",
    "\n",
    "data = pd.read_csv(csv_path)\n",
    "img_file = data['img']\n",
    "roi_file = data['roi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-S2XR2OdHDu"
   },
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "  path = path.decode()\n",
    "  x = cv.imread(path).astype(np.float32)\n",
    "  x = x/255.0\n",
    "  return x\n",
    "def read_mask(path):\n",
    "  path = path.decode()\n",
    "  x = cv.imread(path, 0).astype(np.bool_)\n",
    "  # x = x/255.0\n",
    "  x = np.expand_dims(x, axis = -1)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTWFgEX9eq6O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MN_7q0hJerAZ"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "  test_x = sorted(glob(os.path.join(path, 'data_benign', 'img', '*')))\n",
    "  test_y = sorted(glob(os.path.join(path, 'data_benign', 'mask', '*')))\n",
    "  return test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNVzFRGUfMrK",
    "outputId": "264ffb05-09b7-4971-9b6c-f26f359599f1"
   },
   "outputs": [],
   "source": [
    "dataset_path = '/content'\n",
    "test_x, test_y = load_data(dataset_path)\n",
    "print(len(test_x), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NasgTdY1elNh"
   },
   "outputs": [],
   "source": [
    "IMG_HEIGHT=256\n",
    "IMG_WIDTH=256\n",
    "IMG_CHANNELS=3\n",
    "\n",
    "X_test = np.ndarray(shape = (len(test_x), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.float32)\n",
    "\n",
    "for n, file_path in enumerate(test_x):\n",
    "        img = cv.imread(file_path).astype(np.float32)\n",
    "        # img = img/255.0\n",
    "        img = cv.resize(img, (256,256), cv.INTER_AREA)\n",
    "        img = np.array(img)\n",
    "        # img = cv.bitwise_not(img)\n",
    "        img = 255 - img\n",
    "        X_test[n] = img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKuzCGP7xf8e"
   },
   "outputs": [],
   "source": [
    "img = cv.imread(test_x[2], 0).astype(np.float32)\n",
    "img = img/255.0\n",
    "img = cv.resize(img, (256,256), cv.INTER_AREA)\n",
    "# img = (cv.bitwise_not(img)).astype(np.float32)\n",
    "img = (255-img)\n",
    "plt.imshow(img, 'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qXr8iPPQS7R"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
    "# dataset = dataset.map(tf_parse, num_parallel_calls= tf.data.AUTOTUNE)\n",
    "dataset = dataset.batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iX5aLDfriKud",
    "outputId": "7dc53e98-32e2-4d29-d4ab-8c1f9b97c271"
   },
   "outputs": [],
   "source": [
    "mask_predict = (model.predict(dataset) >= 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSVJLFSJi04D"
   },
   "outputs": [],
   "source": [
    "def show_image_roi_predict(randomlist, x, predict, name):\n",
    "  fg, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "  fg.suptitle(name)\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[0, i].imshow((x[index]).astype('uint8'), 'gray')\n",
    "    ax[0, i].set_xlabel('Image ' + str(index))\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[1, i].imshow((np.squeeze(predict[index]).astype('uint8')), 'gray')\n",
    "    ax[1, i].set_xlabel('Predict ' + str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BDLn8I2i43z"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 8),5)\n",
    "print(randomlist)\n",
    "show_image_roi_predict(randomlist, X_test, mask_predict, 'Test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Swfyzq_3y82u"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/Test-Ultrasound-Busi/data_benign.csv'\n",
    "pred_path = '/content/drive/MyDrive/Test-Ultrasound-Busi/data_benign_predict/original_predict'\n",
    "overlap_path = '/content/drive/MyDrive/Test-Ultrasound-Busi/data_benign_predict/overlap'\n",
    "draw_contour_path = '/content/drive/MyDrive/Test-Ultrasound-Busi/data_benign_predict/draw contour'\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "from patchify import patchify,  unpatchify\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "overlap_list = []\n",
    "area_truth_list = []\n",
    "num_FP = 0\n",
    "name_pred = []\n",
    "num_P_list = []\n",
    "\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file = os.path.basename(img_file)\n",
    "        print(name_file)\n",
    "\n",
    "        large_image = cv.imread(img_file, 0).astype(np.float32)\n",
    "        large_image = large_image/255.0\n",
    "        large_image = cv.bitwise_not(large_image)\n",
    "\n",
    "        roi = cv.imread(roi_file, 0).astype(np.uint8)\n",
    "\n",
    "        img = np.array(large_image)\n",
    "\n",
    "        h,w= img.shape\n",
    "\n",
    "        img_1 = cv.resize(img, (256,256), cv.INTER_AREA)\n",
    "\n",
    "        # img_1 = np.array(img_1)\n",
    "        # plt.imshow(img_1, 'gray')\n",
    "        # plt.show()\n",
    "\n",
    "        single_patch_input = np.zeros((256,256,3), dtype=\"float32\")\n",
    "        single_patch_input[:,:,0] = img_1\n",
    "        single_patch_input[:,:,1] = img_1\n",
    "        single_patch_input[:,:,2] = img_1\n",
    "\n",
    "        # single_patch_input = cv.resize(single_patch_input, (256,256), cv.INTER_AREA)\n",
    "        single_patch_input = np.array(single_patch_input)\n",
    "\n",
    "        mask_predict = (model.predict(single_patch_input) >= 0.5).astype(np.uint8)\n",
    "\n",
    "        mask_predict = cv.resize(img, (h,w), cv.INTER_AREA)\n",
    "\n",
    "        plt.imshow(np.squeeze(mask_predict), cmap='gray')\n",
    "\n",
    "        pred_img = mask_predict\n",
    "\n",
    "        y_pred_filter, n = filter_FP(pred_img, 1000 )\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        num_FP = num_FP + n\n",
    "        num_P_list.append(n)\n",
    "        print(\"number FP  = \", n )\n",
    "\n",
    "        pred_file_path = os.path.join(pred_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        # plt.imsave(pred_file_path, y_pred_filter, cmap='gray')\n",
    "\n",
    "        overlap_img, area_truth, overlap = cal_overlap_per_large_img(roi, y_pred_filter)\n",
    "        print(overlap)\n",
    "        area_truth_list.append(area_truth)\n",
    "        overlap_list.append(overlap)\n",
    "        overlap_img = 1*overlap_img\n",
    "        file_overlap_img_path = os.path.join(overlap_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        # plt.imsave(file_overlap_img_path, overlap_img, cmap='gray')\n",
    "\n",
    "        img_draw = cv.imread(img_file)\n",
    "        img_draw_contour = draw_contour_pred_and_truth(img_draw,y_pred_filter,roi)\n",
    "\n",
    "        plt.imshow(img_draw_contour)\n",
    "        plt.title(name_file_saver + \"- overlap = \"+ str(overlap) + \", Roi = \" + str(n))\n",
    "        plt.show()\n",
    "        img_draw_contour_path = os.path.join(draw_contour_path,\n",
    "                                 ''.join([name_file_saver]))\n",
    "        # plt.imsave(img_draw_contour_path, img_draw_contour, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_Wvmoyx0i7_"
   },
   "source": [
    "### dice loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pErqaddqvW5"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(model_file, verbose = 1, save_best_only= True),\n",
    "    ReduceLROnPlateau(monitor='val_dice_coef', factor = 0.1, patience = 4, mode='min'),\n",
    "    CSVLogger(log_file),\n",
    "    EarlyStopping(monitor = 'val_dice_coef', patience = 20, restore_best_weights = False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xNsHVY3nqxD5",
    "outputId": "0ff6916c-e770-4e22-97d8-4d23e6f75d85"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.metrics import Precision, Recall, MeanIoU\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data= valid_dataset,\n",
    "    epochs= epochs,\n",
    "    callbacks= callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCapjjuVDwHH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.testing import assert_allclose\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# load the model\n",
    "new_model = load_model(model_file\n",
    "                       )\n",
    "\n",
    "log_file_1 = os.path.join(files_dir,'log_new-data-bkg_5-5_vs2_.csv')\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_file, verbose = 1, save_best_only= True),\n",
    "    ReduceLROnPlateau(monitor='val_dice_coef', factor = 0.1, patience = 4, mode='min'),\n",
    "    CSVLogger(log_file_1),\n",
    "    EarlyStopping(monitor = 'val_dice_coef', patience = 20, restore_best_weights = False)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_9_vSc7ES40"
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "new_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data= valid_dataset,\n",
    "    epochs= epochs,\n",
    "    callbacks= callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpJtVw5j_YPm"
   },
   "source": [
    "### Test INBreast (bb<850) patch (1416 mass patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cCbEEV9_bjN",
    "outputId": "d8dd0fd3-30a0-4614-9719-b59fb6a34846"
   },
   "outputs": [],
   "source": [
    "!unrar x \"//content/drive/MyDrive/test INBreast patch/INBreast roi 850.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emjhREVD_1j8"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "dataset_inbreast_path = '/content/INBreast roi 850'\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_inbreast_path, 'Extract Patches', 'Patch', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_inbreast_path, 'Extract Patches', 'Mask', '*')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFid_baApxYq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y})\n",
    "df.to_csv ('/content/drive/MyDrive/test INBreast patch/patch_INBreast.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5kaZkIqAKvf"
   },
   "outputs": [],
   "source": [
    "def create_h5_file1(csv_file, h5_path, filename_x, filename_y):\n",
    "    col_list = [filename_x, filename_y]\n",
    "    df = pd.read_csv(csv_file, usecols=col_list)\n",
    "\n",
    "    x_train = df[filename_x]\n",
    "    y_train = df[filename_y]\n",
    "\n",
    "    # x_train.sort()\n",
    "    # y_train.sort()\n",
    "\n",
    "    IMG_HEIGHT=256\n",
    "    IMG_WIDTH=256\n",
    "    IMG_CHANNELS=3\n",
    "\n",
    "\n",
    "    # X_train = np.zeros((len(x_train), IMG_HEIGHT, IMG_WIDTH, 3), dtype= np.uint8)\n",
    "    X_train = np.ndarray(shape = (len(x_train), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.float32)\n",
    "    Y_train = np.ndarray(shape = (len(y_train), IMG_HEIGHT, IMG_WIDTH, 1), dtype= np.bool_)\n",
    "\n",
    "    x_train.sort_values()\n",
    "    y_train.sort_values()\n",
    "\n",
    "    for n, file_path in enumerate(x_train):\n",
    "        img = cv.imread(file_path)\n",
    "        img = np.array(img)\n",
    "        img = img / 255.\n",
    "        # print(file_path)\n",
    "        X_train[n] = img\n",
    "    #\n",
    "    for n, file_path in enumerate(y_train):\n",
    "        roi = cv.imread(file_path, 0)\n",
    "        roi = np.array(roi)\n",
    "        # roi = roi / 255.\n",
    "        # print(file_path)\n",
    "        roi = np.expand_dims(roi, -1)\n",
    "        Y_train[n] = roi\n",
    "\n",
    "    print(\"number of X examples = \" + str(X_train.shape[0]))\n",
    "    print(\"X shape: \" + str(X_train.shape))\n",
    "    print(\"Y shape: \" + str(Y_train.shape))\n",
    "    # print('pixel values in the mask are: ', np.unique(Y_train))\n",
    "\n",
    "    # return X_train, Y_train\n",
    "\n",
    "    with h5py.File(h5_path, 'w') as hf:\n",
    "        dset_x_train = hf.create_dataset('x', data=X_train, shape=(X_train.shape), compression='gzip',\n",
    "                                         chunks=True)\n",
    "        dset_y_train = hf.create_dataset('y', data=Y_train, shape=(Y_train.shape), compression='gzip',\n",
    "                                         chunks=True)\n",
    "    hf.close()\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bEKYiTssnCYB",
    "outputId": "868c6895-f01b-4261-e61c-8afd872955eb"
   },
   "outputs": [],
   "source": [
    "create_h5_file1('/content/drive/MyDrive/test INBreast patch/patch_INBreast.csv', '/content/drive/MyDrive/test INBreast patch/patch_mask_INBreast.h5','img', 'roi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21l04Rehl3Vo"
   },
   "outputs": [],
   "source": [
    "def read_h5_file(h5_path):\n",
    "    test_dataset = h5py.File(h5_path, \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"x\"][:])  # your train set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"y\"][:])\n",
    "\n",
    "    print(\"number of training examples = \" + str(test_set_x_orig.shape[0]))\n",
    "    print(\"X_INBreast shape: \" + str(test_set_x_orig.shape))\n",
    "    print(\"Y_INBreast shape: \" + str(test_set_y_orig.shape))\n",
    "\n",
    "    return test_set_x_orig, test_set_y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17J4acUPqSRT",
    "outputId": "7177ba85-61d4-409e-c2e8-89bdb00dc119"
   },
   "outputs": [],
   "source": [
    "inbreast_set_x, inbreast_set_y = read_h5_file('/content/drive/MyDrive/test INBreast patch/patch_mask_INBreast.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCGUWAaBqqin"
   },
   "outputs": [],
   "source": [
    "load_model_file = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAu_zihLquNk",
    "outputId": "1dc861e8-7c70-4c93-ceb6-49a3298b5df5"
   },
   "outputs": [],
   "source": [
    "preds_inbreast = load_model_file.predict(inbreast_set_x, verbose=1)\n",
    "inbreast_y_pred = (preds_inbreast > 0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DzxRbaTRrg0i",
    "outputId": "90e37858-3430-4990-db07-ab6cad34ee45"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/test INBreast patch/patch_INBreast.csv'\n",
    "predict_path = \"/content/drive/MyDrive/test INBreast patch/Predict_standard_model\"\n",
    "data = pd.read_csv(csv_path)\n",
    "test_set_x_orig = data['img']\n",
    "\n",
    "# print(test_set_x_orig.shape)\n",
    "n = 0\n",
    "for i in test_set_x_orig:\n",
    "      name_file = os.path.basename(i)\n",
    "      # print(name_file)\n",
    "      save_path = os.path.join(predict_path,''.join([name_file]))\n",
    "      # print(save_path)\n",
    "      predict = np.squeeze(inbreast_y_pred[n])\n",
    "      plt.imsave(save_path, predict, cmap='gray')\n",
    "      # plt.imshow(predict)\n",
    "      # plt.show\n",
    "      # cv.imwrite(save_path, predict)\n",
    "      n = n + 1\n",
    "print(n)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8c5XRUPsSn7"
   },
   "outputs": [],
   "source": [
    "def show_image_roi_predict1_img(index, x, y, predict):\n",
    "\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "    y_pred_filter = cv.morphologyEx(np.squeeze(predict[index]), cv.MORPH_CLOSE, kernel)\n",
    "    y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "    overlap = cal_overlap(x[index], y[index], y_pred_filter)\n",
    "    print (overlap)\n",
    "\n",
    "    roi = np.squeeze(y[index])\n",
    "    plt.subplot(131)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(roi, 'gray')\n",
    "    plt.title('ROI ' + str(index))\n",
    "    image_8bit = np.uint8(roi * 255)\n",
    "    _, binarized = cv.threshold(image_8bit, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_roi, hierarchy = cv.findContours(binarized, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    roi_pred = np.squeeze(y_pred_filter)\n",
    "    plt.subplot(132)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(roi_pred)\n",
    "    plt.title('ROI pred ' + str(index))\n",
    "    image_8bit = np.uint8(roi_pred * 255)\n",
    "    _, binarized = cv.threshold(image_8bit, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_pred, hierarchy = cv.findContours(binarized,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    img = x[index]\n",
    "    img_copy = img.copy()\n",
    "    cv.drawContours(img_copy, contours_roi,-1,(255,0,0),2)\n",
    "    cv.drawContours(img_copy, contours_pred,-1, (0,255,0), 2)\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(img_copy)\n",
    "    plt.title('Image' + str(index))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7WRPys4sTts"
   },
   "outputs": [],
   "source": [
    "def cal_overlap(x,y,y_pred):\n",
    "  bitwise_and_roi_patch = np.logical_and(np.squeeze(y), np.squeeze(y_pred))\n",
    "  overlap = round(np.sum(bitwise_and_roi_patch) / np.sum(np.squeeze(y)), 2)\n",
    "  return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "T7sJ263AsVc2",
    "outputId": "13d7c681-2996-4bc3-a060-aa302dcfbcff"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(42, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "mr1VwHcqsjA0",
    "outputId": "972f91bc-5c19-4720-cb40-f3d9eb70348e"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(100, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "VKf5V4DdsqeY",
    "outputId": "66f883db-5ee1-43b4-fb48-b54ea84f7a7a"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(500, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "MdRGL5f3stQQ",
    "outputId": "e5c76918-3641-4f14-feb6-c9260f93f924"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(200, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "Zz0-WvgTswJG",
    "outputId": "b60b5350-bc9c-49c4-db91-a6fb2741c048"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(5, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "m2Djg_hXsze4",
    "outputId": "aa87cfbd-6716-4c9d-9979-ed8dbe806061"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(60, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEM0k6-htd7a"
   },
   "outputs": [],
   "source": [
    "def show_image_roi_predict(randomlist, x, y, predict, name):\n",
    "  fg, ax = plt.subplots(3, 5, figsize=(20, 8))\n",
    "  fg.suptitle(name)\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[0, i].imshow(x[index], 'gray')\n",
    "    ax[0, i].set_xlabel('Image ' + str(index))\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[1, i].imshow(np.squeeze(y[index]), 'gray')\n",
    "    ax[1, i].set_xlabel('ROI ' + str(index))\n",
    "\n",
    "  for i, index in enumerate(randomlist):\n",
    "    ax[2, i].imshow(np.squeeze(predict[index]), 'gray')\n",
    "    ax[2, i].set_xlabel('Predict ' + str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 813
    },
    "id": "BAUzRb7BtpvT",
    "outputId": "74e93a43-4905-4006-84b6-fe6da779bb65"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 100),5)\n",
    "print(randomlist)\n",
    "show_image_roi_predict(randomlist, inbreast_set_x, inbreast_set_y, inbreast_y_pred, 'inbreast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wM6qS86uqPJ"
   },
   "source": [
    "#### metrics - cha hu x l predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "EBUpbY2BuuoT",
    "outputId": "2924e3a2-e127-4b2b-a2d0-edd2d7e8b9fe"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "from csv import DictReader\n",
    "from pathlib import Path\n",
    "\n",
    "csv_path = '/content/drive/MyDrive/test INBreast patch/patch_INBreast.csv'\n",
    "predict_path = \"/content/drive/MyDrive/test INBreast patch/Predict_standard_model\"\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "dice_list = []\n",
    "iou_list = []\n",
    "overlap_list = []\n",
    "\n",
    "for i in range(len(inbreast_set_x)):\n",
    "        roi = np.squeeze(inbreast_set_x[i])\n",
    "        print(np.shape(inbreast_set_x[i]))\n",
    "        pred = np.squeeze(inbreast_y_pred[i])\n",
    "        print(np.shape(inbreast_y_pred[i]))\n",
    "\n",
    "        # roi_bw = cv.threshold(roi, 1 , 255, cv.THRESH_BINARY)\n",
    "        # roi = np.array(roi_bw)\n",
    "\n",
    "        # kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "        # pred = cv.morphologyEx(pred, cv.MORPH_CLOSE, kernel)\n",
    "        # pred = cv.morphologyEx(pred, cv.MORPH_OPEN, kernel)\n",
    "        # pred_bw = cv.threshold(pred, 1 , 255, cv.THRESH_BINARY)\n",
    "        # pred1 = np.array(pred_bw)\n",
    "\n",
    "        dice = compute_dice_1(roi, pred)\n",
    "        dice_list.append(dice)\n",
    "\n",
    "        # bitwise_and_roi_patch = np.logical_and(np.squeeze(roi), np.squeeze(pred))\n",
    "        # overlap = round(np.sum(bitwise_and_roi_patch) / np.sum(np.squeeze(roi)), 3)\n",
    "        overlap = compute_overlap(roi, pred)\n",
    "        overlap_list.append(overlap)\n",
    "\n",
    "        iou = compute_iou(roi, pred)\n",
    "        iou_list.append(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJ587Qw4IKJg",
    "outputId": "0a14beb5-3d46-41d0-d1eb-0c0ce05e13c2"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/test INBreast patch/patch_INBreast.csv'\n",
    "predict_path = \"/content/drive/MyDrive/test INBreast patch/Predict_standard_model\"\n",
    "data = pd.read_csv(csv_path)\n",
    "inbreast_set_y_orig = data['roi']\n",
    "\n",
    "# print(test_set_x_orig.shape)\n",
    "dice_list = []\n",
    "iou_list = []\n",
    "overlap_list = []\n",
    "\n",
    "for i in inbreast_set_y_orig:\n",
    "      name_file = os.path.basename(i)\n",
    "      roi = cv.imread(i)\n",
    "      # roi = np.array(roi)\n",
    "      pred_path = os.path.join(predict_path,''.join([name_file]))\n",
    "      pred = cv.imread(pred_path)\n",
    "      # pred = np.array(pred)\n",
    "\n",
    "      dice = compute_dice_1(roi, pred)\n",
    "      dice_list.append(dice)\n",
    "\n",
    "        # bitwise_and_roi_patch = np.logical_and(np.squeeze(roi), np.squeeze(pred))\n",
    "        # overlap = round(np.sum(bitwise_and_roi_patch) / np.sum(np.squeeze(roi)), 3)\n",
    "      overlap = compute_overlap(roi, pred)\n",
    "      overlap_list.append(overlap)\n",
    "\n",
    "      iou = compute_iou(roi, pred)\n",
    "      iou_list.append(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5YhpcChJwCO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'overlap': overlap_list, 'iou': iou_list, 'dice': dice_list })\n",
    "df.to_csv ('/content/drive/MyDrive/test INBreast patch/overlap_iou_dice_inbreast_bb_850.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txrXeviDHJe8"
   },
   "source": [
    "#### metrics - hu x l morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtFDwA8AOEaB",
    "outputId": "983e5919-0ae4-4007-d798-927a8605c6ff"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/test INBreast patch/patch_INBreast.csv'\n",
    "predict_path = \"/content/drive/MyDrive/test INBreast patch/Predict_standard_model\"\n",
    "data = pd.read_csv(csv_path)\n",
    "inbreast_set_y_orig = data['roi']\n",
    "\n",
    "# print(test_set_x_orig.shape)\n",
    "dice_list = []\n",
    "iou_list = []\n",
    "overlap_list = []\n",
    "\n",
    "for i in inbreast_set_y_orig:\n",
    "      name_file = os.path.basename(i)\n",
    "      roi = cv.imread(i)\n",
    "\n",
    "      pred_path = os.path.join(predict_path,''.join([name_file]))\n",
    "      pred = cv.imread(pred_path)\n",
    "\n",
    "      kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "      pred = cv.morphologyEx(pred, cv.MORPH_CLOSE, kernel)\n",
    "      pred = cv.morphologyEx(pred, cv.MORPH_OPEN, kernel)\n",
    "      # pred = cv.threshold(pred, 1 , 255, cv.THRESH_BINARY)\n",
    "      # pred = np.array(pred)\n",
    "      # pred = cv.imdecode(pred, cv.IMREAD_GRAYSCALE)\n",
    "      # pred = pred.reshape(-1, pred.shape[-1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      dice = compute_dice_1(roi, pred)\n",
    "      dice_list.append(dice)\n",
    "\n",
    "      overlap = compute_overlap(roi, pred)\n",
    "      overlap_list.append(overlap)\n",
    "\n",
    "      iou = compute_iou(roi, pred)\n",
    "      iou_list.append(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ww91AP7BlzDQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'overlap': overlap_list, 'iou': iou_list, 'dice': dice_list })\n",
    "df.to_csv ('/content/drive/MyDrive/test INBreast patch/overlap_iou_dice_inbreast_bb_850_morphology.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkR32S0Pmcc4"
   },
   "source": [
    "#### model without 2nd skip connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgIWZfkiVDK5"
   },
   "outputs": [],
   "source": [
    "def delete_bkg(patch_img_folder_path):\n",
    "    # name_patch_roi = []\n",
    "    for r, d, f in os.walk(patch_img_folder_path):\n",
    "        for file in f:\n",
    "            if '_bkg.png' in file:\n",
    "                name_file = os.path.basename(os.path.join(r, file))\n",
    "                path = patch_img_folder_path + \"//\" + name_file\n",
    "                os.remove(path)\n",
    "    #             name_patch_roi.append(name_file)\n",
    "    # name_patch_img = []\n",
    "    # for r, d, f in os.walk(patch_img_folder_path):\n",
    "    #     for file in f:\n",
    "    #         if '.png' in file:\n",
    "    #             name_file = os.path.basename(os.path.join(r, file))\n",
    "    #             name_patch_img.append(name_file)\n",
    "\n",
    "    # for i in name_patch_roi:\n",
    "    #     if i not in name_patch_img:\n",
    "    #         path = patch_roi_folder_path + \"\\\\\" + i\n",
    "    #         os.remove(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXsLUGlEVEu3"
   },
   "outputs": [],
   "source": [
    "delete_bkg(\"/content/drive/MyDrive/test INBreast patch/Predict_mass patch_2nd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zz5glpOqZw-Y"
   },
   "outputs": [],
   "source": [
    "delete_bkg(\"/content/Extract mass patch/Patch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iu97U-9PZ7qC"
   },
   "outputs": [],
   "source": [
    "dataset_path = '/content'\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'Extract mass patch', 'Patch', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'Extract mass patch', 'Mask', '*')))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y})\n",
    "df.to_csv ('/content/drive/MyDrive/test INBreast patch/mass_patch_INBreast.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGXH8rUReUkH",
    "outputId": "9c5f0303-8af3-49ed-f5ac-0678e0c51fd6"
   },
   "outputs": [],
   "source": [
    "create_h5_file1('/content/drive/MyDrive/test INBreast patch/mass_patch_INBreast.csv', '/content/drive/MyDrive/test INBreast patch/mass_patch_mask_INBreast.h5','img', 'roi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmxjNvHLmOfB",
    "outputId": "4c6e7cb6-6998-48d1-aa42-0c8362a6edd8"
   },
   "outputs": [],
   "source": [
    "inbreast_set_x, inbreast_set_y = read_h5_file('/content/drive/MyDrive/test INBreast patch/mass_patch_mask_INBreast.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uk1IvhLQncO8"
   },
   "outputs": [],
   "source": [
    "def compute_dice_mass(label_img, pred_img, p_threshold=0.5):\n",
    "    p = pred_img.astype(np.float)\n",
    "    l = label_img.astype(np.float)\n",
    "    if p.max() > 127:\n",
    "        p /= 255.\n",
    "    if l.max() > 127:\n",
    "        l /= 255.\n",
    "\n",
    "    p = np.clip(p, 0, 1.0)\n",
    "    l = np.clip(l, 0, 1.0)\n",
    "    p[p > 0.5] = 1.0\n",
    "    p[p < 0.5] = 0.0\n",
    "    l[l > 0.5] = 1.0\n",
    "    l[l < 0.5] = 0.0\n",
    "    product = ((l.flatten())*(p.flatten())).sum()\n",
    "    dice_num = 2 * product\n",
    "    pred_sum = p.sum()\n",
    "    label_sum = l.sum()\n",
    "    dice_den = pred_sum + label_sum\n",
    "    dice_val = 100*dice_num / dice_den\n",
    "    return round(dice_val,2)\n",
    "def compute_iou_mass(label_img, pred_img, p_threshold=0.5):\n",
    "    p = pred_img.astype(np.float)\n",
    "    l = label_img.astype(np.float)\n",
    "    if p.max() >= 127:\n",
    "        p /= 255.\n",
    "    if l.max() >= 127:\n",
    "        l /= 255.\n",
    "\n",
    "    p = np.clip(p, 0, 1.0)\n",
    "    l = np.clip(l, 0, 1.0)\n",
    "    p[p >= 0.5] = 1.0\n",
    "    p[p < 0.5] = 0.0\n",
    "    l[l >= 0.5] = 1.0\n",
    "    l[l < 0.5] = 0.0\n",
    "\n",
    "    product = ((l.flatten())* (p.flatten())).sum()\n",
    "    iou_num = product\n",
    "    pred_sum = p.sum()\n",
    "    label_sum = l.sum()\n",
    "    iou_den = pred_sum + label_sum  - product\n",
    "    iou = 100*iou_num / iou_den\n",
    "\n",
    "    return round(iou,2)\n",
    "\n",
    "def compute_overlap_mass(label_img, pred_img):\n",
    "    p = pred_img.astype(np.float)\n",
    "    l = label_img.astype(np.float)\n",
    "    if p.max() >= 127:\n",
    "        p /= 255.\n",
    "    if l.max() >= 127:\n",
    "        l /= 255.\n",
    "\n",
    "    p = np.clip(p, 0, 1.0)\n",
    "    l = np.clip(l, 0, 1.0)\n",
    "    p[p >= 0.5] = 1.0\n",
    "    p[p < 0.5] = 0.0\n",
    "    l[l >= 0.5] = 1.0\n",
    "    l[l < 0.5] = 0.0\n",
    "\n",
    "    bitwise_and_roi_patch = np.logical_and(l, p).sum()\n",
    "    overlap = 100*(bitwise_and_roi_patch + 1)/(np.sum(l))\n",
    "    return round(overlap,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdil_Frvfybp",
    "outputId": "9371bec2-01b6-4c81-f450-336afd994c95"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/test INBreast patch/mass_patch_INBreast.csv'\n",
    "\n",
    "predict_2nd_path = \"/content/drive/MyDrive/test INBreast patch/Predict_mass patch_2nd\"\n",
    "predict_path = \"/content/drive/MyDrive/test INBreast patch/test 1416 mass patch standard model/Predict_standard_model\"\n",
    "from pathlib import Path\n",
    "\n",
    "dice_list = []\n",
    "iou_list = []\n",
    "overlap_list = []\n",
    "\n",
    "dice_2nd_list = []\n",
    "iou_2nd_list = []\n",
    "overlap_2nd_list = []\n",
    "\n",
    "with open(csv_path, 'r') as csvfile:\n",
    "    csv_dict_reader = DictReader(csvfile)\n",
    "    for row in csv_dict_reader:\n",
    "        img_file = row['img']\n",
    "        roi_file = row['roi']\n",
    "\n",
    "        name_file_saver = os.path.basename(roi_file)\n",
    "\n",
    "        pred_file= os.path.join(predict_path,''.join([name_file_saver]))\n",
    "        pred_2nd_file= os.path.join(predict_2nd_path,''.join([name_file_saver]))\n",
    "\n",
    "        roi = cv.imread(roi_file,0)\n",
    "\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "\n",
    "        y_pred = cv.imread(pred_file, 0)\n",
    "        print(pred_file)\n",
    "        y_pred = cv.morphologyEx(y_pred, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred = cv.morphologyEx(y_pred, cv.MORPH_OPEN, kernel)\n",
    "        # y_pred, n_2 = filter_FP(pred, 300)\n",
    "\n",
    "        y_pred_2nd = cv.imread(pred_2nd_file, 0)\n",
    "        y_pred_2nd = cv.morphologyEx(y_pred_2nd, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred_2nd = cv.morphologyEx(y_pred_2nd, cv.MORPH_OPEN, kernel)\n",
    "        # y_pred_2nd, n_3 = filter_FP(pred, 300)\n",
    "\n",
    "        dice = compute_dice_mass(roi, y_pred)\n",
    "        dice_list.append(dice)\n",
    "\n",
    "        overlap = compute_overlap_mass(roi, y_pred)\n",
    "        overlap_list.append(overlap)\n",
    "\n",
    "        iou = compute_iou_mass(roi, y_pred)\n",
    "        iou_list.append(iou)\n",
    "\n",
    "        dice_2nd = compute_dice_mass(roi, y_pred_2nd)\n",
    "        dice_2nd_list.append(dice_2nd)\n",
    "\n",
    "        overlap_2nd = compute_overlap_mass(roi, y_pred_2nd)\n",
    "        overlap_2nd_list.append(overlap_2nd)\n",
    "\n",
    "        iou_2nd = compute_iou_mass(roi, y_pred_2nd)\n",
    "        iou_2nd_list.append(iou_2nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z89rEFUusFrQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'overlap': overlap_list, 'iou': iou_list, 'dice': dice_list,\n",
    "                   'overlap_2nd': overlap_2nd_list, 'iou_2nd': iou_2nd_list, 'dice_2nd': dice_2nd_list })\n",
    "df.to_csv ('/content/drive/MyDrive/test INBreast patch/overlap_iou_dice_mass_patch_standard_2nd_inbreast_bb_850_morphology.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVwrHSJbzeoK"
   },
   "source": [
    "# INBreast (mass and non-mass patch - 1416 mass patch, bb<= 850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZH2yNI9z8W7"
   },
   "outputs": [],
   "source": [
    "!unrar x \"//content/drive/MyDrive/test INBreast patch/mass and non mass patch/Extract mass and non-mass patch.rar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRNA-JnQ0ODD"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive'\n",
    "dataset_path = '/content'\n",
    "dataset_inbreast_path = '/content/INBreast roi 850'\n",
    "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg')\n",
    "model_file = os.path.join(files_dir,'unet_effb0-new-data-20_bkg-15_5_2023.h5')\n",
    "\n",
    "test_x= sorted(glob(os.path.join(dataset_path, 'Extract mass and non-mass patch', 'Patch', '*')))\n",
    "test_y= sorted(glob(os.path.join(dataset_path, 'Extract mass and non-mass patch', 'Mask', '*')))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'img': test_x, 'roi': test_y})\n",
    "df.to_csv ('/content/drive/MyDrive/test INBreast patch/mass and non mass patch/patch_INBreast.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "048EnZnn1rn8",
    "outputId": "e1b00f47-a916-44a9-8ec4-fc53deae3a55"
   },
   "outputs": [],
   "source": [
    "create_h5_file1('/content/drive/MyDrive/test INBreast patch/mass and non mass patch/patch_INBreast.csv',\n",
    "                '/content/drive/MyDrive/test INBreast patch/mass and non mass patch/patch_mask_INBreast.h5','img', 'roi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u46Am71z2P0a"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0CuYO_4F13mG",
    "outputId": "95763cbf-8e98-4af6-b5f4-4aeb97ef48db"
   },
   "outputs": [],
   "source": [
    "inbreast_set_x, inbreast_set_y = read_h5_file('/content/drive/MyDrive/test INBreast patch/mass and non mass patch/patch_mask_INBreast.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgIl7OH0GhJf"
   },
   "outputs": [],
   "source": [
    "def compute_dice(label_img, pred_img, p_threshold=0.5):\n",
    "    p = pred_img.astype(np.float)\n",
    "    l = label_img.astype(np.float)\n",
    "    if p.max() > 127:\n",
    "        p /= 255.\n",
    "    if l.max() > 127:\n",
    "        l /= 255.\n",
    "\n",
    "    p = np.clip(p, 0, 1.0)\n",
    "    l = np.clip(l, 0, 1.0)\n",
    "    p[p > 0.5] = 1.0\n",
    "    p[p < 0.5] = 0.0\n",
    "    l[l > 0.5] = 1.0\n",
    "    l[l < 0.5] = 0.0\n",
    "    product = ((l.flatten())*(p.flatten())).sum()\n",
    "    dice_num = 2 * product + 1\n",
    "    pred_sum = p.sum()\n",
    "    label_sum = l.sum()\n",
    "    dice_den = pred_sum + label_sum + 1\n",
    "    dice_val = 100*dice_num / dice_den\n",
    "    return round(dice_val,2)\n",
    "def compute_iou(label_img, pred_img, p_threshold=0.5):\n",
    "    p = pred_img.astype(np.float)\n",
    "    l = label_img.astype(np.float)\n",
    "    if p.max() >= 127:\n",
    "        p /= 255.\n",
    "    if l.max() >= 127:\n",
    "        l /= 255.\n",
    "\n",
    "    p = np.clip(p, 0, 1.0)\n",
    "    l = np.clip(l, 0, 1.0)\n",
    "    p[p >= 0.5] = 1.0\n",
    "    p[p < 0.5] = 0.0\n",
    "    l[l >= 0.5] = 1.0\n",
    "    l[l < 0.5] = 0.0\n",
    "\n",
    "    product = ((l.flatten())* (p.flatten())).sum()\n",
    "    iou_num = product + 1\n",
    "    pred_sum = p.sum()\n",
    "    label_sum = l.sum()\n",
    "    iou_den = pred_sum + label_sum + 1 - product\n",
    "    iou = 100*iou_num / iou_den\n",
    "\n",
    "    return round(iou,2)\n",
    "\n",
    "def compute_overlap_1(label_img, pred_img):\n",
    "    p = pred_img.astype(np.float)\n",
    "    l = label_img.astype(np.float)\n",
    "    if p.max() >= 127:\n",
    "        p /= 255.\n",
    "    if l.max() >= 127:\n",
    "        l /= 255.\n",
    "\n",
    "    p = np.clip(p, 0, 1.0)\n",
    "    l = np.clip(l, 0, 1.0)\n",
    "    p[p >= 0.5] = 1.0\n",
    "    p[p < 0.5] = 0.0\n",
    "    l[l >= 0.5] = 1.0\n",
    "    l[l < 0.5] = 0.0\n",
    "\n",
    "    # product = ((l.flatten())* (p.flatten())).sum()\n",
    "    # label_sum = l.sum()\n",
    "    # overlap = 100*product /label_sum\n",
    "\n",
    "    # bitwise_and_roi_patch = np.logical_and(label_img, pred_img)\n",
    "\n",
    "    if (np.sum(l) == 0):\n",
    "      if (np.sum(p) != 0):\n",
    "          overlap = 0.0\n",
    "      else:\n",
    "          bitwise_and_roi_patch = np.logical_and(l, p).sum()\n",
    "          overlap = 100*(bitwise_and_roi_patch + 1)/(np.sum(l)+1)\n",
    "    else:\n",
    "          bitwise_and_roi_patch = np.logical_and(l, p).sum()\n",
    "          overlap = 100*(bitwise_and_roi_patch + 1)/(np.sum(l)+1)\n",
    "    return round(overlap,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DC-XwkDEzqqq"
   },
   "source": [
    "#### Standard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfV6k1NhmhIM"
   },
   "outputs": [],
   "source": [
    "load_model_file = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7yXdpX0m2Eab",
    "outputId": "61df63da-4cf0-4b07-e9a1-646c7f9ccb09"
   },
   "outputs": [],
   "source": [
    "preds_inbreast = load_model_file.predict(inbreast_set_x, verbose=1)\n",
    "inbreast_y_pred = (preds_inbreast > 0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnqoFmqE9SQd",
    "outputId": "eb1a6e24-1be2-43e7-a36a-968b323118ec"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/test INBreast patch/mass and non mass patch/patch_INBreast.csv'\n",
    "predict_path = \"/content/drive/MyDrive/test INBreast patch/mass and non mass patch/Standard Model/Predict\"\n",
    "data = pd.read_csv(csv_path)\n",
    "test_set_x_orig = data['img']\n",
    "\n",
    "# print(test_set_x_orig.shape)\n",
    "n = 0\n",
    "for i in test_set_x_orig:\n",
    "      name_file = os.path.basename(i)\n",
    "      # print(name_file)\n",
    "      save_path = os.path.join(predict_path,''.join([name_file]))\n",
    "      # print(save_path)\n",
    "      predict = np.squeeze(inbreast_y_pred[n])\n",
    "      plt.imsave(save_path, predict, cmap='gray')\n",
    "      # plt.imshow(predict)\n",
    "      # plt.show\n",
    "      # cv.imwrite(save_path, predict)\n",
    "      n = n + 1\n",
    "print(n)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8B-sPOuiHZuy"
   },
   "source": [
    "##### show predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "_spm4uo1ua4f",
    "outputId": "dd6f3e0a-67f8-4f2e-f853-a1b41d6b2a26"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(66, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "Ly36mxVW6aAf",
    "outputId": "d8510e92-fd1b-48fe-bb72-8929ecd0a270"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(86, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "nzbqkM9j20Ly",
    "outputId": "b92ab78e-2c3d-4725-a967-47327a238a68"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(65, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "3yiPtM5kF0rD",
    "outputId": "0e7dac42-52ac-44ff-a690-f24af1237c9c"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(42, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "F2PPRWaGF2TH",
    "outputId": "ceca1c64-7319-4f11-f01f-017ea01dbf9a"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "kQd1uHP5F45O",
    "outputId": "209e2a1c-232f-42ba-c386-e4083b757399"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(15, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "wr9cobbpF64O",
    "outputId": "cf41a9b8-203e-41db-e2a4-c6f17079b9cb"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(20, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "cuvDBs00F9Rw",
    "outputId": "e4e05d7c-3da1-49ef-d657-9bc44141d1df"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(40, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "B0bpSfPVF_WJ",
    "outputId": "a9aaf2ed-a09c-4957-d05d-a25ba5f4c9ea"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(60, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "VO5fnNx7HxGH",
    "outputId": "43b4e800-816d-4c61-8498-28c2724afea1"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(80, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "P_VMHmBFHzxj",
    "outputId": "cb8268f5-7a68-4fa4-abe2-fedd2c39f35a"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(100, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "OwxVmLDkH13L",
    "outputId": "b824c5e3-5ffe-479a-bfb9-f81126e3ee16"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(120, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "v4GtY2uTH4MO",
    "outputId": "afcca656-0889-4b70-9281-54a547091511"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(140, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "54nKvWZOH7CJ",
    "outputId": "47f7619c-bb0b-4e47-8b79-f80b2cddafb2"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(150, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "YSpUX8XXH9E0",
    "outputId": "ac18ee81-83cb-495f-e1de-43c4e68b1755"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(200, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "K63BkYZxH_TV",
    "outputId": "99ab9dd7-d6a1-4034-95d4-f49f149722de"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(280, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "VGr06sE6IBun",
    "outputId": "650a91e5-d59e-4e49-af82-4737de617111"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(300, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "l4zULYeiIEv4",
    "outputId": "d8ba62e8-76a5-4276-a186-9b15f026bf63"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(350, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "42eQK25MIH1f",
    "outputId": "693fa275-7fc1-42b4-8cf8-793af6ddb149"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(351, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "A5KimfQKIKMu",
    "outputId": "13a26d2a-ca37-4195-f00a-e2bf9645f89e"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(349, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "ypfDtkMII5HH",
    "outputId": "3b4e30c4-024a-4b50-c64a-c0b7abd84978"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(370, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "bHbx5U4JI7cq",
    "outputId": "05f8a2f9-4fd2-43c0-9baf-6f441e8ec086"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(380, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "SN8d9q_1I8yP",
    "outputId": "8f4d5d8c-a5b3-4b60-c4a7-74109d36244a"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(400, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "5eSmHLH0JAtV",
    "outputId": "cfd82fa4-be8d-4bfe-b88b-2d25709b7cfb"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(500, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "0EU42UDOJDFb",
    "outputId": "c8f8e9ed-9206-4b3c-b6f3-1a420b91c785"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(550, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "wWHaN9fLJFrg",
    "outputId": "b2e59305-90e8-40c2-86e7-7b76cdb7c459"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(600, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "-nHRA8cHJIXn",
    "outputId": "97a2bdc6-9261-4560-fc37-eb64af62e05c"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(700, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "jAekvykjJKjK",
    "outputId": "2f3e7def-4973-4104-d4c4-dfe59ac2b899"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(800, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "daqa9qpGJM9f",
    "outputId": "b9e81464-3337-4cb7-c11c-7ea5bca45250"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(900, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "M77GvvCEJZ8L",
    "outputId": "a0aa294a-93ce-4879-fea3-c8970f8cff72"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1000, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "nuBfSGLSJb2Y",
    "outputId": "2fac7b0b-6aa9-4140-fc59-da55f85f5634"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1100, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "RUGLH-8KJeDz",
    "outputId": "63ff4eca-0f19-4cd1-d284-587f7195c0db"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1120, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "WVmqKO1HJhXY",
    "outputId": "0801a243-ab8c-4e84-aadf-95aa48840dd1"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1300, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "1VqjVHKWJkmf",
    "outputId": "49ab604e-52f4-48d6-d363-d377fb0a39ff"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1400, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "nYfTAHziJnlQ",
    "outputId": "35b4d4e7-f4b6-487e-afb5-c8d809675f8e"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1500, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "skTm4T_1JpuP",
    "outputId": "fa95a716-b893-4430-8f73-4c3086c811fe"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1600, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "pfUsWQ4_JsNw",
    "outputId": "4b949417-f91a-4b06-eb48-0cd2bc99d0c4"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1700, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "5KCs-rKZJxed",
    "outputId": "a37d5269-66ae-44f6-be6e-728358d43541"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1800, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "uVKyNDjgJzm9",
    "outputId": "a6f6ee3d-03fb-4f85-f592-9100af7ad336"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1900, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "KAjdr2PvJ1j4",
    "outputId": "b7e8bac8-277b-46d7-f8a9-eb32662c1764"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(2000, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "w1F7nC4iJ3gZ",
    "outputId": "cd559135-b02f-4859-b585-232ff9196a04"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(2100, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "99KHseExJ6n4",
    "outputId": "151b34fd-deb1-4026-d56a-13c73813b515"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(2200, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "5DFQwoaCK_V7",
    "outputId": "cc9cb851-a139-410d-f82a-466e02a6f468"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(2797, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "akjC8xVbLHOs",
    "outputId": "3de17690-973f-4587-9b07-32fe851ad8b9"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(2807, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "qGUrVWGZL_bo",
    "outputId": "d4c064f1-9d15-450f-88a2-50ffa7db688e"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(6, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "sRGZ688SN0VB",
    "outputId": "eacf1509-ef59-4afa-dbdb-6308885b7b8e"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(5, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "iQIFbSsS4XfM",
    "outputId": "027d1291-2e40-4d36-bba2-60895f59a2ec"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(2583, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "mVYby7MyUlAT",
    "outputId": "b1115924-a6b0-4f10-98fd-a38305504b0b"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(7, inbreast_set_x, inbreast_set_y, inbreast_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "UVZ1-9F1GF0u",
    "outputId": "c8452278-44ca-4666-e43e-8c4afc684cb8"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 100),5)\n",
    "print(randomlist)\n",
    "show_image_roi_predict(randomlist, inbreast_set_x, inbreast_set_y, inbreast_y_pred, 'inbreast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "3u3qV2btGJSq",
    "outputId": "c10483dc-891a-4fad-905a-abdb3334be96"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(100, 200),5)\n",
    "print(randomlist)\n",
    "show_image_roi_predict(randomlist, inbreast_set_x, inbreast_set_y, inbreast_y_pred, 'inbreast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "ncGnacpsSZZK",
    "outputId": "aeb50986-6748-4dac-9185-7d5c3e1fdf14"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 2800),5)\n",
    "print(randomlist)\n",
    "show_image_roi_predict(randomlist, inbreast_set_x, inbreast_set_y, inbreast_y_pred, 'inbreast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 813
    },
    "id": "95U7yydbSoF2",
    "outputId": "f6328cb2-33e3-4d89-9837-a61ba6d3ed82"
   },
   "outputs": [],
   "source": [
    "randomlist = random.sample(range(0, 2800),5)\n",
    "print(randomlist)\n",
    "show_image_roi_predict(randomlist, inbreast_set_x, inbreast_set_y, inbreast_y_pred, 'inbreast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZKDGDAY7grA"
   },
   "outputs": [],
   "source": [
    "y_label, y_pred_label = create_label_map(inbreast_set_y,inbreast_y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "YFKdupBr7zKX",
    "outputId": "bb53a9b9-eebc-40da-927f-3716d7c22028"
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_pred_2 = test_set_y_pred.ravel()\n",
    "# test_set_y_2 = test_set_y.ravel()\n",
    "cm=confusion_matrix(y_label, y_pred_label)\n",
    "print(cm)\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title('confusion matrix - Test data')\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4Gx1CR1C7JP",
    "outputId": "85fe55e6-e11f-4809-c5b3-c11d4b0445ce"
   },
   "outputs": [],
   "source": [
    "total1=sum(sum(cm))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1=(cm[0,0]+cm[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffUer5BwBXnf"
   },
   "outputs": [],
   "source": [
    "overlaps = []\n",
    "labels_y = []\n",
    "labels_y_pred = []\n",
    "for i in range(len(inbreast_set_x)):\n",
    "  x = inbreast_set_x[i]\n",
    "  y = inbreast_set_y[i]\n",
    "  y_pred = inbreast_y_pred[i] ,\n",
    "  overlap, label_y, label_y_pred = cal_overlap_label(x,y,y_pred)\n",
    "  overlaps.append(overlap)\n",
    "  labels_y.append(label_y)\n",
    "  labels_y_pred.append(label_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "BKwRxK2YBzSn",
    "outputId": "1998bfc9-1409-47cd-a862-eed2e561d171"
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_pred_2 = test_set_y_pred.ravel()\n",
    "# test_set_y_2 = test_set_y.ravel()\n",
    "cm=confusion_matrix(labels_y, labels_y_pred)\n",
    "print(cm)\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title('confusion matrix - Test data')\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AmkWkQj_CG-e",
    "outputId": "b3ea798f-dc12-46cb-c9f9-6cef95c2294f"
   },
   "outputs": [],
   "source": [
    "total1=sum(sum(cm))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1=(cm[0,0]+cm[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aomr_ivyHc4P"
   },
   "source": [
    "##### metrics - hu x l morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ScjrFbo0Gs1e",
    "outputId": "7d0825de-9e41-4de9-e6b0-6ab806f3f11b"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/test INBreast patch/mass and non mass patch/patch_INBreast.csv'\n",
    "predict_path = \"/content/drive/MyDrive/test INBreast patch/mass and non mass patch/Standard Model/Predict\"\n",
    "data = pd.read_csv(csv_path)\n",
    "inbreast_set_y_orig = data['roi']\n",
    "\n",
    "# print(test_set_x_orig.shape)\n",
    "dice_list = []\n",
    "iou_list = []\n",
    "overlap_list = []\n",
    "\n",
    "for i in inbreast_set_y_orig:\n",
    "      name_file = os.path.basename(i)\n",
    "      roi = cv.imread(i,0)\n",
    "\n",
    "      pred_path = os.path.join(predict_path,''.join([name_file]))\n",
    "      pred = cv.imread(pred_path,0)\n",
    "\n",
    "      kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "      pred = cv.morphologyEx(pred, cv.MORPH_CLOSE, kernel)\n",
    "      pred = cv.morphologyEx(pred, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "      # dice, iou, overlap, label_y, label_y_pred, roi_num_cnt, num_y_pred = cal_dice_iou_overlap(roi, pred)\n",
    "\n",
    "      dice = compute_dice(roi, pred)\n",
    "      dice_list.append(dice)\n",
    "\n",
    "      overlap = compute_overlap_1(roi, pred)\n",
    "      overlap_list.append(overlap)\n",
    "\n",
    "      iou = compute_iou(roi, pred)\n",
    "      iou_list.append(iou)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhKKhxDeHjbD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'overlap': overlap_list, 'iou': iou_list, 'dice': dice_list })\n",
    "df.to_csv ('/content/drive/MyDrive/test INBreast patch/mass and non mass patch/Standard Model/overlap_iou_dice_inbreast_bb_850_morphology.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRx5cZo-Mjb-"
   },
   "outputs": [],
   "source": [
    "# tnh li do overlap sai\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'overlap': overlap_list, 'iou': iou_list, 'dice': dice_list })\n",
    "df.to_csv ('/content/drive/MyDrive/test INBreast patch/mass and non mass patch/Standard Model/overlap_iou_dice_inbreast_bb_850_morphology_5.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaeK2Lt4zxs6"
   },
   "source": [
    "#### Model without 2nd skip connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2sD7l5rz1s6"
   },
   "outputs": [],
   "source": [
    "files_dir_2nd = os.path.join(drive_path, 'Colab Notebooks', 'files_15_5_23', 'training_dataset_20_bkg_unet_without_skip')\n",
    "model_file_2nd = os.path.join(files_dir_2nd,'unet_effb0-new-data-20_bkg-without-skip.h5')\n",
    "load_model_file_2nd = tf.keras.models.load_model(model_file_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxAE8f-LDvO_",
    "outputId": "42eb3164-1b49-4335-9ceb-1879e19bfbd4"
   },
   "outputs": [],
   "source": [
    "preds_inbreast_2nd = load_model_file_2nd.predict(inbreast_set_x, verbose=1)\n",
    "inbreast_y_pred_2nd = (preds_inbreast_2nd > 0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c_RL2IxELJT",
    "outputId": "c5442e53-c44e-4bbe-947a-04872fe5870b"
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "csv_path = '/content/drive/MyDrive/test INBreast patch/mass and non mass patch/patch_INBreast.csv'\n",
    "predict_path = \"/content/drive/MyDrive/test INBreast patch/mass and non mass patch/Model without 2nd skip connection/Predict\"\n",
    "data = pd.read_csv(csv_path)\n",
    "test_set_x_orig = data['img']\n",
    "\n",
    "# print(test_set_x_orig.shape)\n",
    "n = 0\n",
    "for i in test_set_x_orig:\n",
    "      name_file = os.path.basename(i)\n",
    "      # print(name_file)\n",
    "      save_path = os.path.join(predict_path,''.join([name_file]))\n",
    "      # print(save_path)\n",
    "      predict = np.squeeze(inbreast_y_pred_2nd[n])\n",
    "      plt.imsave(save_path, predict, cmap='gray')\n",
    "      # plt.imshow(predict)\n",
    "      # plt.show\n",
    "      # cv.imwrite(save_path, predict)\n",
    "      n = n + 1\n",
    "print(n)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT6qJ2eJShob"
   },
   "source": [
    "##### show predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "xBj8IigBRSSl",
    "outputId": "1116af5f-c0a9-483e-e784-e6fe59712960"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(66, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "dIE_2yBuRYll",
    "outputId": "7c55480a-1201-4f51-e3b4-195dc72cd521"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(45, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "I2t3hoX6RcGr",
    "outputId": "45fe2898-8d0b-48d6-b1bf-3bd69bbe030d"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(100, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "J3TuaTM9Revr",
    "outputId": "56c06d86-2b73-4f14-bb90-a0b58f209254"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(200, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "vtGPFhgCRjVe",
    "outputId": "7a191be4-5f41-4043-ac65-730ad2d330f1"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(86, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "DD-g7rwqRrLk",
    "outputId": "261aaebf-b083-4946-bc56-ecc12cf4bba3"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(65, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "L3z4PJ2sRm17",
    "outputId": "e0e87699-9bf9-4ba3-cfbe-b3f80482995a"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "GQMk_XNiRzRB",
    "outputId": "edf1634a-8189-4fa0-def2-0edc57c58d27"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(15, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "u2IhGO3IR0gF",
    "outputId": "d6be9a88-37d0-45ce-935b-6781a012e475"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(20, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "QoYJE9WlR2x8",
    "outputId": "b2d639aa-48e2-4b67-ac68-e9286852f81d"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(80, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "rKSaNJIqR4CD",
    "outputId": "32b742d8-5d33-4456-bdc8-e960d953c42e"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(120, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "b6vYwxrPR_i5",
    "outputId": "9d4a23f3-cfde-49f7-c02c-7e30d85a1f45"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(300, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "QUf5JrUZSAvu",
    "outputId": "dd57a359-81df-4446-b442-a5aed9f99f7a"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(350, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "vGQDdseXSDVt",
    "outputId": "e048d6d0-0015-4a46-a75f-8c76750c9ab0"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(500, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "cJmFqBSKSNBM",
    "outputId": "f5e4b58f-c338-492c-f194-33ca876c274d"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(800, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "_Nmy0PFXSOJX",
    "outputId": "8e0e91de-de41-456a-f0dd-7d3cb87983fe"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(900, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "UKnHezlCSPnk",
    "outputId": "e5f6db6c-4c6e-45bf-c2b0-46c60ac4e586"
   },
   "outputs": [],
   "source": [
    "show_image_roi_predict1_img(1400, inbreast_set_x, inbreast_set_y, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5uUGliJScjF"
   },
   "source": [
    "##### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4rjmOvGRRF6",
    "outputId": "7b062f08-0b6b-4820-c902-c26bc44b06e7"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/test INBreast patch/mass and non mass patch/patch_INBreast.csv'\n",
    "predict_path = \"/content/drive/MyDrive/test INBreast patch/mass and non mass patch/Model without 2nd skip connection/Predict\"\n",
    "data = pd.read_csv(csv_path)\n",
    "inbreast_set_y_orig = data['roi']\n",
    "\n",
    "# print(test_set_x_orig.shape)\n",
    "dice_list_2nd = []\n",
    "iou_list_2nd = []\n",
    "overlap_list_2nd = []\n",
    "\n",
    "for i in inbreast_set_y_orig:\n",
    "      name_file = os.path.basename(i)\n",
    "      roi = cv.imread(i,0)\n",
    "\n",
    "      pred_path = os.path.join(predict_path,''.join([name_file]))\n",
    "      pred = cv.imread(pred_path,0)\n",
    "\n",
    "      kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "      pred = cv.morphologyEx(pred, cv.MORPH_CLOSE, kernel)\n",
    "      pred = cv.morphologyEx(pred, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "      dice = compute_dice(roi, pred)\n",
    "      dice_list_2nd.append(dice)\n",
    "\n",
    "      overlap = compute_overlap_1(roi, pred)\n",
    "      overlap_list_2nd.append(overlap)\n",
    "\n",
    "      iou = compute_iou(roi, pred)\n",
    "      iou_list_2nd.append(iou)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zWSs_H9S0SI"
   },
   "outputs": [],
   "source": [
    "# tnh li do overlap sai\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'overlap': overlap_list_2nd, 'iou': iou_list_2nd, 'dice': dice_list_2nd })\n",
    "df.to_csv ('/content/drive/MyDrive/test INBreast patch/mass and non mass patch/Model without 2nd skip connection//overlap_iou_dice_inbreast_bb_850_morphology_2nd.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-Bszl3qTM9z"
   },
   "outputs": [],
   "source": [
    "overlaps_2nd = []\n",
    "labels_y_2nd = []\n",
    "labels_y_pred_2nd = []\n",
    "for i in range(len(inbreast_set_x)):\n",
    "  x = inbreast_set_x[i]\n",
    "  y = inbreast_set_y[i]\n",
    "  y_pred = inbreast_y_pred_2nd[i] ,\n",
    "  overlap, label_y, label_y_pred = cal_overlap_label(x,y,y_pred)\n",
    "  overlaps_2nd.append(overlap)\n",
    "  labels_y_2nd.append(label_y)\n",
    "  labels_y_pred_2nd.append(label_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "D4UB95CVTmuU",
    "outputId": "02ff0b43-6e46-41e9-e504-a7c347743cad"
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_pred_2 = test_set_y_pred.ravel()\n",
    "# test_set_y_2 = test_set_y.ravel()\n",
    "cm=confusion_matrix(labels_y_2nd, labels_y_pred_2nd)\n",
    "print(cm)\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title('confusion matrix - Test data')\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQo2YHtMTyXY",
    "outputId": "2c6e79b9-5e9a-4bbd-f7b7-644070355c6e"
   },
   "outputs": [],
   "source": [
    "total1=sum(sum(cm))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1=(cm[0,0]+cm[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3gUiZaMT5K_"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzCL5w8yT5Rr"
   },
   "source": [
    "#### so snh 2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m2yEj04T8ll"
   },
   "outputs": [],
   "source": [
    "def image_roi_predict_pred_2nd_overlap(index, x, y, predict, pred_2nd):\n",
    "    # overlap = cal_overlap(x[index], y[index], predict[index])\n",
    "    # print (overlap)\n",
    "\n",
    "    roi = np.squeeze(y[index])\n",
    "    # print(roi.dtype)\n",
    "    image_8bit = np.uint8(roi)\n",
    "    _, binarized = cv.threshold(image_8bit, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_roi, hierarchy = cv.findContours(binarized, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "    y_pred_filter = cv.morphologyEx(np.squeeze(predict[index]), cv.MORPH_CLOSE, kernel)\n",
    "    y_pred_filter = cv.morphologyEx(y_pred_filter, cv.MORPH_OPEN, kernel)\n",
    "    # roi_pred = np.squeeze(predict[index])\n",
    "    # print(roi_pred.dtype)\n",
    "    y_pred_filter = np.uint8(y_pred_filter)\n",
    "    _, binarized = cv.threshold(y_pred_filter, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_pred, hierarchy = cv.findContours(binarized,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    y_pred_filter_2nd = cv.morphologyEx(np.squeeze(pred_2nd[index]), cv.MORPH_CLOSE, kernel)\n",
    "    y_pred_filter_2nd = cv.morphologyEx(y_pred_filter_2nd, cv.MORPH_OPEN, kernel)\n",
    "    # roi_pred_2nd = np.squeeze(pred_2nd[index])\n",
    "    # print(roi_pred_2nd.dtype)\n",
    "    y_pred_filter_2nd = np.uint8(y_pred_filter_2nd)\n",
    "    _, binarized_2nd = cv.threshold(y_pred_filter_2nd, 0, 255, cv.THRESH_BINARY)\n",
    "    contours_pred_2nd, hierarchy = cv.findContours(binarized_2nd,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    img = x[index]\n",
    "    img_copy = img.copy()\n",
    "    cv.drawContours(img_copy, contours_roi,-1,(255,0,0),2)\n",
    "    cv.drawContours(img_copy, contours_pred,-1, (0,255,0), 2)\n",
    "    cv.drawContours(img_copy, contours_pred_2nd,-1, (0,0,255), 2)\n",
    "    plt.imshow(img_copy)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image' + str(index))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "i5IQDKzRWEv7",
    "outputId": "d3b279df-f63d-4090-e943-7be795963f05"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(1, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "rhJOUJFzY2Q0",
    "outputId": "f25f2ac4-340a-4856-a27e-e4272475eb2c"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(10, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "LeogN3r3Y3kH",
    "outputId": "7688de2d-8cd6-4f45-8ec7-684a5e4a5bbb"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(5, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "kOZgXmu9Y3nf",
    "outputId": "9d9231e9-0c82-4f78-afa5-3326ac29c082"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(6, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "ecQKn8-rY8Ru",
    "outputId": "aa83307f-733a-4ee8-eff7-534a524b0910"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(120, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "mcBpIbghY-KM",
    "outputId": "80ec1cca-310d-43a4-de7b-76036494b880"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(86, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "gCDZXLs6ZBC_",
    "outputId": "18df4cba-feb5-4cd6-9256-e3f6054aa280"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(45, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "fUovw8KzZJ92",
    "outputId": "3f85bcc7-59cb-4c8d-b9a2-b973dd594c0f"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(66, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "qhU2QWgcZLuJ",
    "outputId": "7ab0caac-ff89-40db-acd4-5db7fee289b6"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(15, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "zeJ7s1r8ZNFI",
    "outputId": "283a87d1-5f4b-4ebc-f018-3f0d7f875ae2"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(20, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "8cqZZcv_ZOty",
    "outputId": "a7f31afa-f0d5-455d-a51c-7403d7065eb2"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(120, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "6pyrtxATZqPO",
    "outputId": "6c7b0ce4-b080-4ecb-ee77-37402c73f941"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(3, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "cY86QVEfZwOL",
    "outputId": "4f7abb7b-e1cd-4bb4-aa82-1785335d9e52"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(6, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "BIzVU-egZ09b",
    "outputId": "93c6cf66-9821-4298-dc8d-7b572108eda9"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(39, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "GTSBT4tWZ9md",
    "outputId": "12683344-40f6-4393-c592-72e012a0ba4b"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(47, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "sqaHNXHPaec5",
    "outputId": "2629d478-fa1f-42a3-fff9-7a538b9a93c3"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(212, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "MyyjiTRzan7X",
    "outputId": "3aadebe8-41bd-4c55-ffba-9a6b664258b5"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(274, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "MqFWKPU6apiD",
    "outputId": "32d46a96-9315-44ef-9879-a2f01a14da66"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(275, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "M2azPwZLbSFf",
    "outputId": "910072ce-598c-4e02-d9a6-35958ddd1af7"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(355, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "gC3DbeO4bUQu",
    "outputId": "5680fe67-d2b1-4da0-b6a7-818ab67ec763"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(433, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "__eMPbjFbevJ",
    "outputId": "d8946f2a-8741-470f-9730-aee280aa7b10"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(569, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "t3lgbgbibvQr",
    "outputId": "844d3af9-662c-44db-d198-13f5d19ea2e8"
   },
   "outputs": [],
   "source": [
    "image_roi_predict_pred_2nd_overlap(579, inbreast_set_x, inbreast_set_y, inbreast_y_pred, inbreast_y_pred_2nd)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-9WSDSxOxZlj",
    "faSnoYZMxdbj",
    "4-UFeZpsUkk2",
    "3i5qS4Fu9oBf",
    "KtuFI3auxHuE",
    "kQr5mnmWO9Js"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
